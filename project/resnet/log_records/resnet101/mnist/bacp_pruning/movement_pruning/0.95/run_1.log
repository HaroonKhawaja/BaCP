Model : resnet101 - Learning Type: mnist/bacp_pruning/movement_pruning/0.95
Configuration:
model_name: resnet101
model_task: mnist
model_type: cv
num_classes: 10
batch_size: 512
learning_rate: 0.1
optimizer_type: sgd
epochs: 5
recovery_epochs: 10
patience: 20
pruning_type: movement_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
pruning_epochs: 5
n_views: 2
temperature: 0.07
base_temperature: 0.07
device: cuda
enable_mixed_precision: True
num_workers: 24
train_batches: 99
val_batches: 17
current_model_path: /dbfs/research/resnet101/mnist/resnet101_mnist_movement_pruning_0.95_bacp_pruning.pt

Epoch [1/5]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: 0.0000 | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.541
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.541
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.541
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.541
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.541
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.541
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.541
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.541
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.541
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.541
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.541
Epoch [2/5]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 1.0
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8734 | Avg SnC Loss: nan | Avg FiC Loss: 6.2749 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8741 | Avg SnC Loss: nan | Avg FiC Loss: 6.2749 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8725 | Avg SnC Loss: nan | Avg FiC Loss: 6.2744 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8745 | Avg SnC Loss: nan | Avg FiC Loss: 6.2744 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8740 | Avg SnC Loss: nan | Avg FiC Loss: 6.2749 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8744 | Avg SnC Loss: nan | Avg FiC Loss: 6.2750 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8740 | Avg SnC Loss: nan | Avg FiC Loss: 6.2751 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8733 | Avg SnC Loss: nan | Avg FiC Loss: 6.2756 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8736 | Avg SnC Loss: nan | Avg FiC Loss: 6.2752 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8742 | Avg SnC Loss: nan | Avg FiC Loss: 6.2747 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Epoch [3/5]: Avg Total Loss: nan | Avg PrC Loss: 4.8748 | Avg SnC Loss: nan | Avg FiC Loss: 6.2749 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8739 | Avg SnC Loss: nan | Avg FiC Loss: 6.2756 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8741 | Avg SnC Loss: nan | Avg FiC Loss: 6.2745 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8737 | Avg SnC Loss: nan | Avg FiC Loss: 6.2751 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8740 | Avg SnC Loss: nan | Avg FiC Loss: 6.2749 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8745 | Avg SnC Loss: nan | Avg FiC Loss: 6.2758 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8748 | Avg SnC Loss: nan | Avg FiC Loss: 6.2758 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8734 | Avg SnC Loss: nan | Avg FiC Loss: 6.2749 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8750 | Avg SnC Loss: nan | Avg FiC Loss: 6.2748 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8738 | Avg SnC Loss: nan | Avg FiC Loss: 6.2747 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8740 | Avg SnC Loss: nan | Avg FiC Loss: 6.2744 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Epoch [4/5]: Avg Total Loss: nan | Avg PrC Loss: 4.8736 | Avg SnC Loss: nan | Avg FiC Loss: 6.2756 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8744 | Avg SnC Loss: nan | Avg FiC Loss: 6.2752 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8749 | Avg SnC Loss: nan | Avg FiC Loss: 6.2753 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8730 | Avg SnC Loss: nan | Avg FiC Loss: 6.2753 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8739 | Avg SnC Loss: nan | Avg FiC Loss: 6.2745 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8741 | Avg SnC Loss: nan | Avg FiC Loss: 6.2750 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8742 | Avg SnC Loss: nan | Avg FiC Loss: 6.2747 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8731 | Avg SnC Loss: nan | Avg FiC Loss: 6.2748 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8735 | Avg SnC Loss: nan | Avg FiC Loss: 6.2752 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8742 | Avg SnC Loss: nan | Avg FiC Loss: 6.2751 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8738 | Avg SnC Loss: nan | Avg FiC Loss: 6.2746 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Epoch [5/5]: Avg Total Loss: nan | Avg PrC Loss: 4.8741 | Avg SnC Loss: nan | Avg FiC Loss: 6.2745 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8739 | Avg SnC Loss: nan | Avg FiC Loss: 6.2744 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8728 | Avg SnC Loss: nan | Avg FiC Loss: 6.2755 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8734 | Avg SnC Loss: nan | Avg FiC Loss: 6.2751 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8737 | Avg SnC Loss: nan | Avg FiC Loss: 6.2749 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8744 | Avg SnC Loss: nan | Avg FiC Loss: 6.2757 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8745 | Avg SnC Loss: nan | Avg FiC Loss: 6.2748 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8748 | Avg SnC Loss: nan | Avg FiC Loss: 6.2745 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8731 | Avg SnC Loss: nan | Avg FiC Loss: 6.2758 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8733 | Avg SnC Loss: nan | Avg FiC Loss: 6.2750 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: 4.8740 | Avg SnC Loss: nan | Avg FiC Loss: 6.2757 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
