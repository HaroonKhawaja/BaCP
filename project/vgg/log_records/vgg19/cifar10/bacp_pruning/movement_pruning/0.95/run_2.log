Model : vgg19 - Learning Type: cifar10/bacp_pruning/movement_pruning/0.95
Configuration:
model_name: vgg19
model_task: cifar10
model_type: cv
num_classes: 10
batch_size: 512
learning_rate: 0.1
optimizer_type: sgd
epochs: 5
recovery_epochs: 10
patience: 20
pruning_type: movement_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
pruning_epochs: 5
n_views: 2
temperature: 0.15
base_temperature: 0.15
device: cuda
enable_mixed_precision: True
num_workers: 24
train_batches: 83
val_batches: 14
current_model_path: /dbfs/research/vgg19/cifar10/vgg19_cifar10_movement_pruning_0.95_bacp_pruning.pt

Epoch [1/5]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: 0.0000 | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.4636
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.4636
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.4636
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.4636
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.4636
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.4636
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.4636
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.4636
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.4636
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.4636
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.4636
Epoch [2/5]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 1.0
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1338 | Avg SnC Loss: nan | Avg FiC Loss: 3.6418 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1335 | Avg SnC Loss: nan | Avg FiC Loss: 3.6426 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1339 | Avg SnC Loss: nan | Avg FiC Loss: 3.6427 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1332 | Avg SnC Loss: nan | Avg FiC Loss: 3.6422 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1334 | Avg SnC Loss: nan | Avg FiC Loss: 3.6429 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1336 | Avg SnC Loss: nan | Avg FiC Loss: 3.6421 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1332 | Avg SnC Loss: nan | Avg FiC Loss: 3.6421 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1338 | Avg SnC Loss: nan | Avg FiC Loss: 3.6421 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1334 | Avg SnC Loss: nan | Avg FiC Loss: 3.6424 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1333 | Avg SnC Loss: nan | Avg FiC Loss: 3.6431 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Epoch [3/5]: Avg Total Loss: nan | Avg PrC Loss: 4.1336 | Avg SnC Loss: nan | Avg FiC Loss: 3.6430 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1335 | Avg SnC Loss: nan | Avg FiC Loss: 3.6429 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1334 | Avg SnC Loss: nan | Avg FiC Loss: 3.6426 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1332 | Avg SnC Loss: nan | Avg FiC Loss: 3.6424 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1327 | Avg SnC Loss: nan | Avg FiC Loss: 3.6421 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1341 | Avg SnC Loss: nan | Avg FiC Loss: 3.6426 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1337 | Avg SnC Loss: nan | Avg FiC Loss: 3.6427 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1345 | Avg SnC Loss: nan | Avg FiC Loss: 3.6425 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1333 | Avg SnC Loss: nan | Avg FiC Loss: 3.6422 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1330 | Avg SnC Loss: nan | Avg FiC Loss: 3.6423 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1334 | Avg SnC Loss: nan | Avg FiC Loss: 3.6422 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Epoch [4/5]: Avg Total Loss: nan | Avg PrC Loss: 4.1327 | Avg SnC Loss: nan | Avg FiC Loss: 3.6418 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1331 | Avg SnC Loss: nan | Avg FiC Loss: 3.6425 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1331 | Avg SnC Loss: nan | Avg FiC Loss: 3.6424 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1337 | Avg SnC Loss: nan | Avg FiC Loss: 3.6424 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1336 | Avg SnC Loss: nan | Avg FiC Loss: 3.6424 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1334 | Avg SnC Loss: nan | Avg FiC Loss: 3.6420 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1331 | Avg SnC Loss: nan | Avg FiC Loss: 3.6429 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1332 | Avg SnC Loss: nan | Avg FiC Loss: 3.6424 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1335 | Avg SnC Loss: nan | Avg FiC Loss: 3.6425 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1328 | Avg SnC Loss: nan | Avg FiC Loss: 3.6425 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1337 | Avg SnC Loss: nan | Avg FiC Loss: 3.6428 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Epoch [5/5]: Avg Total Loss: nan | Avg PrC Loss: 4.1339 | Avg SnC Loss: nan | Avg FiC Loss: 3.6427 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1334 | Avg SnC Loss: nan | Avg FiC Loss: 3.6424 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1337 | Avg SnC Loss: nan | Avg FiC Loss: 3.6429 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1328 | Avg SnC Loss: nan | Avg FiC Loss: 3.6425 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1339 | Avg SnC Loss: nan | Avg FiC Loss: 3.6426 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1331 | Avg SnC Loss: nan | Avg FiC Loss: 3.6421 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1332 | Avg SnC Loss: nan | Avg FiC Loss: 3.6429 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1333 | Avg SnC Loss: nan | Avg FiC Loss: 3.6425 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1337 | Avg SnC Loss: nan | Avg FiC Loss: 3.6419 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1336 | Avg SnC Loss: nan | Avg FiC Loss: 3.6424 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: 4.1334 | Avg SnC Loss: nan | Avg FiC Loss: 3.6426 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
