Model : vgg19 - Learning Type: mnist/bacp_pruning/movement_pruning/0.99
Configuration:
model_name: vgg19
model_task: mnist
model_type: cv
num_classes: 10
batch_size: 512
learning_rate: 0.1
optimizer_type: sgd
epochs: 5
recovery_epochs: 10
patience: 20
pruning_type: movement_pruning
target_sparsity: 0.99
sparsity_scheduler: cubic
pruning_epochs: 5
n_views: 2
temperature: 0.15
base_temperature: 0.15
device: cuda
enable_mixed_precision: True
num_workers: 24
train_batches: 99
val_batches: 17
current_model_path: /dbfs/research/vgg19/mnist/vgg19_mnist_movement_pruning_0.99_bacp_pruning.pt

Epoch [1/5]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: 0.0000 | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.6053
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.6053
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.6053
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.6053
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.6053
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.6053
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.6053
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.6053
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.6053
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.6053
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 0.6053
Epoch [2/5]: Avg Total Loss: nan | Avg PrC Loss: nan | Avg SnC Loss: nan | Avg FiC Loss: nan | Avg CE Loss: nan | Model Sparsity: 1.0
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6447 | Avg SnC Loss: nan | Avg FiC Loss: 4.1881 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6450 | Avg SnC Loss: nan | Avg FiC Loss: 4.1884 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6456 | Avg SnC Loss: nan | Avg FiC Loss: 4.1877 | Avg CE Loss: 0.5757 | Model Sparsity: 1.0
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6459 | Avg SnC Loss: nan | Avg FiC Loss: 4.1881 | Avg CE Loss: 0.5757 | Model Sparsity: 1.0
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6458 | Avg SnC Loss: nan | Avg FiC Loss: 4.1880 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6460 | Avg SnC Loss: nan | Avg FiC Loss: 4.1883 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6457 | Avg SnC Loss: nan | Avg FiC Loss: 4.1882 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6452 | Avg SnC Loss: nan | Avg FiC Loss: 4.1882 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6460 | Avg SnC Loss: nan | Avg FiC Loss: 4.1883 | Avg CE Loss: 0.5757 | Model Sparsity: 1.0
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6460 | Avg SnC Loss: nan | Avg FiC Loss: 4.1883 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Epoch [3/5]: Avg Total Loss: nan | Avg PrC Loss: 3.6451 | Avg SnC Loss: nan | Avg FiC Loss: 4.1881 | Avg CE Loss: 0.5757 | Model Sparsity: 1.0
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6450 | Avg SnC Loss: nan | Avg FiC Loss: 4.1877 | Avg CE Loss: 0.5757 | Model Sparsity: 1.0
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6451 | Avg SnC Loss: nan | Avg FiC Loss: 4.1881 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6459 | Avg SnC Loss: nan | Avg FiC Loss: 4.1880 | Avg CE Loss: 0.5759 | Model Sparsity: 1.0
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6451 | Avg SnC Loss: nan | Avg FiC Loss: 4.1885 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6457 | Avg SnC Loss: nan | Avg FiC Loss: 4.1883 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6453 | Avg SnC Loss: nan | Avg FiC Loss: 4.1880 | Avg CE Loss: 0.5757 | Model Sparsity: 1.0
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6449 | Avg SnC Loss: nan | Avg FiC Loss: 4.1879 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6454 | Avg SnC Loss: nan | Avg FiC Loss: 4.1882 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6448 | Avg SnC Loss: nan | Avg FiC Loss: 4.1879 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6450 | Avg SnC Loss: nan | Avg FiC Loss: 4.1885 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Epoch [4/5]: Avg Total Loss: nan | Avg PrC Loss: 3.6459 | Avg SnC Loss: nan | Avg FiC Loss: 4.1881 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6453 | Avg SnC Loss: nan | Avg FiC Loss: 4.1876 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6452 | Avg SnC Loss: nan | Avg FiC Loss: 4.1880 | Avg CE Loss: 0.5757 | Model Sparsity: 1.0
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6450 | Avg SnC Loss: nan | Avg FiC Loss: 4.1886 | Avg CE Loss: 0.5757 | Model Sparsity: 1.0
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6444 | Avg SnC Loss: nan | Avg FiC Loss: 4.1884 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6457 | Avg SnC Loss: nan | Avg FiC Loss: 4.1882 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6453 | Avg SnC Loss: nan | Avg FiC Loss: 4.1875 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6453 | Avg SnC Loss: nan | Avg FiC Loss: 4.1881 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6450 | Avg SnC Loss: nan | Avg FiC Loss: 4.1884 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6457 | Avg SnC Loss: nan | Avg FiC Loss: 4.1882 | Avg CE Loss: 0.5757 | Model Sparsity: 1.0
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6447 | Avg SnC Loss: nan | Avg FiC Loss: 4.1882 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Epoch [5/5]: Avg Total Loss: nan | Avg PrC Loss: 3.6448 | Avg SnC Loss: nan | Avg FiC Loss: 4.1881 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [1/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6455 | Avg SnC Loss: nan | Avg FiC Loss: 4.1881 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [2/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6454 | Avg SnC Loss: nan | Avg FiC Loss: 4.1883 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [3/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6456 | Avg SnC Loss: nan | Avg FiC Loss: 4.1884 | Avg CE Loss: 0.5757 | Model Sparsity: 1.0
Retraining Epoch [4/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6449 | Avg SnC Loss: nan | Avg FiC Loss: 4.1880 | Avg CE Loss: 0.5757 | Model Sparsity: 1.0
Retraining Epoch [5/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6447 | Avg SnC Loss: nan | Avg FiC Loss: 4.1880 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [6/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6451 | Avg SnC Loss: nan | Avg FiC Loss: 4.1882 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [7/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6451 | Avg SnC Loss: nan | Avg FiC Loss: 4.1884 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [8/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6456 | Avg SnC Loss: nan | Avg FiC Loss: 4.1880 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [9/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6451 | Avg SnC Loss: nan | Avg FiC Loss: 4.1884 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
Retraining Epoch [10/10]: Avg Total Loss: nan | Avg PrC Loss: 3.6449 | Avg SnC Loss: nan | Avg FiC Loss: 4.1882 | Avg CE Loss: 0.5758 | Model Sparsity: 1.0
