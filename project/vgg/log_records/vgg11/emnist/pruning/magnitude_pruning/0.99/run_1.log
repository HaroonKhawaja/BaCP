Model : vgg11 - Learning Type: emnist/pruning/magnitude_pruning/0.99
Configuration:
model_type: cv
model_name: vgg11
model_task: emnist
num_classes: 47
criterion: CrossEntropyLoss()
embedding_dim: 4096
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 512
learning_rate: 0.01
learning_type: pruning
optimizer_type: sgd
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.99
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vgg11/emnist/vgg11_emnist_magnitude_pruning_0.99_pruning.pt
finetuned_weights: /dbfs/research/vgg11/emnist/vgg11_emnist_baseline.pt

Epoch [1/5]: Avg Loss: 0.1561 | Avg Accuracy: 88.61 | Model Sparsity: 0.4831
Recovery epoch [1/10]: Avg Loss: 0.1577 | Avg Accuracy: 89.19 | Model Sparsity: 0.4831
Recovery epoch [2/10]: Avg Loss: 0.1567 | Avg Accuracy: 89.10 | Model Sparsity: 0.4831
Recovery epoch [3/10]: Avg Loss: 0.1502 | Avg Accuracy: 88.80 | Model Sparsity: 0.4831
Recovery epoch [4/10]: Avg Loss: 0.1474 | Avg Accuracy: 89.13 | Model Sparsity: 0.4831
Recovery epoch [5/10]: Avg Loss: 0.1480 | Avg Accuracy: 89.02 | Model Sparsity: 0.4831
Recovery epoch [6/10]: Avg Loss: 0.1460 | Avg Accuracy: 89.16 | Model Sparsity: 0.4831
Recovery epoch [7/10]: Avg Loss: 0.1409 | Avg Accuracy: 89.22 | Model Sparsity: 0.4831
Recovery epoch [8/10]: Avg Loss: 0.1407 | Avg Accuracy: 89.12 | Model Sparsity: 0.4831
Recovery epoch [9/10]: Avg Loss: 0.1403 | Avg Accuracy: 88.81 | Model Sparsity: 0.4831
Recovery epoch [10/10]: Avg Loss: 0.1369 | Avg Accuracy: 89.18 | Model Sparsity: 0.4831
Epoch [2/5]: Avg Loss: 0.1388 | Avg Accuracy: 89.12 | Model Sparsity: 0.7762
Recovery epoch [1/10]: Avg Loss: 0.1299 | Avg Accuracy: 89.09 | Model Sparsity: 0.7762
Recovery epoch [2/10]: Avg Loss: 0.1296 | Avg Accuracy: 89.35 | Model Sparsity: 0.7762
Recovery epoch [3/10]: Avg Loss: 0.1280 | Avg Accuracy: 89.06 | Model Sparsity: 0.7762
Recovery epoch [4/10]: Avg Loss: 0.1253 | Avg Accuracy: 89.10 | Model Sparsity: 0.7762
Recovery epoch [5/10]: Avg Loss: 0.1247 | Avg Accuracy: 89.43 | Model Sparsity: 0.7762
Recovery epoch [6/10]: Avg Loss: 0.1231 | Avg Accuracy: 89.10 | Model Sparsity: 0.7762
Recovery epoch [7/10]: Avg Loss: 0.1246 | Avg Accuracy: 89.17 | Model Sparsity: 0.7762
Recovery epoch [8/10]: Avg Loss: 0.1204 | Avg Accuracy: 89.10 | Model Sparsity: 0.7762
Recovery epoch [9/10]: Avg Loss: 0.1200 | Avg Accuracy: 88.54 | Model Sparsity: 0.7762
Recovery epoch [10/10]: Avg Loss: 0.1181 | Avg Accuracy: 89.05 | Model Sparsity: 0.7762
Epoch [3/5]: Avg Loss: 0.1915 | Avg Accuracy: 89.31 | Model Sparsity: 0.9266
Recovery epoch [1/10]: Avg Loss: 0.1475 | Avg Accuracy: 89.29 | Model Sparsity: 0.9266
Recovery epoch [2/10]: Avg Loss: 0.1363 | Avg Accuracy: 89.00 | Model Sparsity: 0.9266
Recovery epoch [3/10]: Avg Loss: 0.1346 | Avg Accuracy: 89.09 | Model Sparsity: 0.9266
Recovery epoch [4/10]: Avg Loss: 0.1287 | Avg Accuracy: 89.10 | Model Sparsity: 0.9266
Recovery epoch [5/10]: Avg Loss: 0.1297 | Avg Accuracy: 88.65 | Model Sparsity: 0.9266
Recovery epoch [6/10]: Avg Loss: 0.1263 | Avg Accuracy: 89.13 | Model Sparsity: 0.9266
Recovery epoch [7/10]: Avg Loss: 0.1199 | Avg Accuracy: 88.81 | Model Sparsity: 0.9266
Recovery epoch [8/10]: Avg Loss: 0.1205 | Avg Accuracy: 88.86 | Model Sparsity: 0.9266
Recovery epoch [9/10]: Avg Loss: 0.1181 | Avg Accuracy: 88.94 | Model Sparsity: 0.9266
Recovery epoch [10/10]: Avg Loss: 0.1181 | Avg Accuracy: 88.78 | Model Sparsity: 0.9266
Epoch [4/5]: Avg Loss: 0.5892 | Avg Accuracy: 88.41 | Model Sparsity: 0.9821
Recovery epoch [1/10]: Avg Loss: 0.2897 | Avg Accuracy: 89.01 | Model Sparsity: 0.9821
Recovery epoch [2/10]: Avg Loss: 0.2571 | Avg Accuracy: 89.02 | Model Sparsity: 0.9821
Recovery epoch [3/10]: Avg Loss: 0.2390 | Avg Accuracy: 89.34 | Model Sparsity: 0.9821
Recovery epoch [4/10]: Avg Loss: 0.2233 | Avg Accuracy: 89.03 | Model Sparsity: 0.9821
Recovery epoch [5/10]: Avg Loss: 0.2148 | Avg Accuracy: 89.32 | Model Sparsity: 0.9821
Recovery epoch [6/10]: Avg Loss: 0.2036 | Avg Accuracy: 89.04 | Model Sparsity: 0.9821
Recovery epoch [7/10]: Avg Loss: 0.1972 | Avg Accuracy: 89.31 | Model Sparsity: 0.9821
Recovery epoch [8/10]: Avg Loss: 0.1880 | Avg Accuracy: 89.05 | Model Sparsity: 0.9821
Recovery epoch [9/10]: Avg Loss: 0.1813 | Avg Accuracy: 89.31 | Model Sparsity: 0.9821
Recovery epoch [10/10]: Avg Loss: 0.1774 | Avg Accuracy: 89.10 | Model Sparsity: 0.9821
Epoch [5/5]: Avg Loss: 0.2132 | Avg Accuracy: 88.80 | Model Sparsity: 0.99
Recovery epoch [1/10]: Avg Loss: 0.1918 | Avg Accuracy: 89.06 | Model Sparsity: 0.99
Recovery epoch [2/10]: Avg Loss: 0.1849 | Avg Accuracy: 88.95 | Model Sparsity: 0.99
Recovery epoch [3/10]: Avg Loss: 0.1795 | Avg Accuracy: 88.96 | Model Sparsity: 0.99
Recovery epoch [4/10]: Avg Loss: 0.1767 | Avg Accuracy: 89.18 | Model Sparsity: 0.99
Recovery epoch [5/10]: Avg Loss: 0.1718 | Avg Accuracy: 89.15 | Model Sparsity: 0.99
Recovery epoch [6/10]: Avg Loss: 0.1680 | Avg Accuracy: 88.93 | Model Sparsity: 0.99
Recovery epoch [7/10]: Avg Loss: 0.1658 | Avg Accuracy: 89.07 | Model Sparsity: 0.99
Recovery epoch [8/10]: Avg Loss: 0.1668 | Avg Accuracy: 89.31 | Model Sparsity: 0.99
Recovery epoch [9/10]: Avg Loss: 0.1615 | Avg Accuracy: 88.84 | Model Sparsity: 0.99
Recovery epoch [10/10]: Avg Loss: 0.1599 | Avg Accuracy: 88.86 | Model Sparsity: 0.99
