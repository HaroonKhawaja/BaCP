Model : vgg11 - Learning Type: cifar10/bacp_finetune/magnitude_pruning/0.95
Configuration:
model_type: cv
model_name: vgg11
model_task: cifar10
num_classes: 10
criterion: CrossEntropyLoss()
embedding_dim: 4096
epochs: 50
pruning_epochs: 50
recovery_epochs: 10
batch_size: 512
learning_rate: 0.001
learning_type: bacp_finetune
optimizer_type: adamw
prune: False
pruning_type: magnitude_pruning
target_sparsity: 0.95
sparsity_scheduler: linear
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vgg11/cifar10/vgg11_cifar10_magnitude_pruning_0.95_bacp_finetune.pt
finetuned_weights: /dbfs/research/vgg11/cifar10/vgg11_cifar10_magnitude_pruning_0.95_bacp_pruning.pt

Epoch [1/50]: Avg Loss: 1.1140 | Avg Accuracy: 84.49 | Model Sparsity: 0.95
Epoch [2/50]: Avg Loss: 0.4504 | Avg Accuracy: 85.34 | Model Sparsity: 0.95
Epoch [3/50]: Avg Loss: 0.3983 | Avg Accuracy: 85.95 | Model Sparsity: 0.95
Epoch [4/50]: Avg Loss: 0.3723 | Avg Accuracy: 87.00 | Model Sparsity: 0.95
Epoch [5/50]: Avg Loss: 0.3588 | Avg Accuracy: 88.13 | Model Sparsity: 0.95
Epoch [6/50]: Avg Loss: 0.3271 | Avg Accuracy: 87.47 | Model Sparsity: 0.95
Epoch [7/50]: Avg Loss: 0.3190 | Avg Accuracy: 87.81 | Model Sparsity: 0.95
Epoch [8/50]: Avg Loss: 0.3062 | Avg Accuracy: 87.25 | Model Sparsity: 0.95
Epoch [9/50]: Avg Loss: 0.2981 | Avg Accuracy: 86.94 | Model Sparsity: 0.95
Epoch [10/50]: Avg Loss: 0.2882 | Avg Accuracy: 87.99 | Model Sparsity: 0.95
Epoch [11/50]: Avg Loss: 0.2704 | Avg Accuracy: 87.67 | Model Sparsity: 0.95
Epoch [12/50]: Avg Loss: 0.2691 | Avg Accuracy: 88.41 | Model Sparsity: 0.95
Epoch [13/50]: Avg Loss: 0.2547 | Avg Accuracy: 87.75 | Model Sparsity: 0.95
Epoch [14/50]: Avg Loss: 0.2460 | Avg Accuracy: 87.93 | Model Sparsity: 0.95
Epoch [15/50]: Avg Loss: 0.2453 | Avg Accuracy: 87.70 | Model Sparsity: 0.95
Epoch [16/50]: Avg Loss: 0.2397 | Avg Accuracy: 87.97 | Model Sparsity: 0.95
Epoch [17/50]: Avg Loss: 0.2391 | Avg Accuracy: 88.36 | Model Sparsity: 0.95
Epoch [18/50]: Avg Loss: 0.2278 | Avg Accuracy: 88.84 | Model Sparsity: 0.95
Epoch [19/50]: Avg Loss: 0.2214 | Avg Accuracy: 88.14 | Model Sparsity: 0.95
Epoch [20/50]: Avg Loss: 0.2202 | Avg Accuracy: 87.83 | Model Sparsity: 0.95
Epoch [21/50]: Avg Loss: 0.2177 | Avg Accuracy: 88.36 | Model Sparsity: 0.95
Epoch [22/50]: Avg Loss: 0.2017 | Avg Accuracy: 88.39 | Model Sparsity: 0.95
Epoch [23/50]: Avg Loss: 0.2000 | Avg Accuracy: 88.28 | Model Sparsity: 0.95
Epoch [24/50]: Avg Loss: 0.1977 | Avg Accuracy: 88.46 | Model Sparsity: 0.95
Epoch [25/50]: Avg Loss: 0.1913 | Avg Accuracy: 88.02 | Model Sparsity: 0.95
Epoch [26/50]: Avg Loss: 0.1879 | Avg Accuracy: 88.70 | Model Sparsity: 0.95
Epoch [27/50]: Avg Loss: 0.1826 | Avg Accuracy: 88.27 | Model Sparsity: 0.95
Epoch [28/50]: Avg Loss: 0.1894 | Avg Accuracy: 87.89 | Model Sparsity: 0.95
Epoch [29/50]: Avg Loss: 0.1932 | Avg Accuracy: 88.34 | Model Sparsity: 0.95
Epoch [30/50]: Avg Loss: 0.1768 | Avg Accuracy: 88.06 | Model Sparsity: 0.95
Epoch [31/50]: Avg Loss: 0.1802 | Avg Accuracy: 88.28 | Model Sparsity: 0.95
Epoch [32/50]: Avg Loss: 0.1729 | Avg Accuracy: 88.11 | Model Sparsity: 0.95
Epoch [33/50]: Avg Loss: 0.1759 | Avg Accuracy: 88.31 | Model Sparsity: 0.95
Epoch [34/50]: Avg Loss: 0.1802 | Avg Accuracy: 87.17 | Model Sparsity: 0.95
Epoch [35/50]: Avg Loss: 0.1760 | Avg Accuracy: 88.42 | Model Sparsity: 0.95
Epoch [36/50]: Avg Loss: 0.1656 | Avg Accuracy: 88.35 | Model Sparsity: 0.95
Epoch [37/50]: Avg Loss: 0.1625 | Avg Accuracy: 88.67 | Model Sparsity: 0.95
Epoch [38/50]: Avg Loss: 0.1726 | Avg Accuracy: 87.93 | Model Sparsity: 0.95
