{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58a9ae51-88d5-4a44-9724-222fb310ae08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d864be54-f8b5-4448-b908-2f110b1e7fa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from bacp import BaCPTrainer, BaCPTrainingArguments\n",
    "from trainer import Trainer, TrainingArguments\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "disable_progress_bar()\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/dbfs/hf_datasets\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" \n",
    "\n",
    "from utils import *\n",
    "from constants import *\n",
    "\n",
    "device = get_device()\n",
    "print(f\"{device = }\")\n",
    "BATCH_SIZE_LLM = 64\n",
    "NUM_WORKERS = 24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22ccfbfc-6204-4ca3-b707-7ad645dcce8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Baseline Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14c0e00f-1cd4-4e81-9dc6-89b4a054ba6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SST-2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee2ea104-b28f-42f6-947b-b00728cb8415",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    model_name=\"roberta-base\",\n",
    "    model_task=\"sst2\",\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    epochs=3,\n",
    "    learning_type=\"baseline\",\n",
    "    optimizer_type=\"adamw\",\n",
    "    learning_rate=2e-5,\n",
    "    scheduler_type='linear_with_warmup'\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if False:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01eae47f-561a-4e7f-9cce-619ce45b4bd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## WikiText2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b6d30f8-d7b8-47aa-92c1-3726bdc67708",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    learning_rate=5e-5,\n",
    "    optimizer_type='adamw',\n",
    "    scheduler_type='linear_with_warmup',\n",
    "    epochs=50,\n",
    "    learning_type=\"baseline\",\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if False:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print('\\n', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7be69d1d-373f-4b12-a48d-9ab5140e1728",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Pruning Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6555eb17-e586-47bd-823d-494c738fb285",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SST-2 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d58a036-4334-44c0-823e-031ae7e08669",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Magnitude Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d98519d4-561a-4ecd-9fc3-9c5394efc5e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler=\"cubic\",\n",
    "\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='pruning',\n",
    ")\n",
    "\n",
    "trainer = Trainer(training_args=training_args)\n",
    "\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "acc = trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "defe99f3-fbdb-4502-b1a1-d11ce121da08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"./research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "# Initializing pruning method\n",
    "pruning_type = \"magnitude_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_MID\n",
    "\n",
    "training_args = LLMTrainingArguments(\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    sparsity_scheduler=\"cubic\",\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='pruning',\n",
    ")\n",
    "\n",
    "trainer = LLMTrainer(training_args=training_args)\n",
    "\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "acc = trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97ba3b50-f1da-447b-9cb2-909914a423a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"./research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "# Initializing pruning method\n",
    "pruning_type = \"magnitude_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_HIGH\n",
    "\n",
    "training_args = LLMTrainingArguments(\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    sparsity_scheduler=\"cubic\",\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='pruning',\n",
    ")\n",
    "\n",
    "trainer = LLMTrainer(training_args=training_args)\n",
    "\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "acc = trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4d1270a-6f28-4e85-8416-c473016644cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Movement Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab38d80e-18d7-4212-a829-d6d300d611cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"./research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "# Initializing pruning method\n",
    "pruning_type = \"movement_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_LOW\n",
    "\n",
    "training_args = LLMTrainingArguments(\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    sparsity_scheduler=\"cubic\",\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='pruning',\n",
    ")\n",
    "\n",
    "trainer = LLMTrainer(training_args=training_args)\n",
    "\n",
    "if False:\n",
    "    trainer.train()\n",
    "\n",
    "acc = trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d511df92-bbae-4f32-88be-368dab9b0d5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"./research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "# Initializing pruning method\n",
    "pruning_type = \"movement_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_MID\n",
    "\n",
    "training_args = LLMTrainingArguments(\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    sparsity_scheduler=\"cubic\",\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='pruning',\n",
    ")\n",
    "\n",
    "trainer = LLMTrainer(training_args=training_args)\n",
    "\n",
    "if False:\n",
    "    trainer.train()\n",
    "\n",
    "acc = trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44235e91-261e-4573-ba7a-e422171d8e37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"./research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "# Initializing pruning method\n",
    "pruning_type = \"movement_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_HIGH\n",
    "\n",
    "training_args = LLMTrainingArguments(\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    sparsity_scheduler=\"cubic\",\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='pruning',\n",
    ")\n",
    "\n",
    "trainer = LLMTrainer(training_args=training_args)\n",
    "\n",
    "if False:\n",
    "    trainer.train()\n",
    "\n",
    "acc = trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b8b53cd-9626-4b42-8655-6cfe9cf07194",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### WandA Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f4ffcd4-02dd-41d9-9870-36e12b20926f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"./research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "# Initializing pruning method\n",
    "pruning_type = \"wanda_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_LOW\n",
    "\n",
    "training_args = LLMTrainingArguments(\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    sparsity_scheduler=\"cubic\",\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='pruning',\n",
    ")\n",
    "\n",
    "trainer = LLMTrainer(training_args=training_args)\n",
    "\n",
    "if False:\n",
    "    trainer.train()\n",
    "\n",
    "acc = trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79cfef5e-ce9c-40e6-873f-05e90d5c2ee5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"./research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "# Initializing pruning method\n",
    "pruning_type = \"wanda_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_MID\n",
    "\n",
    "training_args = LLMTrainingArguments(\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    sparsity_scheduler=\"cubic\",\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='pruning',\n",
    ")\n",
    "\n",
    "trainer = LLMTrainer(training_args=training_args)\n",
    "\n",
    "if False:\n",
    "    trainer.train()\n",
    "\n",
    "acc = trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66a21b89-e8aa-4377-a402-7e1cd7f66155",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"./research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "# Initializing pruning method\n",
    "pruning_type = \"wanda_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_HIGH\n",
    "\n",
    "training_args = LLMTrainingArguments(\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    sparsity_scheduler=\"cubic\",\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='pruning',\n",
    ")\n",
    "\n",
    "trainer = LLMTrainer(training_args=training_args)\n",
    "\n",
    "if False:\n",
    "    trainer.train()\n",
    "\n",
    "acc = trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02bdcadd-f40f-4994-a4cd-7f159219ff4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## WikiText-2 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f45345a-28ce-49df-80ee-312319af142b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Magnitude Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9ed1b69-9c21-436d-85f3-8034015f51e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    learning_rate=5e-5,\n",
    "    optimizer_type=\"adamw\",\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    learning_type='pruning',\n",
    "    sparsity_scheduler='cubic',\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"\\n{metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4508881f-362f-4486-99e7-fbf1eda48998",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    learning_rate=5e-5,\n",
    "    optimizer_type=\"adamw\",\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    learning_type='pruning',\n",
    "    sparsity_scheduler='cubic',\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"\\n{metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b55bc463-47f5-4404-84ba-73796627d100",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    learning_rate=5e-5,\n",
    "    optimizer_type=\"adamw\",\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    learning_type='pruning',\n",
    "    sparsity_scheduler='cubic',\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"\\n{metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74cdab1e-9a35-457b-ab2b-8c3f5711e94a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Movement Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e9eae45-49c4-45e9-8f48-e69eb174c822",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    learning_rate=5e-5,\n",
    "    optimizer_type=\"adamw\",\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=\"movement_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    learning_type='pruning',\n",
    "    sparsity_scheduler='cubic',\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"\\n{metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12a2356f-dabc-462f-a988-beae479e7351",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    learning_rate=5e-5,\n",
    "    optimizer_type=\"adamw\",\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=\"movement_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    learning_type='pruning',\n",
    "    sparsity_scheduler='cubic',\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"\\n{metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9fd1dbe-a231-4ada-bf0d-26c16eb924d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    learning_rate=5e-5,\n",
    "    optimizer_type=\"adamw\",\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=\"movement_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    learning_type='pruning',\n",
    "    sparsity_scheduler='cubic',\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"\\n{metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a8170c7-5b3e-4240-941f-b76b2a9380bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### WandA Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59882a42-3d0d-47d1-89a8-9f7de192e3d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    learning_rate=5e-5,\n",
    "    optimizer_type=\"adamw\",\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=\"wanda_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    learning_type='pruning',\n",
    "    sparsity_scheduler='cubic',\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"\\n{metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fdeee07-3f3f-4593-a225-5ffbcacf3848",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    learning_rate=5e-5,\n",
    "    optimizer_type=\"adamw\",\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=\"wanda_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    learning_type='pruning',\n",
    "    sparsity_scheduler='cubic',\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"\\n{metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5879253e-32e2-4370-b38d-273e6e11f294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "\n",
    "# Loading trained weights\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    learning_rate=5e-5,\n",
    "    optimizer_type=\"adamw\",\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=\"wanda_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    learning_type='pruning',\n",
    "    sparsity_scheduler='cubic',\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"\\n{metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8747bf0e-75c0-4843-8ad7-071bbba5a572",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# BaCP Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c633c13-c4fd-49fd-8be6-96719c276692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SST-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1377dc7a-a6aa-4c85-8f45-936363972746",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Magnitude Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a92e160-d512-47e0-a0c7-ae8c50b6df8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArgumentsLLM(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    optimizer_type=\"adamw\",\n",
    "    learning_rate=1e-5,\n",
    "    )\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if False:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "pruner = bacp_trainer.get_pruner()\n",
    "\n",
    "llm_training_args = LLMTrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.cm_save_path,\n",
    "    epochs=3,\n",
    "    pruner=pruner,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\"\n",
    ")\n",
    "llm_trainer = LLMTrainer(llm_training_args)\n",
    "if False:\n",
    "    llm_trainer.train()\n",
    "\n",
    "acc = llm_trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e47be290-7787-4221-9b97-b4aeef5734f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pruning_type = \"magnitude_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_MID\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArgumentsLLM(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    learning_rate=1e-5,\n",
    "    )\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if False:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "pruner = bacp_trainer.get_pruner()\n",
    "\n",
    "llm_training_args = LLMTrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.cm_save_path,\n",
    "    epochs=3,\n",
    "    pruner=pruner,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\"\n",
    ")\n",
    "llm_trainer = LLMTrainer(llm_training_args)\n",
    "if False:\n",
    "    llm_trainer.train()\n",
    "\n",
    "acc = llm_trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b962ef97-9de7-41ca-96f7-9ec3f76bf65a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pruning_type = \"magnitude_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_HIGH\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArgumentsLLM(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    learning_rate=1e-5,\n",
    "    )\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if False:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "pruner = bacp_trainer.get_pruner()\n",
    "\n",
    "llm_training_args = LLMTrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.cm_save_path,\n",
    "    epochs=3,\n",
    "    pruner=pruner,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\"\n",
    ")\n",
    "llm_trainer = LLMTrainer(llm_training_args)\n",
    "if False:\n",
    "    llm_trainer.train()\n",
    "\n",
    "acc = llm_trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2de2502-7ee6-4605-8863-dd0a372deb79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Movement Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a26f4511-494a-4791-a159-de2542f7a834",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pruning_type = \"movement_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_LOW\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArgumentsLLM(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    learning_rate=1e-5,\n",
    "    )\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if False:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "pruner = bacp_trainer.get_pruner()\n",
    "\n",
    "llm_training_args = LLMTrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.cm_save_path,\n",
    "    epochs=3,\n",
    "    pruner=pruner,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\"\n",
    ")\n",
    "llm_trainer = LLMTrainer(llm_training_args)\n",
    "if False:\n",
    "    llm_trainer.train()\n",
    "\n",
    "acc = llm_trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e99f94d7-44b5-4dbe-8f94-02c47d3955ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pruning_type = \"movement_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_MID\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArgumentsLLM(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    learning_rate=1e-5,\n",
    "    )\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if False:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "pruner = bacp_trainer.get_pruner()\n",
    "\n",
    "llm_training_args = LLMTrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.cm_save_path,\n",
    "    epochs=3,\n",
    "    pruner=pruner,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\"\n",
    ")\n",
    "llm_trainer = LLMTrainer(llm_training_args)\n",
    "if False:\n",
    "    llm_trainer.train()\n",
    "\n",
    "acc = llm_trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f389e8a0-1966-4175-bb47-0e9d5dcb8bf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pruning_type = \"movement_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_HIGH\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArgumentsLLM(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    learning_rate=1e-5,\n",
    "    )\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if False:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "pruner = bacp_trainer.get_pruner()\n",
    "\n",
    "llm_training_args = LLMTrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.cm_save_path,\n",
    "    epochs=3,\n",
    "    pruner=pruner,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\"\n",
    ")\n",
    "llm_trainer = LLMTrainer(llm_training_args)\n",
    "if False:\n",
    "    llm_trainer.train()\n",
    "\n",
    "acc = llm_trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ed47df3-7300-495c-aa53-db45eae151d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Wanda Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d5b9914-fb71-4e73-a33b-dea46e2f3b57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pruning_type = \"wanda_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_LOW\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArgumentsLLM(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    learning_rate=1e-5,\n",
    "    )\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if False:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "pruner = bacp_trainer.get_pruner()\n",
    "\n",
    "llm_training_args = LLMTrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.cm_save_path,\n",
    "    epochs=3,\n",
    "    pruner=pruner,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\"\n",
    ")\n",
    "llm_trainer = LLMTrainer(llm_training_args)\n",
    "if False:\n",
    "    llm_trainer.train()\n",
    "\n",
    "acc = llm_trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3ffae43-49c6-4f13-b214-7683aa9437e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pruning_type = \"wanda_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_MID\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArgumentsLLM(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    learning_rate=1e-5,\n",
    "    )\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if False:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "pruner = bacp_trainer.get_pruner()\n",
    "\n",
    "llm_training_args = LLMTrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.cm_save_path,\n",
    "    epochs=3,\n",
    "    pruner=pruner,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\"\n",
    ")\n",
    "llm_trainer = LLMTrainer(llm_training_args)\n",
    "if False:\n",
    "    llm_trainer.train()\n",
    "\n",
    "acc = llm_trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5c888ec-97f9-4943-9474-4ef2abfcb87e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pruning_type = \"wanda_pruning\"\n",
    "target_sparsity = TARGET_SPARSITY_HIGH\n",
    "model_name = \"roberta-base\"\n",
    "model_task = \"sst2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArgumentsLLM(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_DISTILBERT,\n",
    "    finetuned_weights=trained_model_path,\n",
    "    pruning_type=pruning_type,\n",
    "    target_sparsity=target_sparsity,\n",
    "    learning_rate=1e-5,\n",
    "    )\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if False:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "pruner = bacp_trainer.get_pruner()\n",
    "\n",
    "llm_training_args = LLMTrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.cm_save_path,\n",
    "    epochs=3,\n",
    "    pruner=pruner,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\"\n",
    ")\n",
    "llm_trainer = LLMTrainer(llm_training_args)\n",
    "if False:\n",
    "    llm_trainer.train()\n",
    "\n",
    "acc = llm_trainer.evaluate()\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4559899-5e66-4e98-b1c1-48c59858ef2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## WikiText2 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "073229e0-1837-4576-a200-309872a4d2b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Magnitude Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27c84529-3b5f-4006-afd4-88ea5b73cbeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='bacp_pruning',\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if True:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    epochs=50,\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f2955fd-8f6f-4a5e-90e7-6ef2c222fd66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='bacp_pruning',\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if True:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    epochs=50,\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55037054-3406-451e-9bde-47e75fb44708",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='bacp_pruning',\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if True:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    epochs=50,\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f68b8f4-dae2-4be6-bb9a-2e7f13a602fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Movement Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9e815a5-6431-4f33-9408-5032e8721d93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=\"movement_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='bacp_pruning',\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if True:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    epochs=50,\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c30e565-76c6-4e5e-99fa-b9e7db82cc25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=\"movement_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='bacp_pruning',\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if True:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    epochs=50,\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd60722e-e4ed-4b03-b106-9cee7716e63c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=\"movement_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='bacp_pruning',\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if True:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    epochs=50,\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6fb654b-e1a0-4ec5-855b-0f3d97bc115d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### WandA Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b7ed701-d84a-405f-8e18-c521b622050e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=\"wanda_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='bacp_pruning',\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if True:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    epochs=50,\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec730ac3-9fa7-460d-b919-80aeed41646e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=\"wanda_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='bacp_pruning',\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if True:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    epochs=50,\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87a3bf2c-ce4c-4838-aee8-4e59344e2713",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model_task = \"wikitext2\"\n",
    "trained_model_path = f\"/dbfs/research/{model_name}/{model_task}/{model_name}_{model_task}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=BATCH_SIZE_LLM,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=\"wanda_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=trained_model_path,\n",
    "    learning_type='bacp_pruning',\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "if True:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type='adamw',\n",
    "    learning_rate=1e-3,\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    epochs=50,\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6215900699327041,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "RoBERTa_test_v2",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
