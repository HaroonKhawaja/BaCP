Model : distilbert-base-uncased - Learning Type: sst2/bacp_pruning/movement_pruning/0.99
Configuration:
model_name: distilbert-base-uncased
model_task: sst2
model_type: llm
num_classes: 2
batch_size: 64
learning_rate: 1e-05
optimizer_type: adamw
epochs: 1
recovery_epochs: 0
patience: 20
pruning_type: movement_pruning
target_sparsity: 0.99
sparsity_scheduler: cubic
pruning_epochs: 1
n_views: 2
temperature: 0.15
base_temperature: 0.15
device: cuda
enable_mixed_precision: True
num_workers: 24
train_batches: 1052
val_batches: 13
current_model_path: /dbfs/research/distilbert-base-uncased/sst2/distilbert-base-uncased_sst2_movement_pruning_0.99_bacp_pruning.pt

Epoch [1/1]: Avg Total Loss: 6.2262 | Avg PrC Loss: 2.5520 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 3.5023 | Avg CE Loss: 0.1719 | Model Sparsity: 0.99
