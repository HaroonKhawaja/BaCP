Model : distilbert-base-uncased - Learning Type: sst2/pruning/wanda_pruning/0.95
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: sst2
num_classes: 2
criterion: CrossEntropyLoss()
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 1e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: wanda_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/sst2/distilbert-base-uncased_sst2_wanda_pruning_0.95_pruning.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/sst2/distilbert-base-uncased_sst2_baseline.pt

Epoch [1/5]: Avg Loss: 0.0708 | Avg Accuracy: 89.18 | Model Sparsity: 0.4636
Recovery epoch [1/10]: Avg Loss: 0.0543 | Avg Accuracy: 88.94 | Model Sparsity: 0.4636
Recovery epoch [2/10]: Avg Loss: 0.0438 | Avg Accuracy: 88.94 | Model Sparsity: 0.4636
Recovery epoch [3/10]: Avg Loss: 0.0361 | Avg Accuracy: 89.30 | Model Sparsity: 0.4636
Recovery epoch [4/10]: Avg Loss: 0.0297 | Avg Accuracy: 90.02 | Model Sparsity: 0.4636
Recovery epoch [5/10]: Avg Loss: 0.0257 | Avg Accuracy: 89.42 | Model Sparsity: 0.4636
Recovery epoch [6/10]: Avg Loss: 0.0223 | Avg Accuracy: 89.06 | Model Sparsity: 0.4636
Recovery epoch [7/10]: Avg Loss: 0.0200 | Avg Accuracy: 89.06 | Model Sparsity: 0.4636
Recovery epoch [8/10]: Avg Loss: 0.0173 | Avg Accuracy: 89.18 | Model Sparsity: 0.4636
Recovery epoch [9/10]: Avg Loss: 0.0159 | Avg Accuracy: 88.46 | Model Sparsity: 0.4636
Recovery epoch [10/10]: Avg Loss: 0.0137 | Avg Accuracy: 88.22 | Model Sparsity: 0.4636
Epoch [2/5]: Avg Loss: 0.1629 | Avg Accuracy: 86.66 | Model Sparsity: 0.7448
Recovery epoch [1/10]: Avg Loss: 0.0963 | Avg Accuracy: 86.90 | Model Sparsity: 0.7448
Recovery epoch [2/10]: Avg Loss: 0.0694 | Avg Accuracy: 87.38 | Model Sparsity: 0.7448
Recovery epoch [3/10]: Avg Loss: 0.0557 | Avg Accuracy: 87.62 | Model Sparsity: 0.7448
Recovery epoch [4/10]: Avg Loss: 0.0452 | Avg Accuracy: 87.02 | Model Sparsity: 0.7448
Recovery epoch [5/10]: Avg Loss: 0.0405 | Avg Accuracy: 87.26 | Model Sparsity: 0.7448
Recovery epoch [6/10]: Avg Loss: 0.0360 | Avg Accuracy: 87.38 | Model Sparsity: 0.7448
Recovery epoch [7/10]: Avg Loss: 0.0311 | Avg Accuracy: 87.38 | Model Sparsity: 0.7448
Recovery epoch [8/10]: Avg Loss: 0.0282 | Avg Accuracy: 87.50 | Model Sparsity: 0.7448
Recovery epoch [9/10]: Avg Loss: 0.0250 | Avg Accuracy: 88.10 | Model Sparsity: 0.7448
Recovery epoch [10/10]: Avg Loss: 0.0241 | Avg Accuracy: 87.74 | Model Sparsity: 0.7448
Epoch [3/5]: Avg Loss: 0.2259 | Avg Accuracy: 82.81 | Model Sparsity: 0.8892
Recovery epoch [1/10]: Avg Loss: 0.1569 | Avg Accuracy: 84.25 | Model Sparsity: 0.8892
Recovery epoch [2/10]: Avg Loss: 0.1319 | Avg Accuracy: 84.38 | Model Sparsity: 0.8892
Recovery epoch [3/10]: Avg Loss: 0.1139 | Avg Accuracy: 83.77 | Model Sparsity: 0.8892
Recovery epoch [4/10]: Avg Loss: 0.1003 | Avg Accuracy: 83.89 | Model Sparsity: 0.8892
Recovery epoch [5/10]: Avg Loss: 0.0898 | Avg Accuracy: 84.38 | Model Sparsity: 0.8892
Recovery epoch [6/10]: Avg Loss: 0.0820 | Avg Accuracy: 82.21 | Model Sparsity: 0.8892
Recovery epoch [7/10]: Avg Loss: 0.0750 | Avg Accuracy: 83.65 | Model Sparsity: 0.8892
Recovery epoch [8/10]: Avg Loss: 0.0683 | Avg Accuracy: 84.38 | Model Sparsity: 0.8892
Recovery epoch [9/10]: Avg Loss: 0.0633 | Avg Accuracy: 83.29 | Model Sparsity: 0.8892
Recovery epoch [10/10]: Avg Loss: 0.0583 | Avg Accuracy: 85.10 | Model Sparsity: 0.8892
Epoch [4/5]: Avg Loss: 0.1879 | Avg Accuracy: 81.25 | Model Sparsity: 0.9424
Recovery epoch [1/10]: Avg Loss: 0.1316 | Avg Accuracy: 81.73 | Model Sparsity: 0.9424
Recovery epoch [2/10]: Avg Loss: 0.1136 | Avg Accuracy: 81.73 | Model Sparsity: 0.9424
Recovery epoch [3/10]: Avg Loss: 0.1019 | Avg Accuracy: 81.97 | Model Sparsity: 0.9424
Recovery epoch [4/10]: Avg Loss: 0.0926 | Avg Accuracy: 81.61 | Model Sparsity: 0.9424
Recovery epoch [5/10]: Avg Loss: 0.0870 | Avg Accuracy: 81.49 | Model Sparsity: 0.9424
Recovery epoch [6/10]: Avg Loss: 0.0836 | Avg Accuracy: 81.13 | Model Sparsity: 0.9424
Recovery epoch [7/10]: Avg Loss: 0.0778 | Avg Accuracy: 81.25 | Model Sparsity: 0.9424
Recovery epoch [8/10]: Avg Loss: 0.0729 | Avg Accuracy: 81.61 | Model Sparsity: 0.9424
Recovery epoch [9/10]: Avg Loss: 0.0691 | Avg Accuracy: 81.61 | Model Sparsity: 0.9424
Recovery epoch [10/10]: Avg Loss: 0.0656 | Avg Accuracy: 81.73 | Model Sparsity: 0.9424
Epoch [5/5]: Avg Loss: 0.0805 | Avg Accuracy: 81.73 | Model Sparsity: 0.95
Recovery epoch [1/10]: Avg Loss: 0.0652 | Avg Accuracy: 81.85 | Model Sparsity: 0.95
Recovery epoch [2/10]: Avg Loss: 0.0605 | Avg Accuracy: 81.49 | Model Sparsity: 0.95
Recovery epoch [3/10]: Avg Loss: 0.0580 | Avg Accuracy: 81.61 | Model Sparsity: 0.95
Recovery epoch [4/10]: Avg Loss: 0.0530 | Avg Accuracy: 81.73 | Model Sparsity: 0.95
Recovery epoch [5/10]: Avg Loss: 0.0511 | Avg Accuracy: 81.49 | Model Sparsity: 0.95
Recovery epoch [6/10]: Avg Loss: 0.0482 | Avg Accuracy: 81.01 | Model Sparsity: 0.95
Recovery epoch [7/10]: Avg Loss: 0.0465 | Avg Accuracy: 81.73 | Model Sparsity: 0.95
Recovery epoch [8/10]: Avg Loss: 0.0452 | Avg Accuracy: 81.97 | Model Sparsity: 0.95
Recovery epoch [9/10]: Avg Loss: 0.0444 | Avg Accuracy: 81.13 | Model Sparsity: 0.95
Recovery epoch [10/10]: Avg Loss: 0.0422 | Avg Accuracy: 81.13 | Model Sparsity: 0.95
