Model : distilbert-base-uncased - Learning Type: sst2/pruning/magnitude_pruning/0.97
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: sst2
num_classes: 2
criterion: CrossEntropyLoss()
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 1e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.97
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/sst2/distilbert-base-uncased_sst2_magnitude_pruning_0.97_pruning.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/sst2/distilbert-base-uncased_sst2_baseline.pt

Epoch [1/5]: Avg Loss: 0.0764 | Avg Accuracy: 89.78 | Model Sparsity: 0.4734
Recovery epoch [1/10]: Avg Loss: 0.0563 | Avg Accuracy: 89.66 | Model Sparsity: 0.4734
Recovery epoch [2/10]: Avg Loss: 0.0466 | Avg Accuracy: 90.02 | Model Sparsity: 0.4734
Recovery epoch [3/10]: Avg Loss: 0.0397 | Avg Accuracy: 90.38 | Model Sparsity: 0.4734
Recovery epoch [4/10]: Avg Loss: 0.0328 | Avg Accuracy: 90.75 | Model Sparsity: 0.4734
Recovery epoch [5/10]: Avg Loss: 0.0279 | Avg Accuracy: 88.46 | Model Sparsity: 0.4734
Recovery epoch [6/10]: Avg Loss: 0.0241 | Avg Accuracy: 89.66 | Model Sparsity: 0.4734
Recovery epoch [7/10]: Avg Loss: 0.0218 | Avg Accuracy: 88.94 | Model Sparsity: 0.4734
Recovery epoch [8/10]: Avg Loss: 0.0181 | Avg Accuracy: 89.06 | Model Sparsity: 0.4734
Recovery epoch [9/10]: Avg Loss: 0.0165 | Avg Accuracy: 89.66 | Model Sparsity: 0.4734
Recovery epoch [10/10]: Avg Loss: 0.0160 | Avg Accuracy: 89.66 | Model Sparsity: 0.4734
Epoch [2/5]: Avg Loss: 0.1929 | Avg Accuracy: 84.38 | Model Sparsity: 0.7605
Recovery epoch [1/10]: Avg Loss: 0.1197 | Avg Accuracy: 86.06 | Model Sparsity: 0.7605
Recovery epoch [2/10]: Avg Loss: 0.0922 | Avg Accuracy: 86.30 | Model Sparsity: 0.7605
Recovery epoch [3/10]: Avg Loss: 0.0736 | Avg Accuracy: 86.66 | Model Sparsity: 0.7605
Recovery epoch [4/10]: Avg Loss: 0.0596 | Avg Accuracy: 87.14 | Model Sparsity: 0.7605
Recovery epoch [5/10]: Avg Loss: 0.0525 | Avg Accuracy: 87.26 | Model Sparsity: 0.7605
Recovery epoch [6/10]: Avg Loss: 0.0463 | Avg Accuracy: 87.86 | Model Sparsity: 0.7605
Recovery epoch [7/10]: Avg Loss: 0.0392 | Avg Accuracy: 87.50 | Model Sparsity: 0.7605
Recovery epoch [8/10]: Avg Loss: 0.0365 | Avg Accuracy: 88.10 | Model Sparsity: 0.7605
Recovery epoch [9/10]: Avg Loss: 0.0326 | Avg Accuracy: 87.38 | Model Sparsity: 0.7605
Recovery epoch [10/10]: Avg Loss: 0.0300 | Avg Accuracy: 87.38 | Model Sparsity: 0.7605
Epoch [3/5]: Avg Loss: 0.2499 | Avg Accuracy: 83.65 | Model Sparsity: 0.9079
Recovery epoch [1/10]: Avg Loss: 0.1772 | Avg Accuracy: 83.89 | Model Sparsity: 0.9079
Recovery epoch [2/10]: Avg Loss: 0.1487 | Avg Accuracy: 84.50 | Model Sparsity: 0.9079
Recovery epoch [3/10]: Avg Loss: 0.1288 | Avg Accuracy: 83.89 | Model Sparsity: 0.9079
Recovery epoch [4/10]: Avg Loss: 0.1149 | Avg Accuracy: 84.01 | Model Sparsity: 0.9079
Recovery epoch [5/10]: Avg Loss: 0.1037 | Avg Accuracy: 82.93 | Model Sparsity: 0.9079
Recovery epoch [6/10]: Avg Loss: 0.0957 | Avg Accuracy: 84.13 | Model Sparsity: 0.9079
Recovery epoch [7/10]: Avg Loss: 0.0878 | Avg Accuracy: 83.29 | Model Sparsity: 0.9079
Recovery epoch [8/10]: Avg Loss: 0.0811 | Avg Accuracy: 83.53 | Model Sparsity: 0.9079
Recovery epoch [9/10]: Avg Loss: 0.0762 | Avg Accuracy: 83.77 | Model Sparsity: 0.9079
Recovery epoch [10/10]: Avg Loss: 0.0692 | Avg Accuracy: 84.13 | Model Sparsity: 0.9079
Epoch [4/5]: Avg Loss: 0.2241 | Avg Accuracy: 81.49 | Model Sparsity: 0.9622
Recovery epoch [1/10]: Avg Loss: 0.1580 | Avg Accuracy: 80.89 | Model Sparsity: 0.9622
Recovery epoch [2/10]: Avg Loss: 0.1369 | Avg Accuracy: 81.73 | Model Sparsity: 0.9622
Recovery epoch [3/10]: Avg Loss: 0.1230 | Avg Accuracy: 81.61 | Model Sparsity: 0.9622
Recovery epoch [4/10]: Avg Loss: 0.1130 | Avg Accuracy: 82.21 | Model Sparsity: 0.9622
Recovery epoch [5/10]: Avg Loss: 0.1047 | Avg Accuracy: 82.33 | Model Sparsity: 0.9622
Recovery epoch [6/10]: Avg Loss: 0.0992 | Avg Accuracy: 82.21 | Model Sparsity: 0.9622
Recovery epoch [7/10]: Avg Loss: 0.0932 | Avg Accuracy: 81.73 | Model Sparsity: 0.9622
Recovery epoch [8/10]: Avg Loss: 0.0896 | Avg Accuracy: 81.97 | Model Sparsity: 0.9622
Recovery epoch [9/10]: Avg Loss: 0.0830 | Avg Accuracy: 81.37 | Model Sparsity: 0.9622
Recovery epoch [10/10]: Avg Loss: 0.0785 | Avg Accuracy: 81.61 | Model Sparsity: 0.9622
Epoch [5/5]: Avg Loss: 0.1182 | Avg Accuracy: 80.65 | Model Sparsity: 0.97
Recovery epoch [1/10]: Avg Loss: 0.0846 | Avg Accuracy: 80.29 | Model Sparsity: 0.97
Recovery epoch [2/10]: Avg Loss: 0.0755 | Avg Accuracy: 80.89 | Model Sparsity: 0.97
Recovery epoch [3/10]: Avg Loss: 0.0711 | Avg Accuracy: 81.25 | Model Sparsity: 0.97
Recovery epoch [4/10]: Avg Loss: 0.0674 | Avg Accuracy: 81.01 | Model Sparsity: 0.97
Recovery epoch [5/10]: Avg Loss: 0.0642 | Avg Accuracy: 81.01 | Model Sparsity: 0.97
Recovery epoch [6/10]: Avg Loss: 0.0622 | Avg Accuracy: 79.93 | Model Sparsity: 0.97
Recovery epoch [7/10]: Avg Loss: 0.0593 | Avg Accuracy: 81.01 | Model Sparsity: 0.97
Recovery epoch [8/10]: Avg Loss: 0.0553 | Avg Accuracy: 80.65 | Model Sparsity: 0.97
Recovery epoch [9/10]: Avg Loss: 0.0541 | Avg Accuracy: 80.17 | Model Sparsity: 0.97
Recovery epoch [10/10]: Avg Loss: 0.0520 | Avg Accuracy: 80.29 | Model Sparsity: 0.97
