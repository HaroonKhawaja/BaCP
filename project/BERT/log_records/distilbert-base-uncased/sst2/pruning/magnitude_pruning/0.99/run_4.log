Model : distilbert-base-uncased - Learning Type: sst2/pruning/magnitude_pruning/0.99
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: sst2
num_classes: 2
criterion: CrossEntropyLoss()
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 1e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.99
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/sst2/distilbert-base-uncased_sst2_magnitude_pruning_0.99_pruning.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/sst2/distilbert-base-uncased_sst2_baseline.pt

Epoch [1/5]: Avg Loss: 0.0780 | Avg Accuracy: 89.78 | Model Sparsity: 0.4831
Recovery epoch [1/10]: Avg Loss: 0.0584 | Avg Accuracy: 89.06 | Model Sparsity: 0.4831
Recovery epoch [2/10]: Avg Loss: 0.0476 | Avg Accuracy: 89.18 | Model Sparsity: 0.4831
Recovery epoch [3/10]: Avg Loss: 0.0404 | Avg Accuracy: 89.18 | Model Sparsity: 0.4831
Recovery epoch [4/10]: Avg Loss: 0.0329 | Avg Accuracy: 89.18 | Model Sparsity: 0.4831
Recovery epoch [5/10]: Avg Loss: 0.0292 | Avg Accuracy: 89.66 | Model Sparsity: 0.4831
Recovery epoch [6/10]: Avg Loss: 0.0248 | Avg Accuracy: 89.66 | Model Sparsity: 0.4831
Recovery epoch [7/10]: Avg Loss: 0.0226 | Avg Accuracy: 89.18 | Model Sparsity: 0.4831
Recovery epoch [8/10]: Avg Loss: 0.0186 | Avg Accuracy: 89.66 | Model Sparsity: 0.4831
Recovery epoch [9/10]: Avg Loss: 0.0172 | Avg Accuracy: 89.06 | Model Sparsity: 0.4831
Recovery epoch [10/10]: Avg Loss: 0.0152 | Avg Accuracy: 89.66 | Model Sparsity: 0.4831
Epoch [2/5]: Avg Loss: 0.2091 | Avg Accuracy: 84.98 | Model Sparsity: 0.7762
Recovery epoch [1/10]: Avg Loss: 0.1322 | Avg Accuracy: 86.18 | Model Sparsity: 0.7762
Recovery epoch [2/10]: Avg Loss: 0.1026 | Avg Accuracy: 87.14 | Model Sparsity: 0.7762
Recovery epoch [3/10]: Avg Loss: 0.0817 | Avg Accuracy: 86.66 | Model Sparsity: 0.7762
Recovery epoch [4/10]: Avg Loss: 0.0702 | Avg Accuracy: 87.02 | Model Sparsity: 0.7762
Recovery epoch [5/10]: Avg Loss: 0.0605 | Avg Accuracy: 87.14 | Model Sparsity: 0.7762
Recovery epoch [6/10]: Avg Loss: 0.0514 | Avg Accuracy: 86.66 | Model Sparsity: 0.7762
Recovery epoch [7/10]: Avg Loss: 0.0456 | Avg Accuracy: 88.10 | Model Sparsity: 0.7762
Recovery epoch [8/10]: Avg Loss: 0.0410 | Avg Accuracy: 87.50 | Model Sparsity: 0.7762
Recovery epoch [9/10]: Avg Loss: 0.0355 | Avg Accuracy: 86.90 | Model Sparsity: 0.7762
Recovery epoch [10/10]: Avg Loss: 0.0326 | Avg Accuracy: 86.54 | Model Sparsity: 0.7762
Epoch [3/5]: Avg Loss: 0.2891 | Avg Accuracy: 81.73 | Model Sparsity: 0.9266
Recovery epoch [1/10]: Avg Loss: 0.2098 | Avg Accuracy: 83.05 | Model Sparsity: 0.9266
Recovery epoch [2/10]: Avg Loss: 0.1799 | Avg Accuracy: 83.05 | Model Sparsity: 0.9266
Recovery epoch [3/10]: Avg Loss: 0.1595 | Avg Accuracy: 83.77 | Model Sparsity: 0.9266
Recovery epoch [4/10]: Avg Loss: 0.1422 | Avg Accuracy: 83.17 | Model Sparsity: 0.9266
Recovery epoch [5/10]: Avg Loss: 0.1314 | Avg Accuracy: 83.17 | Model Sparsity: 0.9266
Recovery epoch [6/10]: Avg Loss: 0.1200 | Avg Accuracy: 82.93 | Model Sparsity: 0.9266
Recovery epoch [7/10]: Avg Loss: 0.1098 | Avg Accuracy: 82.93 | Model Sparsity: 0.9266
Recovery epoch [8/10]: Avg Loss: 0.1031 | Avg Accuracy: 82.57 | Model Sparsity: 0.9266
Recovery epoch [9/10]: Avg Loss: 0.0951 | Avg Accuracy: 82.21 | Model Sparsity: 0.9266
Recovery epoch [10/10]: Avg Loss: 0.0900 | Avg Accuracy: 82.09 | Model Sparsity: 0.9266
Epoch [4/5]: Avg Loss: 0.3292 | Avg Accuracy: 81.25 | Model Sparsity: 0.9821
Recovery epoch [1/10]: Avg Loss: 0.2378 | Avg Accuracy: 81.01 | Model Sparsity: 0.9821
Recovery epoch [2/10]: Avg Loss: 0.2115 | Avg Accuracy: 80.29 | Model Sparsity: 0.9821
Recovery epoch [3/10]: Avg Loss: 0.1907 | Avg Accuracy: 80.05 | Model Sparsity: 0.9821
Recovery epoch [4/10]: Avg Loss: 0.1740 | Avg Accuracy: 80.41 | Model Sparsity: 0.9821
Recovery epoch [5/10]: Avg Loss: 0.1608 | Avg Accuracy: 80.17 | Model Sparsity: 0.9821
Recovery epoch [6/10]: Avg Loss: 0.1520 | Avg Accuracy: 80.41 | Model Sparsity: 0.9821
Recovery epoch [7/10]: Avg Loss: 0.1446 | Avg Accuracy: 80.05 | Model Sparsity: 0.9821
Recovery epoch [8/10]: Avg Loss: 0.1382 | Avg Accuracy: 80.29 | Model Sparsity: 0.9821
Recovery epoch [9/10]: Avg Loss: 0.1320 | Avg Accuracy: 79.81 | Model Sparsity: 0.9821
Recovery epoch [10/10]: Avg Loss: 0.1267 | Avg Accuracy: 79.81 | Model Sparsity: 0.9821
Epoch [5/5]: Avg Loss: 0.1480 | Avg Accuracy: 80.53 | Model Sparsity: 0.99
Recovery epoch [1/10]: Avg Loss: 0.1317 | Avg Accuracy: 80.53 | Model Sparsity: 0.99
Recovery epoch [2/10]: Avg Loss: 0.1239 | Avg Accuracy: 80.05 | Model Sparsity: 0.99
Recovery epoch [3/10]: Avg Loss: 0.1178 | Avg Accuracy: 80.17 | Model Sparsity: 0.99
Recovery epoch [4/10]: Avg Loss: 0.1133 | Avg Accuracy: 79.69 | Model Sparsity: 0.99
Recovery epoch [5/10]: Avg Loss: 0.1107 | Avg Accuracy: 80.53 | Model Sparsity: 0.99
Recovery epoch [6/10]: Avg Loss: 0.1074 | Avg Accuracy: 79.33 | Model Sparsity: 0.99
Recovery epoch [7/10]: Avg Loss: 0.1024 | Avg Accuracy: 80.05 | Model Sparsity: 0.99
Recovery epoch [8/10]: Avg Loss: 0.1014 | Avg Accuracy: 79.21 | Model Sparsity: 0.99
Recovery epoch [9/10]: Avg Loss: 0.0973 | Avg Accuracy: 79.09 | Model Sparsity: 0.99
Recovery epoch [10/10]: Avg Loss: 0.0941 | Avg Accuracy: 78.61 | Model Sparsity: 0.99
