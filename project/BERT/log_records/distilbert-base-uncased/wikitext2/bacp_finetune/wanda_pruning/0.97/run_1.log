Model : distilbert-base-uncased - Learning Type: wikitext2/bacp_finetune/wanda_pruning/0.97
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: wikitext2
num_classes: 30522
embedding_dim: 768
epochs: 50
pruning_epochs: 50
recovery_epochs: 10
batch_size: 64
learning_rate: 0.001
learning_type: bacp_finetune
optimizer_type: adamw
prune: False
pruning_type: wanda_pruning
target_sparsity: 0.97
sparsity_scheduler: linear
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_wanda_pruning_0.97_bacp_finetune.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_wanda_pruning_0.97_bacp_pruning.pt

Epoch [1/50]: Avg Loss: 3.9596 | Avg Accuracy: 42.66 | Model Sparsity: 0.97
Epoch [2/50]: Avg Loss: 3.2063 | Avg Accuracy: 43.65 | Model Sparsity: 0.97
Epoch [3/50]: Avg Loss: 3.0461 | Avg Accuracy: 44.76 | Model Sparsity: 0.97
Epoch [4/50]: Avg Loss: 2.9540 | Avg Accuracy: 44.92 | Model Sparsity: 0.97
Epoch [5/50]: Avg Loss: 2.8785 | Avg Accuracy: 45.30 | Model Sparsity: 0.97
Epoch [6/50]: Avg Loss: 2.8223 | Avg Accuracy: 45.72 | Model Sparsity: 0.97
Epoch [7/50]: Avg Loss: 2.7556 | Avg Accuracy: 46.11 | Model Sparsity: 0.97
Epoch [8/50]: Avg Loss: 2.6902 | Avg Accuracy: 45.69 | Model Sparsity: 0.97
Epoch [9/50]: Avg Loss: 2.6562 | Avg Accuracy: 46.14 | Model Sparsity: 0.97
Epoch [10/50]: Avg Loss: 2.6215 | Avg Accuracy: 46.30 | Model Sparsity: 0.97
Epoch [11/50]: Avg Loss: 2.5834 | Avg Accuracy: 46.30 | Model Sparsity: 0.97
Epoch [12/50]: Avg Loss: 2.5545 | Avg Accuracy: 46.03 | Model Sparsity: 0.97
Epoch [13/50]: Avg Loss: 2.5141 | Avg Accuracy: 45.86 | Model Sparsity: 0.97
Epoch [14/50]: Avg Loss: 2.4860 | Avg Accuracy: 46.63 | Model Sparsity: 0.97
Epoch [15/50]: Avg Loss: 2.4512 | Avg Accuracy: 45.73 | Model Sparsity: 0.97
Epoch [16/50]: Avg Loss: 2.4260 | Avg Accuracy: 46.70 | Model Sparsity: 0.97
Epoch [17/50]: Avg Loss: 2.4077 | Avg Accuracy: 45.93 | Model Sparsity: 0.97
Epoch [18/50]: Avg Loss: 2.3855 | Avg Accuracy: 46.21 | Model Sparsity: 0.97
Epoch [19/50]: Avg Loss: 2.3593 | Avg Accuracy: 46.59 | Model Sparsity: 0.97
Epoch [20/50]: Avg Loss: 2.3343 | Avg Accuracy: 47.05 | Model Sparsity: 0.97
Epoch [21/50]: Avg Loss: 2.3168 | Avg Accuracy: 46.61 | Model Sparsity: 0.97
Epoch [22/50]: Avg Loss: 2.2909 | Avg Accuracy: 46.38 | Model Sparsity: 0.97
Epoch [23/50]: Avg Loss: 2.2816 | Avg Accuracy: 46.27 | Model Sparsity: 0.97
Epoch [24/50]: Avg Loss: 2.2569 | Avg Accuracy: 46.22 | Model Sparsity: 0.97
Epoch [25/50]: Avg Loss: 2.2380 | Avg Accuracy: 45.91 | Model Sparsity: 0.97
Epoch [26/50]: Avg Loss: 2.2175 | Avg Accuracy: 46.83 | Model Sparsity: 0.97
Epoch [27/50]: Avg Loss: 2.2015 | Avg Accuracy: 46.09 | Model Sparsity: 0.97
Epoch [28/50]: Avg Loss: 2.1871 | Avg Accuracy: 46.35 | Model Sparsity: 0.97
Epoch [29/50]: Avg Loss: 2.1691 | Avg Accuracy: 46.37 | Model Sparsity: 0.97
Epoch [30/50]: Avg Loss: 2.1593 | Avg Accuracy: 46.50 | Model Sparsity: 0.97
Epoch [31/50]: Avg Loss: 2.1369 | Avg Accuracy: 46.16 | Model Sparsity: 0.97
Epoch [32/50]: Avg Loss: 2.1307 | Avg Accuracy: 46.35 | Model Sparsity: 0.97
Epoch [33/50]: Avg Loss: 2.1079 | Avg Accuracy: 46.62 | Model Sparsity: 0.97
Epoch [34/50]: Avg Loss: 2.0991 | Avg Accuracy: 46.27 | Model Sparsity: 0.97
Epoch [35/50]: Avg Loss: 2.0860 | Avg Accuracy: 46.73 | Model Sparsity: 0.97
Epoch [36/50]: Avg Loss: 2.0654 | Avg Accuracy: 46.17 | Model Sparsity: 0.97
Epoch [37/50]: Avg Loss: 2.0558 | Avg Accuracy: 46.43 | Model Sparsity: 0.97
Epoch [38/50]: Avg Loss: 2.0474 | Avg Accuracy: 46.57 | Model Sparsity: 0.97
Epoch [39/50]: Avg Loss: 2.0277 | Avg Accuracy: 46.34 | Model Sparsity: 0.97
Epoch [40/50]: Avg Loss: 2.0227 | Avg Accuracy: 46.73 | Model Sparsity: 0.97
