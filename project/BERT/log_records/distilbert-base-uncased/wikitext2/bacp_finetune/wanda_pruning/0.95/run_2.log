Model : distilbert-base-uncased - Learning Type: wikitext2/bacp_finetune/wanda_pruning/0.95
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: wikitext2
num_classes: 30522
embedding_dim: 768
epochs: 50
pruning_epochs: 50
recovery_epochs: 10
batch_size: 64
learning_rate: 0.001
learning_type: bacp_finetune
optimizer_type: adamw
prune: False
pruning_type: wanda_pruning
target_sparsity: 0.95
sparsity_scheduler: linear
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_wanda_pruning_0.95_bacp_finetune.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_wanda_pruning_0.95_bacp_pruning.pt

Epoch [1/50]: Avg Loss: 3.6388 | Avg Accuracy: 45.45 | Model Sparsity: 0.95
Epoch [2/50]: Avg Loss: 2.9289 | Avg Accuracy: 47.04 | Model Sparsity: 0.95
Epoch [3/50]: Avg Loss: 2.8089 | Avg Accuracy: 47.25 | Model Sparsity: 0.95
Epoch [4/50]: Avg Loss: 2.7140 | Avg Accuracy: 47.85 | Model Sparsity: 0.95
Epoch [5/50]: Avg Loss: 2.6486 | Avg Accuracy: 47.44 | Model Sparsity: 0.95
Epoch [6/50]: Avg Loss: 2.5885 | Avg Accuracy: 48.38 | Model Sparsity: 0.95
Epoch [7/50]: Avg Loss: 2.5359 | Avg Accuracy: 47.99 | Model Sparsity: 0.95
Epoch [8/50]: Avg Loss: 2.4931 | Avg Accuracy: 48.43 | Model Sparsity: 0.95
Epoch [9/50]: Avg Loss: 2.4598 | Avg Accuracy: 48.34 | Model Sparsity: 0.95
Epoch [10/50]: Avg Loss: 2.4097 | Avg Accuracy: 48.76 | Model Sparsity: 0.95
Epoch [11/50]: Avg Loss: 2.3866 | Avg Accuracy: 48.04 | Model Sparsity: 0.95
Epoch [12/50]: Avg Loss: 2.3515 | Avg Accuracy: 48.66 | Model Sparsity: 0.95
Epoch [13/50]: Avg Loss: 2.3336 | Avg Accuracy: 48.01 | Model Sparsity: 0.95
Epoch [14/50]: Avg Loss: 2.3003 | Avg Accuracy: 48.94 | Model Sparsity: 0.95
Epoch [15/50]: Avg Loss: 2.2785 | Avg Accuracy: 48.49 | Model Sparsity: 0.95
Epoch [16/50]: Avg Loss: 2.2547 | Avg Accuracy: 48.51 | Model Sparsity: 0.95
Epoch [17/50]: Avg Loss: 2.2156 | Avg Accuracy: 48.64 | Model Sparsity: 0.95
Epoch [18/50]: Avg Loss: 2.2052 | Avg Accuracy: 49.00 | Model Sparsity: 0.95
Epoch [19/50]: Avg Loss: 2.1822 | Avg Accuracy: 48.85 | Model Sparsity: 0.95
Epoch [20/50]: Avg Loss: 2.1631 | Avg Accuracy: 48.22 | Model Sparsity: 0.95
Epoch [21/50]: Avg Loss: 2.1387 | Avg Accuracy: 48.25 | Model Sparsity: 0.95
Epoch [22/50]: Avg Loss: 2.1188 | Avg Accuracy: 48.97 | Model Sparsity: 0.95
Epoch [23/50]: Avg Loss: 2.0983 | Avg Accuracy: 48.81 | Model Sparsity: 0.95
Epoch [24/50]: Avg Loss: 2.0882 | Avg Accuracy: 48.70 | Model Sparsity: 0.95
Epoch [25/50]: Avg Loss: 2.0729 | Avg Accuracy: 48.64 | Model Sparsity: 0.95
Epoch [26/50]: Avg Loss: 2.0471 | Avg Accuracy: 48.18 | Model Sparsity: 0.95
Epoch [27/50]: Avg Loss: 2.0418 | Avg Accuracy: 48.50 | Model Sparsity: 0.95
Epoch [28/50]: Avg Loss: 2.0223 | Avg Accuracy: 48.56 | Model Sparsity: 0.95
Epoch [29/50]: Avg Loss: 2.0041 | Avg Accuracy: 48.67 | Model Sparsity: 0.95
Epoch [30/50]: Avg Loss: 1.9946 | Avg Accuracy: 48.88 | Model Sparsity: 0.95
Epoch [31/50]: Avg Loss: 1.9754 | Avg Accuracy: 48.43 | Model Sparsity: 0.95
Epoch [32/50]: Avg Loss: 1.9584 | Avg Accuracy: 48.44 | Model Sparsity: 0.95
Epoch [33/50]: Avg Loss: 1.9550 | Avg Accuracy: 48.66 | Model Sparsity: 0.95
Epoch [34/50]: Avg Loss: 1.9362 | Avg Accuracy: 48.54 | Model Sparsity: 0.95
Epoch [35/50]: Avg Loss: 1.9258 | Avg Accuracy: 48.64 | Model Sparsity: 0.95
Epoch [36/50]: Avg Loss: 1.9150 | Avg Accuracy: 48.92 | Model Sparsity: 0.95
Epoch [37/50]: Avg Loss: 1.8923 | Avg Accuracy: 48.21 | Model Sparsity: 0.95
Epoch [38/50]: Avg Loss: 1.8900 | Avg Accuracy: 48.90 | Model Sparsity: 0.95
