Model : distilbert-base-uncased - Learning Type: wikitext2/pruning/wanda_pruning/0.95
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: wikitext2
num_classes: 30522
criterion: CrossEntropyLoss()
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 4
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: wanda_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_wanda_pruning_0.95_pruning.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_baseline.pt

Epoch [1/5]: Avg Loss: 1.5288 | Avg Accuracy: 64.37 | Avg Perplexity: 5.654 | Model Sparsity: 0.4636
Recovery epoch [1/10]: Avg Loss: 1.5299 | Avg Accuracy: 64.05 | Avg Perplexity: 5.722 | Model Sparsity: 0.4636
Recovery epoch [2/10]: Avg Loss: 1.5215 | Avg Accuracy: 63.84 | Avg Perplexity: 5.842 | Model Sparsity: 0.4636
Recovery epoch [3/10]: Avg Loss: 1.5218 | Avg Accuracy: 64.35 | Avg Perplexity: 5.625 | Model Sparsity: 0.4636
Recovery epoch [4/10]: Avg Loss: 1.5133 | Avg Accuracy: 63.80 | Avg Perplexity: 5.886 | Model Sparsity: 0.4636
Recovery epoch [5/10]: Avg Loss: 1.5042 | Avg Accuracy: 64.10 | Avg Perplexity: 5.693 | Model Sparsity: 0.4636
Recovery epoch [6/10]: Avg Loss: 1.5100 | Avg Accuracy: 63.51 | Avg Perplexity: 5.833 | Model Sparsity: 0.4636
Recovery epoch [7/10]: Avg Loss: 1.5071 | Avg Accuracy: 63.92 | Avg Perplexity: 5.748 | Model Sparsity: 0.4636
Recovery epoch [8/10]: Avg Loss: 1.5070 | Avg Accuracy: 63.99 | Avg Perplexity: 5.838 | Model Sparsity: 0.4636
Recovery epoch [9/10]: Avg Loss: 1.5097 | Avg Accuracy: 64.02 | Avg Perplexity: 5.750 | Model Sparsity: 0.4636
Recovery epoch [10/10]: Avg Loss: 1.5011 | Avg Accuracy: 63.98 | Avg Perplexity: 5.789 | Model Sparsity: 0.4636
Epoch [2/5]: Avg Loss: 1.5018 | Avg Accuracy: 64.04 | Avg Perplexity: 5.837 | Model Sparsity: 0.7448
Recovery epoch [1/10]: Avg Loss: 1.4970 | Avg Accuracy: 63.93 | Avg Perplexity: 5.806 | Model Sparsity: 0.7448
Recovery epoch [2/10]: Avg Loss: 1.4932 | Avg Accuracy: 63.65 | Avg Perplexity: 5.965 | Model Sparsity: 0.7448
Recovery epoch [3/10]: Avg Loss: 1.4893 | Avg Accuracy: 64.17 | Avg Perplexity: 5.797 | Model Sparsity: 0.7448
Recovery epoch [4/10]: Avg Loss: 1.4972 | Avg Accuracy: 63.69 | Avg Perplexity: 5.916 | Model Sparsity: 0.7448
Recovery epoch [5/10]: Avg Loss: 1.4885 | Avg Accuracy: 63.60 | Avg Perplexity: 5.980 | Model Sparsity: 0.7448
Recovery epoch [6/10]: Avg Loss: 1.4845 | Avg Accuracy: 63.69 | Avg Perplexity: 5.993 | Model Sparsity: 0.7448
Recovery epoch [7/10]: Avg Loss: 1.4766 | Avg Accuracy: 63.72 | Avg Perplexity: 5.829 | Model Sparsity: 0.7448
Recovery epoch [8/10]: Avg Loss: 1.4803 | Avg Accuracy: 63.27 | Avg Perplexity: 6.026 | Model Sparsity: 0.7448
Recovery epoch [9/10]: Avg Loss: 1.4762 | Avg Accuracy: 63.50 | Avg Perplexity: 5.985 | Model Sparsity: 0.7448
Recovery epoch [10/10]: Avg Loss: 1.4782 | Avg Accuracy: 63.51 | Avg Perplexity: 5.943 | Model Sparsity: 0.7448
Epoch [3/5]: Avg Loss: 1.4762 | Avg Accuracy: 63.31 | Avg Perplexity: 5.993 | Model Sparsity: 0.8892
Recovery epoch [1/10]: Avg Loss: 1.4716 | Avg Accuracy: 63.19 | Avg Perplexity: 6.085 | Model Sparsity: 0.8892
Recovery epoch [2/10]: Avg Loss: 1.4788 | Avg Accuracy: 63.25 | Avg Perplexity: 6.077 | Model Sparsity: 0.8892
Recovery epoch [3/10]: Avg Loss: 1.4724 | Avg Accuracy: 63.03 | Avg Perplexity: 6.182 | Model Sparsity: 0.8892
Recovery epoch [4/10]: Avg Loss: 1.4745 | Avg Accuracy: 63.59 | Avg Perplexity: 6.027 | Model Sparsity: 0.8892
Recovery epoch [5/10]: Avg Loss: 1.4674 | Avg Accuracy: 62.71 | Avg Perplexity: 6.218 | Model Sparsity: 0.8892
Recovery epoch [6/10]: Avg Loss: 1.4701 | Avg Accuracy: 62.84 | Avg Perplexity: 6.274 | Model Sparsity: 0.8892
Recovery epoch [7/10]: Avg Loss: 1.4653 | Avg Accuracy: 63.00 | Avg Perplexity: 6.188 | Model Sparsity: 0.8892
Recovery epoch [8/10]: Avg Loss: 1.4592 | Avg Accuracy: 63.15 | Avg Perplexity: 6.261 | Model Sparsity: 0.8892
Recovery epoch [9/10]: Avg Loss: 1.4685 | Avg Accuracy: 63.44 | Avg Perplexity: 6.264 | Model Sparsity: 0.8892
Recovery epoch [10/10]: Avg Loss: 1.4641 | Avg Accuracy: 63.11 | Avg Perplexity: 6.220 | Model Sparsity: 0.8892
Epoch [4/5]: Avg Loss: 1.4586 | Avg Accuracy: 63.13 | Avg Perplexity: 6.235 | Model Sparsity: 0.9424
Recovery epoch [1/10]: Avg Loss: 1.4641 | Avg Accuracy: 62.89 | Avg Perplexity: 6.242 | Model Sparsity: 0.9424
Recovery epoch [2/10]: Avg Loss: 1.4595 | Avg Accuracy: 62.57 | Avg Perplexity: 6.308 | Model Sparsity: 0.9424
Recovery epoch [3/10]: Avg Loss: 1.4650 | Avg Accuracy: 62.86 | Avg Perplexity: 6.302 | Model Sparsity: 0.9424
Recovery epoch [4/10]: Avg Loss: 1.4636 | Avg Accuracy: 62.70 | Avg Perplexity: 6.333 | Model Sparsity: 0.9424
Recovery epoch [5/10]: Avg Loss: 1.4478 | Avg Accuracy: 63.25 | Avg Perplexity: 6.191 | Model Sparsity: 0.9424
Recovery epoch [6/10]: Avg Loss: 1.4537 | Avg Accuracy: 63.03 | Avg Perplexity: 6.211 | Model Sparsity: 0.9424
Recovery epoch [7/10]: Avg Loss: 1.4559 | Avg Accuracy: 62.55 | Avg Perplexity: 6.400 | Model Sparsity: 0.9424
Recovery epoch [8/10]: Avg Loss: 1.4563 | Avg Accuracy: 62.96 | Avg Perplexity: 6.251 | Model Sparsity: 0.9424
Recovery epoch [9/10]: Avg Loss: 1.4549 | Avg Accuracy: 62.66 | Avg Perplexity: 6.271 | Model Sparsity: 0.9424
Recovery epoch [10/10]: Avg Loss: 1.4590 | Avg Accuracy: 62.60 | Avg Perplexity: 6.429 | Model Sparsity: 0.9424
Epoch [5/5]: Avg Loss: 1.4536 | Avg Accuracy: 62.91 | Avg Perplexity: 6.302 | Model Sparsity: 0.95
Recovery epoch [1/10]: Avg Loss: 1.4500 | Avg Accuracy: 62.42 | Avg Perplexity: 6.432 | Model Sparsity: 0.95
Recovery epoch [2/10]: Avg Loss: 1.4475 | Avg Accuracy: 62.48 | Avg Perplexity: 6.392 | Model Sparsity: 0.95
Recovery epoch [3/10]: Avg Loss: 1.4545 | Avg Accuracy: 62.13 | Avg Perplexity: 6.530 | Model Sparsity: 0.95
Recovery epoch [4/10]: Avg Loss: 1.4476 | Avg Accuracy: 62.32 | Avg Perplexity: 6.527 | Model Sparsity: 0.95
Recovery epoch [5/10]: Avg Loss: 1.4499 | Avg Accuracy: 62.99 | Avg Perplexity: 6.281 | Model Sparsity: 0.95
Recovery epoch [6/10]: Avg Loss: 1.4460 | Avg Accuracy: 62.30 | Avg Perplexity: 6.485 | Model Sparsity: 0.95
Recovery epoch [7/10]: Avg Loss: 1.4377 | Avg Accuracy: 62.46 | Avg Perplexity: 6.505 | Model Sparsity: 0.95
Recovery epoch [8/10]: Avg Loss: 1.4455 | Avg Accuracy: 62.25 | Avg Perplexity: 6.452 | Model Sparsity: 0.95
Recovery epoch [9/10]: Avg Loss: 1.4517 | Avg Accuracy: 61.77 | Avg Perplexity: 6.722 | Model Sparsity: 0.95
Recovery epoch [10/10]: Avg Loss: 1.4455 | Avg Accuracy: 62.39 | Avg Perplexity: 6.580 | Model Sparsity: 0.95
