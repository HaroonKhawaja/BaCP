Model : distilbert-base-uncased - Learning Type: wikitext2/pruning/wanda_pruning/0.97
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: wikitext2
num_classes: 30522
criterion: CrossEntropyLoss()
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: wanda_pruning
target_sparsity: 0.97
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_wanda_pruning_0.97_pruning.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_baseline.pt

Epoch [1/5]: Avg Loss: 1.5296 | Avg Accuracy: 64.06 | Avg Perplexity: 5.653 | Model Sparsity: 0.4734
Recovery epoch [1/10]: Avg Loss: 1.5275 | Avg Accuracy: 64.26 | Avg Perplexity: 5.653 | Model Sparsity: 0.4734
Recovery epoch [2/10]: Avg Loss: 1.5281 | Avg Accuracy: 64.36 | Avg Perplexity: 5.599 | Model Sparsity: 0.4734
Recovery epoch [3/10]: Avg Loss: 1.5149 | Avg Accuracy: 64.60 | Avg Perplexity: 5.580 | Model Sparsity: 0.4734
Recovery epoch [4/10]: Avg Loss: 1.5284 | Avg Accuracy: 64.37 | Avg Perplexity: 5.696 | Model Sparsity: 0.4734
Recovery epoch [5/10]: Avg Loss: 1.5191 | Avg Accuracy: 64.22 | Avg Perplexity: 5.634 | Model Sparsity: 0.4734
Recovery epoch [6/10]: Avg Loss: 1.5127 | Avg Accuracy: 64.13 | Avg Perplexity: 5.766 | Model Sparsity: 0.4734
Recovery epoch [7/10]: Avg Loss: 1.5133 | Avg Accuracy: 64.14 | Avg Perplexity: 5.676 | Model Sparsity: 0.4734
Recovery epoch [8/10]: Avg Loss: 1.5122 | Avg Accuracy: 63.94 | Avg Perplexity: 5.720 | Model Sparsity: 0.4734
Recovery epoch [9/10]: Avg Loss: 1.5102 | Avg Accuracy: 64.38 | Avg Perplexity: 5.746 | Model Sparsity: 0.4734
Recovery epoch [10/10]: Avg Loss: 1.5136 | Avg Accuracy: 64.29 | Avg Perplexity: 5.595 | Model Sparsity: 0.4734
Epoch [2/5]: Avg Loss: 1.5060 | Avg Accuracy: 64.64 | Avg Perplexity: 5.574 | Model Sparsity: 0.7605
Recovery epoch [1/10]: Avg Loss: 1.5126 | Avg Accuracy: 64.57 | Avg Perplexity: 5.547 | Model Sparsity: 0.7605
Recovery epoch [2/10]: Avg Loss: 1.5020 | Avg Accuracy: 64.32 | Avg Perplexity: 5.645 | Model Sparsity: 0.7605
Recovery epoch [3/10]: Avg Loss: 1.5084 | Avg Accuracy: 64.45 | Avg Perplexity: 5.656 | Model Sparsity: 0.7605
Recovery epoch [4/10]: Avg Loss: 1.4957 | Avg Accuracy: 63.79 | Avg Perplexity: 5.784 | Model Sparsity: 0.7605
Recovery epoch [5/10]: Avg Loss: 1.4994 | Avg Accuracy: 64.67 | Avg Perplexity: 5.529 | Model Sparsity: 0.7605
Recovery epoch [6/10]: Avg Loss: 1.4972 | Avg Accuracy: 64.14 | Avg Perplexity: 5.653 | Model Sparsity: 0.7605
Recovery epoch [7/10]: Avg Loss: 1.4939 | Avg Accuracy: 64.72 | Avg Perplexity: 5.550 | Model Sparsity: 0.7605
Recovery epoch [8/10]: Avg Loss: 1.5026 | Avg Accuracy: 64.26 | Avg Perplexity: 5.689 | Model Sparsity: 0.7605
Recovery epoch [9/10]: Avg Loss: 1.4954 | Avg Accuracy: 64.30 | Avg Perplexity: 5.613 | Model Sparsity: 0.7605
Recovery epoch [10/10]: Avg Loss: 1.4847 | Avg Accuracy: 64.19 | Avg Perplexity: 5.788 | Model Sparsity: 0.7605
Epoch [3/5]: Avg Loss: 1.4870 | Avg Accuracy: 64.32 | Avg Perplexity: 5.696 | Model Sparsity: 0.9079
Recovery epoch [1/10]: Avg Loss: 1.4843 | Avg Accuracy: 64.02 | Avg Perplexity: 5.758 | Model Sparsity: 0.9079
Recovery epoch [2/10]: Avg Loss: 1.4956 | Avg Accuracy: 64.28 | Avg Perplexity: 5.631 | Model Sparsity: 0.9079
Recovery epoch [3/10]: Avg Loss: 1.4926 | Avg Accuracy: 64.76 | Avg Perplexity: 5.604 | Model Sparsity: 0.9079
Recovery epoch [4/10]: Avg Loss: 1.4889 | Avg Accuracy: 63.84 | Avg Perplexity: 5.697 | Model Sparsity: 0.9079
Recovery epoch [5/10]: Avg Loss: 1.4886 | Avg Accuracy: 64.36 | Avg Perplexity: 5.577 | Model Sparsity: 0.9079
Recovery epoch [6/10]: Avg Loss: 1.4869 | Avg Accuracy: 64.13 | Avg Perplexity: 5.646 | Model Sparsity: 0.9079
Recovery epoch [7/10]: Avg Loss: 1.4786 | Avg Accuracy: 64.59 | Avg Perplexity: 5.624 | Model Sparsity: 0.9079
Recovery epoch [8/10]: Avg Loss: 1.4753 | Avg Accuracy: 64.02 | Avg Perplexity: 5.733 | Model Sparsity: 0.9079
Recovery epoch [9/10]: Avg Loss: 1.4840 | Avg Accuracy: 64.17 | Avg Perplexity: 5.666 | Model Sparsity: 0.9079
Recovery epoch [10/10]: Avg Loss: 1.4824 | Avg Accuracy: 64.27 | Avg Perplexity: 5.669 | Model Sparsity: 0.9079
Epoch [4/5]: Avg Loss: 1.4808 | Avg Accuracy: 64.24 | Avg Perplexity: 5.725 | Model Sparsity: 0.9622
Recovery epoch [1/10]: Avg Loss: 1.4756 | Avg Accuracy: 64.48 | Avg Perplexity: 5.681 | Model Sparsity: 0.9622
Recovery epoch [2/10]: Avg Loss: 1.4816 | Avg Accuracy: 64.06 | Avg Perplexity: 5.675 | Model Sparsity: 0.9622
Recovery epoch [3/10]: Avg Loss: 1.4700 | Avg Accuracy: 63.98 | Avg Perplexity: 5.760 | Model Sparsity: 0.9622
Recovery epoch [4/10]: Avg Loss: 1.4798 | Avg Accuracy: 64.14 | Avg Perplexity: 5.692 | Model Sparsity: 0.9622
Recovery epoch [5/10]: Avg Loss: 1.4690 | Avg Accuracy: 64.37 | Avg Perplexity: 5.645 | Model Sparsity: 0.9622
Recovery epoch [6/10]: Avg Loss: 1.4704 | Avg Accuracy: 64.40 | Avg Perplexity: 5.586 | Model Sparsity: 0.9622
Recovery epoch [7/10]: Avg Loss: 1.4681 | Avg Accuracy: 64.19 | Avg Perplexity: 5.598 | Model Sparsity: 0.9622
Recovery epoch [8/10]: Avg Loss: 1.4687 | Avg Accuracy: 64.16 | Avg Perplexity: 5.738 | Model Sparsity: 0.9622
Recovery epoch [9/10]: Avg Loss: 1.4658 | Avg Accuracy: 64.13 | Avg Perplexity: 5.727 | Model Sparsity: 0.9622
Recovery epoch [10/10]: Avg Loss: 1.4731 | Avg Accuracy: 64.45 | Avg Perplexity: 5.582 | Model Sparsity: 0.9622
Epoch [5/5]: Avg Loss: 1.4696 | Avg Accuracy: 64.18 | Avg Perplexity: 5.675 | Model Sparsity: 0.97
Recovery epoch [1/10]: Avg Loss: 1.4735 | Avg Accuracy: 63.61 | Avg Perplexity: 5.830 | Model Sparsity: 0.97
Recovery epoch [2/10]: Avg Loss: 1.4629 | Avg Accuracy: 64.10 | Avg Perplexity: 5.702 | Model Sparsity: 0.97
Recovery epoch [3/10]: Avg Loss: 1.4749 | Avg Accuracy: 64.43 | Avg Perplexity: 5.648 | Model Sparsity: 0.97
Recovery epoch [4/10]: Avg Loss: 1.4674 | Avg Accuracy: 63.90 | Avg Perplexity: 5.785 | Model Sparsity: 0.97
Recovery epoch [5/10]: Avg Loss: 1.4657 | Avg Accuracy: 64.20 | Avg Perplexity: 5.668 | Model Sparsity: 0.97
Recovery epoch [6/10]: Avg Loss: 1.4681 | Avg Accuracy: 64.00 | Avg Perplexity: 5.647 | Model Sparsity: 0.97
Recovery epoch [7/10]: Avg Loss: 1.4667 | Avg Accuracy: 64.23 | Avg Perplexity: 5.606 | Model Sparsity: 0.97
Recovery epoch [8/10]: Avg Loss: 1.4704 | Avg Accuracy: 63.80 | Avg Perplexity: 5.860 | Model Sparsity: 0.97
Recovery epoch [9/10]: Avg Loss: 1.4656 | Avg Accuracy: 64.56 | Avg Perplexity: 5.549 | Model Sparsity: 0.97
Recovery epoch [10/10]: Avg Loss: 1.4637 | Avg Accuracy: 64.34 | Avg Perplexity: 5.702 | Model Sparsity: 0.97
