Model : distilbert-base-uncased - Learning Type: wikitext2/pruning/snip_pruning/0.95
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: wikitext2
num_classes: 30522
criterion: CrossEntropyLoss()
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: snip_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_snip_pruning_0.95_pruning.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_baseline.pt

Epoch [1/5]: Avg Loss: 2.8235 | Avg Accuracy: 54.57 | Avg Perplexity: 10.392 | Model Sparsity: 0.4636
Recovery epoch [1/10]: Avg Loss: 2.2807 | Avg Accuracy: 55.84 | Avg Perplexity: 9.691 | Model Sparsity: 0.4636
Recovery epoch [2/10]: Avg Loss: 2.1886 | Avg Accuracy: 56.78 | Avg Perplexity: 9.077 | Model Sparsity: 0.4636
Recovery epoch [3/10]: Avg Loss: 2.1271 | Avg Accuracy: 57.38 | Avg Perplexity: 8.741 | Model Sparsity: 0.4636
Recovery epoch [4/10]: Avg Loss: 2.0756 | Avg Accuracy: 57.67 | Avg Perplexity: 8.568 | Model Sparsity: 0.4636
Recovery epoch [5/10]: Avg Loss: 2.0386 | Avg Accuracy: 57.88 | Avg Perplexity: 8.401 | Model Sparsity: 0.4636
Recovery epoch [6/10]: Avg Loss: 2.0027 | Avg Accuracy: 58.22 | Avg Perplexity: 8.307 | Model Sparsity: 0.4636
Recovery epoch [7/10]: Avg Loss: 1.9735 | Avg Accuracy: 58.42 | Avg Perplexity: 8.249 | Model Sparsity: 0.4636
Recovery epoch [8/10]: Avg Loss: 1.9550 | Avg Accuracy: 58.59 | Avg Perplexity: 8.125 | Model Sparsity: 0.4636
Recovery epoch [9/10]: Avg Loss: 1.9330 | Avg Accuracy: 59.09 | Avg Perplexity: 7.878 | Model Sparsity: 0.4636
Recovery epoch [10/10]: Avg Loss: 1.9000 | Avg Accuracy: 58.74 | Avg Perplexity: 8.050 | Model Sparsity: 0.4636
Epoch [2/5]: Avg Loss: 4.2842 | Avg Accuracy: 39.47 | Avg Perplexity: 35.721 | Model Sparsity: 0.7448
Recovery epoch [1/10]: Avg Loss: 3.4445 | Avg Accuracy: 41.99 | Avg Perplexity: 28.272 | Model Sparsity: 0.7448
Recovery epoch [2/10]: Avg Loss: 3.2094 | Avg Accuracy: 43.93 | Avg Perplexity: 24.897 | Model Sparsity: 0.7448
Recovery epoch [3/10]: Avg Loss: 3.0803 | Avg Accuracy: 45.34 | Avg Perplexity: 21.531 | Model Sparsity: 0.7448
Recovery epoch [4/10]: Avg Loss: 2.9693 | Avg Accuracy: 46.11 | Avg Perplexity: 20.341 | Model Sparsity: 0.7448
Recovery epoch [5/10]: Avg Loss: 2.8874 | Avg Accuracy: 47.07 | Avg Perplexity: 19.455 | Model Sparsity: 0.7448
Recovery epoch [6/10]: Avg Loss: 2.8240 | Avg Accuracy: 47.36 | Avg Perplexity: 18.610 | Model Sparsity: 0.7448
Recovery epoch [7/10]: Avg Loss: 2.7700 | Avg Accuracy: 48.00 | Avg Perplexity: 17.942 | Model Sparsity: 0.7448
Recovery epoch [8/10]: Avg Loss: 2.7307 | Avg Accuracy: 48.56 | Avg Perplexity: 17.150 | Model Sparsity: 0.7448
Recovery epoch [9/10]: Avg Loss: 2.6827 | Avg Accuracy: 48.83 | Avg Perplexity: 16.907 | Model Sparsity: 0.7448
Recovery epoch [10/10]: Avg Loss: 2.6437 | Avg Accuracy: 49.13 | Avg Perplexity: 16.342 | Model Sparsity: 0.7448
Epoch [3/5]: Avg Loss: 5.7205 | Avg Accuracy: 28.28 | Avg Perplexity: 121.836 | Model Sparsity: 0.8892
Recovery epoch [1/10]: Avg Loss: 4.5492 | Avg Accuracy: 32.61 | Avg Perplexity: 72.759 | Model Sparsity: 0.8892
Recovery epoch [2/10]: Avg Loss: 4.1531 | Avg Accuracy: 34.53 | Avg Perplexity: 60.288 | Model Sparsity: 0.8892
Recovery epoch [3/10]: Avg Loss: 3.9546 | Avg Accuracy: 35.33 | Avg Perplexity: 55.961 | Model Sparsity: 0.8892
Recovery epoch [4/10]: Avg Loss: 3.8207 | Avg Accuracy: 36.79 | Avg Perplexity: 49.173 | Model Sparsity: 0.8892
Recovery epoch [5/10]: Avg Loss: 3.7152 | Avg Accuracy: 37.33 | Avg Perplexity: 46.420 | Model Sparsity: 0.8892
Recovery epoch [6/10]: Avg Loss: 3.6372 | Avg Accuracy: 37.48 | Avg Perplexity: 45.297 | Model Sparsity: 0.8892
Recovery epoch [7/10]: Avg Loss: 3.5623 | Avg Accuracy: 38.66 | Avg Perplexity: 41.830 | Model Sparsity: 0.8892
Recovery epoch [8/10]: Avg Loss: 3.4899 | Avg Accuracy: 39.49 | Avg Perplexity: 38.844 | Model Sparsity: 0.8892
Recovery epoch [9/10]: Avg Loss: 3.4451 | Avg Accuracy: 39.24 | Avg Perplexity: 39.421 | Model Sparsity: 0.8892
Recovery epoch [10/10]: Avg Loss: 3.4023 | Avg Accuracy: 40.16 | Avg Perplexity: 36.967 | Model Sparsity: 0.8892
Epoch [4/5]: Avg Loss: 5.4645 | Avg Accuracy: 29.21 | Avg Perplexity: 120.939 | Model Sparsity: 0.9424
Recovery epoch [1/10]: Avg Loss: 4.5946 | Avg Accuracy: 32.30 | Avg Perplexity: 86.025 | Model Sparsity: 0.9424
Recovery epoch [2/10]: Avg Loss: 4.3076 | Avg Accuracy: 33.08 | Avg Perplexity: 75.732 | Model Sparsity: 0.9424
Recovery epoch [3/10]: Avg Loss: 4.1456 | Avg Accuracy: 34.04 | Avg Perplexity: 69.347 | Model Sparsity: 0.9424
Recovery epoch [4/10]: Avg Loss: 4.0557 | Avg Accuracy: 34.19 | Avg Perplexity: 67.144 | Model Sparsity: 0.9424
Recovery epoch [5/10]: Avg Loss: 3.9758 | Avg Accuracy: 35.06 | Avg Perplexity: 60.921 | Model Sparsity: 0.9424
Recovery epoch [6/10]: Avg Loss: 3.9035 | Avg Accuracy: 35.35 | Avg Perplexity: 59.844 | Model Sparsity: 0.9424
Recovery epoch [7/10]: Avg Loss: 3.8452 | Avg Accuracy: 35.56 | Avg Perplexity: 58.281 | Model Sparsity: 0.9424
Recovery epoch [8/10]: Avg Loss: 3.7931 | Avg Accuracy: 35.98 | Avg Perplexity: 56.356 | Model Sparsity: 0.9424
Recovery epoch [9/10]: Avg Loss: 3.7548 | Avg Accuracy: 36.00 | Avg Perplexity: 56.786 | Model Sparsity: 0.9424
Recovery epoch [10/10]: Avg Loss: 3.7216 | Avg Accuracy: 36.17 | Avg Perplexity: 55.235 | Model Sparsity: 0.9424
Epoch [5/5]: Avg Loss: 3.8932 | Avg Accuracy: 35.86 | Avg Perplexity: 57.066 | Model Sparsity: 0.95
Recovery epoch [1/10]: Avg Loss: 3.7999 | Avg Accuracy: 35.83 | Avg Perplexity: 56.847 | Model Sparsity: 0.95
Recovery epoch [2/10]: Avg Loss: 3.7525 | Avg Accuracy: 35.95 | Avg Perplexity: 57.368 | Model Sparsity: 0.95
Recovery epoch [3/10]: Avg Loss: 3.7152 | Avg Accuracy: 36.31 | Avg Perplexity: 56.564 | Model Sparsity: 0.95
Recovery epoch [4/10]: Avg Loss: 3.6780 | Avg Accuracy: 36.51 | Avg Perplexity: 53.240 | Model Sparsity: 0.95
Recovery epoch [5/10]: Avg Loss: 3.6417 | Avg Accuracy: 36.59 | Avg Perplexity: 53.765 | Model Sparsity: 0.95
Recovery epoch [6/10]: Avg Loss: 3.6090 | Avg Accuracy: 36.51 | Avg Perplexity: 53.165 | Model Sparsity: 0.95
Recovery epoch [7/10]: Avg Loss: 3.5830 | Avg Accuracy: 36.78 | Avg Perplexity: 53.168 | Model Sparsity: 0.95
Recovery epoch [8/10]: Avg Loss: 3.5698 | Avg Accuracy: 37.19 | Avg Perplexity: 51.265 | Model Sparsity: 0.95
Recovery epoch [9/10]: Avg Loss: 3.5369 | Avg Accuracy: 37.13 | Avg Perplexity: 51.106 | Model Sparsity: 0.95
Recovery epoch [10/10]: Avg Loss: 3.5153 | Avg Accuracy: 37.38 | Avg Perplexity: 49.871 | Model Sparsity: 0.95
