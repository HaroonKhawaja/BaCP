Model : distilbert-base-uncased - Learning Type: wikitext2/pruning/magnitude_pruning/0.99
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: wikitext2
num_classes: 30522
criterion: CrossEntropyLoss()
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.99
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_magnitude_pruning_0.99_pruning.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_baseline.pt

Epoch [1/5]: Avg Loss: 1.5254 | Avg Accuracy: 63.82 | Avg Perplexity: 5.887 | Model Sparsity: 0.4831
Recovery epoch [1/10]: Avg Loss: 1.5217 | Avg Accuracy: 64.12 | Avg Perplexity: 5.742 | Model Sparsity: 0.4831
Recovery epoch [2/10]: Avg Loss: 1.5209 | Avg Accuracy: 64.29 | Avg Perplexity: 5.630 | Model Sparsity: 0.4831
Recovery epoch [3/10]: Avg Loss: 1.5252 | Avg Accuracy: 64.52 | Avg Perplexity: 5.600 | Model Sparsity: 0.4831
Recovery epoch [4/10]: Avg Loss: 1.5170 | Avg Accuracy: 64.26 | Avg Perplexity: 5.649 | Model Sparsity: 0.4831
Recovery epoch [5/10]: Avg Loss: 1.5209 | Avg Accuracy: 63.97 | Avg Perplexity: 5.756 | Model Sparsity: 0.4831
Recovery epoch [6/10]: Avg Loss: 1.5170 | Avg Accuracy: 64.41 | Avg Perplexity: 5.579 | Model Sparsity: 0.4831
Recovery epoch [7/10]: Avg Loss: 1.5168 | Avg Accuracy: 64.01 | Avg Perplexity: 5.651 | Model Sparsity: 0.4831
Recovery epoch [8/10]: Avg Loss: 1.5102 | Avg Accuracy: 64.12 | Avg Perplexity: 5.667 | Model Sparsity: 0.4831
Recovery epoch [9/10]: Avg Loss: 1.5185 | Avg Accuracy: 63.90 | Avg Perplexity: 5.864 | Model Sparsity: 0.4831
Recovery epoch [10/10]: Avg Loss: 1.5046 | Avg Accuracy: 64.16 | Avg Perplexity: 5.699 | Model Sparsity: 0.4831
Epoch [2/5]: Avg Loss: 1.5040 | Avg Accuracy: 64.24 | Avg Perplexity: 5.550 | Model Sparsity: 0.7762
Recovery epoch [1/10]: Avg Loss: 1.5091 | Avg Accuracy: 64.39 | Avg Perplexity: 5.708 | Model Sparsity: 0.7762
Recovery epoch [2/10]: Avg Loss: 1.5003 | Avg Accuracy: 64.74 | Avg Perplexity: 5.468 | Model Sparsity: 0.7762
Recovery epoch [3/10]: Avg Loss: 1.4990 | Avg Accuracy: 64.73 | Avg Perplexity: 5.470 | Model Sparsity: 0.7762
Recovery epoch [4/10]: Avg Loss: 1.4998 | Avg Accuracy: 64.07 | Avg Perplexity: 5.741 | Model Sparsity: 0.7762
Recovery epoch [5/10]: Avg Loss: 1.5009 | Avg Accuracy: 64.21 | Avg Perplexity: 5.687 | Model Sparsity: 0.7762
Recovery epoch [6/10]: Avg Loss: 1.5035 | Avg Accuracy: 64.07 | Avg Perplexity: 5.708 | Model Sparsity: 0.7762
Recovery epoch [7/10]: Avg Loss: 1.4973 | Avg Accuracy: 64.68 | Avg Perplexity: 5.522 | Model Sparsity: 0.7762
Recovery epoch [8/10]: Avg Loss: 1.4973 | Avg Accuracy: 64.21 | Avg Perplexity: 5.620 | Model Sparsity: 0.7762
Recovery epoch [9/10]: Avg Loss: 1.4919 | Avg Accuracy: 64.33 | Avg Perplexity: 5.720 | Model Sparsity: 0.7762
Recovery epoch [10/10]: Avg Loss: 1.5026 | Avg Accuracy: 63.98 | Avg Perplexity: 5.797 | Model Sparsity: 0.7762
Epoch [3/5]: Avg Loss: 1.4946 | Avg Accuracy: 64.11 | Avg Perplexity: 5.688 | Model Sparsity: 0.9266
Recovery epoch [1/10]: Avg Loss: 1.4931 | Avg Accuracy: 64.13 | Avg Perplexity: 5.625 | Model Sparsity: 0.9266
Recovery epoch [2/10]: Avg Loss: 1.4907 | Avg Accuracy: 64.26 | Avg Perplexity: 5.660 | Model Sparsity: 0.9266
Recovery epoch [3/10]: Avg Loss: 1.4929 | Avg Accuracy: 63.89 | Avg Perplexity: 5.642 | Model Sparsity: 0.9266
Recovery epoch [4/10]: Avg Loss: 1.4938 | Avg Accuracy: 63.63 | Avg Perplexity: 5.845 | Model Sparsity: 0.9266
Recovery epoch [5/10]: Avg Loss: 1.4882 | Avg Accuracy: 64.12 | Avg Perplexity: 5.672 | Model Sparsity: 0.9266
Recovery epoch [6/10]: Avg Loss: 1.4840 | Avg Accuracy: 63.98 | Avg Perplexity: 5.670 | Model Sparsity: 0.9266
Recovery epoch [7/10]: Avg Loss: 1.4759 | Avg Accuracy: 64.12 | Avg Perplexity: 5.680 | Model Sparsity: 0.9266
Recovery epoch [8/10]: Avg Loss: 1.4800 | Avg Accuracy: 64.56 | Avg Perplexity: 5.534 | Model Sparsity: 0.9266
Recovery epoch [9/10]: Avg Loss: 1.4945 | Avg Accuracy: 64.46 | Avg Perplexity: 5.547 | Model Sparsity: 0.9266
Recovery epoch [10/10]: Avg Loss: 1.4770 | Avg Accuracy: 64.07 | Avg Perplexity: 5.698 | Model Sparsity: 0.9266
Epoch [4/5]: Avg Loss: 1.4811 | Avg Accuracy: 64.00 | Avg Perplexity: 5.831 | Model Sparsity: 0.9821
Recovery epoch [1/10]: Avg Loss: 1.4732 | Avg Accuracy: 63.79 | Avg Perplexity: 5.826 | Model Sparsity: 0.9821
Recovery epoch [2/10]: Avg Loss: 1.4792 | Avg Accuracy: 64.35 | Avg Perplexity: 5.645 | Model Sparsity: 0.9821
Recovery epoch [3/10]: Avg Loss: 1.4805 | Avg Accuracy: 63.96 | Avg Perplexity: 5.759 | Model Sparsity: 0.9821
Recovery epoch [4/10]: Avg Loss: 1.4820 | Avg Accuracy: 64.27 | Avg Perplexity: 5.651 | Model Sparsity: 0.9821
Recovery epoch [5/10]: Avg Loss: 1.4757 | Avg Accuracy: 64.05 | Avg Perplexity: 5.670 | Model Sparsity: 0.9821
Recovery epoch [6/10]: Avg Loss: 1.4698 | Avg Accuracy: 64.21 | Avg Perplexity: 5.685 | Model Sparsity: 0.9821
Recovery epoch [7/10]: Avg Loss: 1.4761 | Avg Accuracy: 63.64 | Avg Perplexity: 5.747 | Model Sparsity: 0.9821
Recovery epoch [8/10]: Avg Loss: 1.4672 | Avg Accuracy: 64.42 | Avg Perplexity: 5.642 | Model Sparsity: 0.9821
Recovery epoch [9/10]: Avg Loss: 1.4710 | Avg Accuracy: 64.80 | Avg Perplexity: 5.514 | Model Sparsity: 0.9821
Recovery epoch [10/10]: Avg Loss: 1.4645 | Avg Accuracy: 64.39 | Avg Perplexity: 5.675 | Model Sparsity: 0.9821
Epoch [5/5]: Avg Loss: 1.4705 | Avg Accuracy: 64.42 | Avg Perplexity: 5.656 | Model Sparsity: 0.99
Recovery epoch [1/10]: Avg Loss: 1.4734 | Avg Accuracy: 64.05 | Avg Perplexity: 5.762 | Model Sparsity: 0.99
Recovery epoch [2/10]: Avg Loss: 1.4707 | Avg Accuracy: 64.16 | Avg Perplexity: 5.681 | Model Sparsity: 0.99
Recovery epoch [3/10]: Avg Loss: 1.4646 | Avg Accuracy: 64.21 | Avg Perplexity: 5.666 | Model Sparsity: 0.99
Recovery epoch [4/10]: Avg Loss: 1.4738 | Avg Accuracy: 64.24 | Avg Perplexity: 5.640 | Model Sparsity: 0.99
Recovery epoch [5/10]: Avg Loss: 1.4707 | Avg Accuracy: 64.24 | Avg Perplexity: 5.688 | Model Sparsity: 0.99
Recovery epoch [6/10]: Avg Loss: 1.4652 | Avg Accuracy: 64.43 | Avg Perplexity: 5.759 | Model Sparsity: 0.99
Recovery epoch [7/10]: Avg Loss: 1.4634 | Avg Accuracy: 64.69 | Avg Perplexity: 5.552 | Model Sparsity: 0.99
Recovery epoch [8/10]: Avg Loss: 1.4649 | Avg Accuracy: 64.29 | Avg Perplexity: 5.729 | Model Sparsity: 0.99
Recovery epoch [9/10]: Avg Loss: 1.4617 | Avg Accuracy: 64.14 | Avg Perplexity: 5.783 | Model Sparsity: 0.99
Recovery epoch [10/10]: Avg Loss: 1.4665 | Avg Accuracy: 64.23 | Avg Perplexity: 5.672 | Model Sparsity: 0.99
