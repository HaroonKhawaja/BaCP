Model : distilbert-base-uncased - Learning Type: wikitext2/pruning/magnitude_pruning/0.95
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: wikitext2
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbds/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_magnitude_pruning_0.95_pruning.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_baseline.pt

Epoch [1/5]: Avg Loss: 1.4035 | Avg Accuracy: 57.75 | Model Sparsity: 0.4636
Recovery epoch [1/10]: Avg Loss: 1.2841 | Avg Accuracy: 58.69 | Model Sparsity: 0.4636
Recovery epoch [2/10]: Avg Loss: 1.2498 | Avg Accuracy: 59.08 | Model Sparsity: 0.4636
Recovery epoch [3/10]: Avg Loss: 1.2210 | Avg Accuracy: 59.14 | Model Sparsity: 0.4636
Recovery epoch [4/10]: Avg Loss: 1.2038 | Avg Accuracy: 59.53 | Model Sparsity: 0.4636
Recovery epoch [5/10]: Avg Loss: 1.1964 | Avg Accuracy: 59.22 | Model Sparsity: 0.4636
Recovery epoch [6/10]: Avg Loss: 1.1845 | Avg Accuracy: 59.52 | Model Sparsity: 0.4636
Recovery epoch [7/10]: Avg Loss: 1.1766 | Avg Accuracy: 59.73 | Model Sparsity: 0.4636
Recovery epoch [8/10]: Avg Loss: 1.1670 | Avg Accuracy: 59.74 | Model Sparsity: 0.4636
Recovery epoch [9/10]: Avg Loss: 1.1570 | Avg Accuracy: 59.77 | Model Sparsity: 0.4636
Recovery epoch [10/10]: Avg Loss: 1.1469 | Avg Accuracy: 59.58 | Model Sparsity: 0.4636
Epoch [2/5]: Avg Loss: 3.9109 | Avg Accuracy: 43.47 | Model Sparsity: 0.7448
Recovery epoch [1/10]: Avg Loss: 2.7310 | Avg Accuracy: 46.68 | Model Sparsity: 0.7448
Recovery epoch [2/10]: Avg Loss: 2.5016 | Avg Accuracy: 48.65 | Model Sparsity: 0.7448
Recovery epoch [3/10]: Avg Loss: 2.3668 | Avg Accuracy: 49.01 | Model Sparsity: 0.7448
Recovery epoch [4/10]: Avg Loss: 2.2787 | Avg Accuracy: 49.85 | Model Sparsity: 0.7448
Recovery epoch [5/10]: Avg Loss: 2.2162 | Avg Accuracy: 50.26 | Model Sparsity: 0.7448
Recovery epoch [6/10]: Avg Loss: 2.1642 | Avg Accuracy: 50.95 | Model Sparsity: 0.7448
Recovery epoch [7/10]: Avg Loss: 2.1222 | Avg Accuracy: 50.98 | Model Sparsity: 0.7448
Recovery epoch [8/10]: Avg Loss: 2.0804 | Avg Accuracy: 52.10 | Model Sparsity: 0.7448
Recovery epoch [9/10]: Avg Loss: 2.0452 | Avg Accuracy: 51.78 | Model Sparsity: 0.7448
Recovery epoch [10/10]: Avg Loss: 2.0147 | Avg Accuracy: 51.96 | Model Sparsity: 0.7448
Epoch [3/5]: Avg Loss: 5.0583 | Avg Accuracy: 30.98 | Model Sparsity: 0.8892
Recovery epoch [1/10]: Avg Loss: 4.2575 | Avg Accuracy: 34.06 | Model Sparsity: 0.8892
Recovery epoch [2/10]: Avg Loss: 3.9244 | Avg Accuracy: 36.01 | Model Sparsity: 0.8892
Recovery epoch [3/10]: Avg Loss: 3.7269 | Avg Accuracy: 36.98 | Model Sparsity: 0.8892
Recovery epoch [4/10]: Avg Loss: 3.5881 | Avg Accuracy: 37.89 | Model Sparsity: 0.8892
Recovery epoch [5/10]: Avg Loss: 3.4801 | Avg Accuracy: 38.55 | Model Sparsity: 0.8892
Recovery epoch [6/10]: Avg Loss: 3.4024 | Avg Accuracy: 39.44 | Model Sparsity: 0.8892
Recovery epoch [7/10]: Avg Loss: 3.3063 | Avg Accuracy: 39.73 | Model Sparsity: 0.8892
Recovery epoch [8/10]: Avg Loss: 3.2574 | Avg Accuracy: 40.63 | Model Sparsity: 0.8892
Recovery epoch [9/10]: Avg Loss: 3.2064 | Avg Accuracy: 40.81 | Model Sparsity: 0.8892
Recovery epoch [10/10]: Avg Loss: 3.1464 | Avg Accuracy: 41.33 | Model Sparsity: 0.8892
Epoch [4/5]: Avg Loss: 4.7072 | Avg Accuracy: 32.74 | Model Sparsity: 0.9424
Recovery epoch [1/10]: Avg Loss: 4.1662 | Avg Accuracy: 33.91 | Model Sparsity: 0.9424
Recovery epoch [2/10]: Avg Loss: 3.9720 | Avg Accuracy: 35.16 | Model Sparsity: 0.9424
Recovery epoch [3/10]: Avg Loss: 3.8682 | Avg Accuracy: 36.49 | Model Sparsity: 0.9424
Recovery epoch [4/10]: Avg Loss: 3.7840 | Avg Accuracy: 36.05 | Model Sparsity: 0.9424
Recovery epoch [5/10]: Avg Loss: 3.7238 | Avg Accuracy: 36.37 | Model Sparsity: 0.9424
Recovery epoch [6/10]: Avg Loss: 3.6525 | Avg Accuracy: 36.88 | Model Sparsity: 0.9424
Recovery epoch [7/10]: Avg Loss: 3.6025 | Avg Accuracy: 37.25 | Model Sparsity: 0.9424
Recovery epoch [8/10]: Avg Loss: 3.5634 | Avg Accuracy: 37.18 | Model Sparsity: 0.9424
Recovery epoch [9/10]: Avg Loss: 3.5264 | Avg Accuracy: 37.77 | Model Sparsity: 0.9424
Recovery epoch [10/10]: Avg Loss: 3.4900 | Avg Accuracy: 37.76 | Model Sparsity: 0.9424
Epoch [5/5]: Avg Loss: 3.7299 | Avg Accuracy: 37.31 | Model Sparsity: 0.95
Recovery epoch [1/10]: Avg Loss: 3.5257 | Avg Accuracy: 38.01 | Model Sparsity: 0.95
Recovery epoch [2/10]: Avg Loss: 3.4648 | Avg Accuracy: 37.77 | Model Sparsity: 0.95
Recovery epoch [3/10]: Avg Loss: 3.4119 | Avg Accuracy: 38.39 | Model Sparsity: 0.95
Recovery epoch [4/10]: Avg Loss: 3.3801 | Avg Accuracy: 38.74 | Model Sparsity: 0.95
Recovery epoch [5/10]: Avg Loss: 3.3449 | Avg Accuracy: 38.89 | Model Sparsity: 0.95
Recovery epoch [6/10]: Avg Loss: 3.3201 | Avg Accuracy: 38.80 | Model Sparsity: 0.95
Recovery epoch [7/10]: Avg Loss: 3.2997 | Avg Accuracy: 38.73 | Model Sparsity: 0.95
Recovery epoch [8/10]: Avg Loss: 3.2781 | Avg Accuracy: 39.56 | Model Sparsity: 0.95
Recovery epoch [9/10]: Avg Loss: 3.2455 | Avg Accuracy: 39.64 | Model Sparsity: 0.95
Recovery epoch [10/10]: Avg Loss: 3.2317 | Avg Accuracy: 39.22 | Model Sparsity: 0.95
