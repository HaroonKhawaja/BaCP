Model : distilbert-base-uncased - Learning Type: wikitext2/pruning/magnitude_pruning/0.95
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: wikitext2
num_classes: 30522
criterion: CrossEntropyLoss()
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_magnitude_pruning_0.95_pruning.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_baseline.pt

Epoch [1/5]: Avg Loss: 1.5241 | Avg Accuracy: 64.77 | Avg Perplexity: 5.486 | Model Sparsity: 0.4636
Recovery epoch [1/10]: Avg Loss: 1.5306 | Avg Accuracy: 64.06 | Avg Perplexity: 5.655 | Model Sparsity: 0.4636
Recovery epoch [2/10]: Avg Loss: 1.5214 | Avg Accuracy: 64.54 | Avg Perplexity: 5.616 | Model Sparsity: 0.4636
Recovery epoch [3/10]: Avg Loss: 1.5152 | Avg Accuracy: 64.40 | Avg Perplexity: 5.644 | Model Sparsity: 0.4636
Recovery epoch [4/10]: Avg Loss: 1.5120 | Avg Accuracy: 64.43 | Avg Perplexity: 5.612 | Model Sparsity: 0.4636
Recovery epoch [5/10]: Avg Loss: 1.5173 | Avg Accuracy: 64.70 | Avg Perplexity: 5.601 | Model Sparsity: 0.4636
Recovery epoch [6/10]: Avg Loss: 1.5197 | Avg Accuracy: 64.68 | Avg Perplexity: 5.528 | Model Sparsity: 0.4636
Recovery epoch [7/10]: Avg Loss: 1.5120 | Avg Accuracy: 64.47 | Avg Perplexity: 5.550 | Model Sparsity: 0.4636
Recovery epoch [8/10]: Avg Loss: 1.5123 | Avg Accuracy: 64.35 | Avg Perplexity: 5.579 | Model Sparsity: 0.4636
Recovery epoch [9/10]: Avg Loss: 1.5134 | Avg Accuracy: 63.95 | Avg Perplexity: 5.768 | Model Sparsity: 0.4636
Recovery epoch [10/10]: Avg Loss: 1.5130 | Avg Accuracy: 64.28 | Avg Perplexity: 5.699 | Model Sparsity: 0.4636
Epoch [2/5]: Avg Loss: 1.5068 | Avg Accuracy: 64.60 | Avg Perplexity: 5.545 | Model Sparsity: 0.7448
Recovery epoch [1/10]: Avg Loss: 1.5123 | Avg Accuracy: 64.72 | Avg Perplexity: 5.509 | Model Sparsity: 0.7448
Recovery epoch [2/10]: Avg Loss: 1.5064 | Avg Accuracy: 63.91 | Avg Perplexity: 5.807 | Model Sparsity: 0.7448
Recovery epoch [3/10]: Avg Loss: 1.5060 | Avg Accuracy: 64.36 | Avg Perplexity: 5.673 | Model Sparsity: 0.7448
Recovery epoch [4/10]: Avg Loss: 1.4993 | Avg Accuracy: 64.38 | Avg Perplexity: 5.606 | Model Sparsity: 0.7448
Recovery epoch [5/10]: Avg Loss: 1.5031 | Avg Accuracy: 64.56 | Avg Perplexity: 5.645 | Model Sparsity: 0.7448
Recovery epoch [6/10]: Avg Loss: 1.5006 | Avg Accuracy: 64.46 | Avg Perplexity: 5.587 | Model Sparsity: 0.7448
Recovery epoch [7/10]: Avg Loss: 1.4926 | Avg Accuracy: 64.40 | Avg Perplexity: 5.561 | Model Sparsity: 0.7448
Recovery epoch [8/10]: Avg Loss: 1.4987 | Avg Accuracy: 64.37 | Avg Perplexity: 5.613 | Model Sparsity: 0.7448
Recovery epoch [9/10]: Avg Loss: 1.4883 | Avg Accuracy: 64.50 | Avg Perplexity: 5.667 | Model Sparsity: 0.7448
Recovery epoch [10/10]: Avg Loss: 1.5015 | Avg Accuracy: 64.31 | Avg Perplexity: 5.630 | Model Sparsity: 0.7448
Epoch [3/5]: Avg Loss: 1.4980 | Avg Accuracy: 64.11 | Avg Perplexity: 5.679 | Model Sparsity: 0.8892
Recovery epoch [1/10]: Avg Loss: 1.4850 | Avg Accuracy: 64.25 | Avg Perplexity: 5.647 | Model Sparsity: 0.8892
Recovery epoch [2/10]: Avg Loss: 1.4845 | Avg Accuracy: 64.49 | Avg Perplexity: 5.495 | Model Sparsity: 0.8892
Recovery epoch [3/10]: Avg Loss: 1.4909 | Avg Accuracy: 64.36 | Avg Perplexity: 5.672 | Model Sparsity: 0.8892
Recovery epoch [4/10]: Avg Loss: 1.4879 | Avg Accuracy: 64.44 | Avg Perplexity: 5.604 | Model Sparsity: 0.8892
Recovery epoch [5/10]: Avg Loss: 1.4871 | Avg Accuracy: 64.07 | Avg Perplexity: 5.730 | Model Sparsity: 0.8892
Recovery epoch [6/10]: Avg Loss: 1.4809 | Avg Accuracy: 64.10 | Avg Perplexity: 5.719 | Model Sparsity: 0.8892
Recovery epoch [7/10]: Avg Loss: 1.4800 | Avg Accuracy: 63.76 | Avg Perplexity: 5.782 | Model Sparsity: 0.8892
Recovery epoch [8/10]: Avg Loss: 1.4779 | Avg Accuracy: 64.40 | Avg Perplexity: 5.585 | Model Sparsity: 0.8892
Recovery epoch [9/10]: Avg Loss: 1.4920 | Avg Accuracy: 64.34 | Avg Perplexity: 5.673 | Model Sparsity: 0.8892
Recovery epoch [10/10]: Avg Loss: 1.4814 | Avg Accuracy: 63.89 | Avg Perplexity: 5.737 | Model Sparsity: 0.8892
Epoch [4/5]: Avg Loss: 1.4864 | Avg Accuracy: 64.53 | Avg Perplexity: 5.608 | Model Sparsity: 0.9424
Recovery epoch [1/10]: Avg Loss: 1.4815 | Avg Accuracy: 63.89 | Avg Perplexity: 5.727 | Model Sparsity: 0.9424
Recovery epoch [2/10]: Avg Loss: 1.4743 | Avg Accuracy: 64.12 | Avg Perplexity: 5.691 | Model Sparsity: 0.9424
Recovery epoch [3/10]: Avg Loss: 1.4815 | Avg Accuracy: 64.04 | Avg Perplexity: 5.741 | Model Sparsity: 0.9424
Recovery epoch [4/10]: Avg Loss: 1.4763 | Avg Accuracy: 64.35 | Avg Perplexity: 5.669 | Model Sparsity: 0.9424
Recovery epoch [5/10]: Avg Loss: 1.4775 | Avg Accuracy: 64.24 | Avg Perplexity: 5.621 | Model Sparsity: 0.9424
Recovery epoch [6/10]: Avg Loss: 1.4819 | Avg Accuracy: 64.08 | Avg Perplexity: 5.646 | Model Sparsity: 0.9424
Recovery epoch [7/10]: Avg Loss: 1.4683 | Avg Accuracy: 64.28 | Avg Perplexity: 5.648 | Model Sparsity: 0.9424
Recovery epoch [8/10]: Avg Loss: 1.4827 | Avg Accuracy: 64.53 | Avg Perplexity: 5.557 | Model Sparsity: 0.9424
Recovery epoch [9/10]: Avg Loss: 1.4704 | Avg Accuracy: 63.75 | Avg Perplexity: 5.782 | Model Sparsity: 0.9424
Recovery epoch [10/10]: Avg Loss: 1.4709 | Avg Accuracy: 63.43 | Avg Perplexity: 5.798 | Model Sparsity: 0.9424
Epoch [5/5]: Avg Loss: 1.4778 | Avg Accuracy: 64.07 | Avg Perplexity: 5.701 | Model Sparsity: 0.95
Recovery epoch [1/10]: Avg Loss: 1.4664 | Avg Accuracy: 64.16 | Avg Perplexity: 5.781 | Model Sparsity: 0.95
Recovery epoch [2/10]: Avg Loss: 1.4743 | Avg Accuracy: 64.56 | Avg Perplexity: 5.565 | Model Sparsity: 0.95
Recovery epoch [3/10]: Avg Loss: 1.4713 | Avg Accuracy: 63.63 | Avg Perplexity: 5.790 | Model Sparsity: 0.95
Recovery epoch [4/10]: Avg Loss: 1.4643 | Avg Accuracy: 64.62 | Avg Perplexity: 5.617 | Model Sparsity: 0.95
Recovery epoch [5/10]: Avg Loss: 1.4670 | Avg Accuracy: 64.30 | Avg Perplexity: 5.601 | Model Sparsity: 0.95
Recovery epoch [6/10]: Avg Loss: 1.4660 | Avg Accuracy: 64.06 | Avg Perplexity: 5.653 | Model Sparsity: 0.95
Recovery epoch [7/10]: Avg Loss: 1.4690 | Avg Accuracy: 64.81 | Avg Perplexity: 5.510 | Model Sparsity: 0.95
Recovery epoch [8/10]: Avg Loss: 1.4630 | Avg Accuracy: 64.30 | Avg Perplexity: 5.562 | Model Sparsity: 0.95
Recovery epoch [9/10]: Avg Loss: 1.4654 | Avg Accuracy: 64.44 | Avg Perplexity: 5.627 | Model Sparsity: 0.95
Recovery epoch [10/10]: Avg Loss: 1.4603 | Avg Accuracy: 64.15 | Avg Perplexity: 5.744 | Model Sparsity: 0.95
