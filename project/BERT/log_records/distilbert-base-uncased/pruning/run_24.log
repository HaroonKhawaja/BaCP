Model : distilbert-base-uncased - Learning Type: pruning
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: wikitext2
num_classes: 2
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 1e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: wanda_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
delta_t: 35
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_wanda_pruning_0.95.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_baseline.pt
current_sparsity: 0.0

Epoch [1/5]: Avg Loss: 1.1618 | Avg Accuracy: 15.01 | Model Sparsity: 0.832
Recovery epoch [1/10]: Avg Loss: 6.2147 | Avg Accuracy: 22.85 | Model Sparsity: 0.832
Recovery epoch [2/10]: Avg Loss: 5.5487 | Avg Accuracy: 25.17 | Model Sparsity: 0.832
Recovery epoch [3/10]: Avg Loss: 5.2143 | Avg Accuracy: 26.39 | Model Sparsity: 0.832
Recovery epoch [4/10]: Avg Loss: 4.9966 | Avg Accuracy: 27.54 | Model Sparsity: 0.832
Recovery epoch [5/10]: Avg Loss: 4.8109 | Avg Accuracy: 28.73 | Model Sparsity: 0.832
Recovery epoch [6/10]: Avg Loss: 4.6679 | Avg Accuracy: 30.06 | Model Sparsity: 0.832
Recovery epoch [7/10]: Avg Loss: 4.5415 | Avg Accuracy: 30.94 | Model Sparsity: 0.832
Recovery epoch [8/10]: Avg Loss: 4.4300 | Avg Accuracy: 31.29 | Model Sparsity: 0.832
Recovery epoch [9/10]: Avg Loss: 4.3349 | Avg Accuracy: 31.86 | Model Sparsity: 0.832
Recovery epoch [10/10]: Avg Loss: 4.2549 | Avg Accuracy: 32.66 | Model Sparsity: 0.832
Epoch [2/5]: Avg Loss: 4.5902 | Avg Accuracy: 17.42 | Model Sparsity: 0.9215
Recovery epoch [1/10]: Avg Loss: 6.2632 | Avg Accuracy: 20.11 | Model Sparsity: 0.9215
Recovery epoch [2/10]: Avg Loss: 5.9977 | Avg Accuracy: 22.28 | Model Sparsity: 0.9215
Recovery epoch [3/10]: Avg Loss: 5.8257 | Avg Accuracy: 23.27 | Model Sparsity: 0.9215
Recovery epoch [4/10]: Avg Loss: 5.7214 | Avg Accuracy: 24.28 | Model Sparsity: 0.9215
Recovery epoch [5/10]: Avg Loss: 5.6242 | Avg Accuracy: 24.33 | Model Sparsity: 0.9215
Recovery epoch [6/10]: Avg Loss: 5.5458 | Avg Accuracy: 24.96 | Model Sparsity: 0.9215
Recovery epoch [7/10]: Avg Loss: 5.4751 | Avg Accuracy: 25.35 | Model Sparsity: 0.9215
Recovery epoch [8/10]: Avg Loss: 5.3982 | Avg Accuracy: 25.81 | Model Sparsity: 0.9215
Recovery epoch [9/10]: Avg Loss: 5.3317 | Avg Accuracy: 25.73 | Model Sparsity: 0.9215
Recovery epoch [10/10]: Avg Loss: 5.2880 | Avg Accuracy: 26.17 | Model Sparsity: 0.9215
Epoch [3/5]: Avg Loss: 5.2265 | Avg Accuracy: 25.26 | Model Sparsity: 0.9312
Recovery epoch [1/10]: Avg Loss: 5.2850 | Avg Accuracy: 26.45 | Model Sparsity: 0.9312
Recovery epoch [2/10]: Avg Loss: 5.1830 | Avg Accuracy: 26.55 | Model Sparsity: 0.9312
Recovery epoch [3/10]: Avg Loss: 5.1327 | Avg Accuracy: 26.71 | Model Sparsity: 0.9312
Recovery epoch [4/10]: Avg Loss: 5.1075 | Avg Accuracy: 26.39 | Model Sparsity: 0.9312
Recovery epoch [5/10]: Avg Loss: 5.0564 | Avg Accuracy: 27.10 | Model Sparsity: 0.9312
Recovery epoch [6/10]: Avg Loss: 5.0497 | Avg Accuracy: 27.49 | Model Sparsity: 0.9312
Recovery epoch [7/10]: Avg Loss: 5.0155 | Avg Accuracy: 27.20 | Model Sparsity: 0.9312
Recovery epoch [8/10]: Avg Loss: 4.9928 | Avg Accuracy: 27.71 | Model Sparsity: 0.9312
Recovery epoch [9/10]: Avg Loss: 4.9640 | Avg Accuracy: 27.75 | Model Sparsity: 0.9312
Recovery epoch [10/10]: Avg Loss: 4.9352 | Avg Accuracy: 28.06 | Model Sparsity: 0.9312
Epoch [4/5]: Avg Loss: 4.9156 | Avg Accuracy: 27.29 | Model Sparsity: 0.933
Recovery epoch [1/10]: Avg Loss: 4.8829 | Avg Accuracy: 27.73 | Model Sparsity: 0.933
Recovery epoch [2/10]: Avg Loss: 4.8446 | Avg Accuracy: 28.06 | Model Sparsity: 0.933
Recovery epoch [3/10]: Avg Loss: 4.8225 | Avg Accuracy: 27.95 | Model Sparsity: 0.933
Recovery epoch [4/10]: Avg Loss: 4.8046 | Avg Accuracy: 28.35 | Model Sparsity: 0.933
Recovery epoch [5/10]: Avg Loss: 4.7815 | Avg Accuracy: 28.66 | Model Sparsity: 0.933
Recovery epoch [6/10]: Avg Loss: 4.7688 | Avg Accuracy: 28.73 | Model Sparsity: 0.933
Recovery epoch [7/10]: Avg Loss: 4.7367 | Avg Accuracy: 28.81 | Model Sparsity: 0.933
Recovery epoch [8/10]: Avg Loss: 4.7217 | Avg Accuracy: 28.74 | Model Sparsity: 0.933
Recovery epoch [9/10]: Avg Loss: 4.7081 | Avg Accuracy: 28.85 | Model Sparsity: 0.933
Recovery epoch [10/10]: Avg Loss: 4.6971 | Avg Accuracy: 29.22 | Model Sparsity: 0.933
Epoch [5/5]: Avg Loss: 4.6702 | Avg Accuracy: 29.28 | Model Sparsity: 0.9334
Recovery epoch [1/10]: Avg Loss: 4.6373 | Avg Accuracy: 29.06 | Model Sparsity: 0.9334
Recovery epoch [2/10]: Avg Loss: 4.6208 | Avg Accuracy: 29.52 | Model Sparsity: 0.9334
Recovery epoch [3/10]: Avg Loss: 4.6053 | Avg Accuracy: 29.52 | Model Sparsity: 0.9334
Recovery epoch [4/10]: Avg Loss: 4.5969 | Avg Accuracy: 29.42 | Model Sparsity: 0.9334
Recovery epoch [5/10]: Avg Loss: 4.5755 | Avg Accuracy: 29.80 | Model Sparsity: 0.9334
Recovery epoch [6/10]: Avg Loss: 4.5642 | Avg Accuracy: 30.12 | Model Sparsity: 0.9334
Recovery epoch [7/10]: Avg Loss: 4.5332 | Avg Accuracy: 29.83 | Model Sparsity: 0.9334
Recovery epoch [8/10]: Avg Loss: 4.5332 | Avg Accuracy: 29.68 | Model Sparsity: 0.9334
Recovery epoch [9/10]: Avg Loss: 4.5249 | Avg Accuracy: 30.14 | Model Sparsity: 0.9334
Recovery epoch [10/10]: Avg Loss: 4.5124 | Avg Accuracy: 29.80 | Model Sparsity: 0.9334
