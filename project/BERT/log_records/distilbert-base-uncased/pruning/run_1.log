Model : distilbert-base-uncased - Learning Type: pruning
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: sst2
num_classes: 2
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 2e-05
learning_type: pruning
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.97
sparsity_scheduler: cubic
delta_t: 500
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/sst2/distilbert-base-uncased_magnitude_pruning_0.97.pt
finetuned_weights: /dbfs/research/distilbert-base-uncased/sst2/distilbert-base-uncased_baseline.pt
current_sparsity: 0.0

Epoch [1/5]: Avg Loss: 0.0958 | Avg Accuracy: 78.12 | Model Sparsity: 0.8627
Recovery epoch [1/10]: Avg Loss: 0.2768 | Avg Accuracy: 82.69 | Model Sparsity: 0.8627
Recovery epoch [2/10]: Avg Loss: 0.1965 | Avg Accuracy: 83.41 | Model Sparsity: 0.8627
Recovery epoch [3/10]: Avg Loss: 0.1598 | Avg Accuracy: 83.65 | Model Sparsity: 0.8627
Recovery epoch [4/10]: Avg Loss: 0.1315 | Avg Accuracy: 82.33 | Model Sparsity: 0.8627
Recovery epoch [5/10]: Avg Loss: 0.1121 | Avg Accuracy: 83.41 | Model Sparsity: 0.8627
Recovery epoch [6/10]: Avg Loss: 0.0965 | Avg Accuracy: 83.05 | Model Sparsity: 0.8627
Recovery epoch [7/10]: Avg Loss: 0.0843 | Avg Accuracy: 83.65 | Model Sparsity: 0.8627
Recovery epoch [8/10]: Avg Loss: 0.0741 | Avg Accuracy: 83.53 | Model Sparsity: 0.8627
Recovery epoch [9/10]: Avg Loss: 0.0647 | Avg Accuracy: 83.65 | Model Sparsity: 0.8627
Recovery epoch [10/10]: Avg Loss: 0.0573 | Avg Accuracy: 83.77 | Model Sparsity: 0.8627
Epoch [2/5]: Avg Loss: 0.0974 | Avg Accuracy: 79.09 | Model Sparsity: 0.9581
Recovery epoch [1/10]: Avg Loss: 0.1972 | Avg Accuracy: 82.33 | Model Sparsity: 0.9581
Recovery epoch [2/10]: Avg Loss: 0.1463 | Avg Accuracy: 82.21 | Model Sparsity: 0.9581
Recovery epoch [3/10]: Avg Loss: 0.1245 | Avg Accuracy: 81.25 | Model Sparsity: 0.9581
Recovery epoch [4/10]: Avg Loss: 0.1081 | Avg Accuracy: 81.85 | Model Sparsity: 0.9581
Recovery epoch [5/10]: Avg Loss: 0.0961 | Avg Accuracy: 81.13 | Model Sparsity: 0.9581
Recovery epoch [6/10]: Avg Loss: 0.0881 | Avg Accuracy: 81.37 | Model Sparsity: 0.9581
Recovery epoch [7/10]: Avg Loss: 0.0819 | Avg Accuracy: 80.77 | Model Sparsity: 0.9581
Recovery epoch [8/10]: Avg Loss: 0.0739 | Avg Accuracy: 80.65 | Model Sparsity: 0.9581
Recovery epoch [9/10]: Avg Loss: 0.0692 | Avg Accuracy: 80.53 | Model Sparsity: 0.9581
Recovery epoch [10/10]: Avg Loss: 0.0640 | Avg Accuracy: 80.77 | Model Sparsity: 0.9581
Epoch [3/5]: Avg Loss: 0.0920 | Avg Accuracy: 81.37 | Model Sparsity: 0.9687
Recovery epoch [1/10]: Avg Loss: 0.0799 | Avg Accuracy: 79.45 | Model Sparsity: 0.9687
Recovery epoch [2/10]: Avg Loss: 0.0595 | Avg Accuracy: 79.81 | Model Sparsity: 0.9687
Recovery epoch [3/10]: Avg Loss: 0.0530 | Avg Accuracy: 79.57 | Model Sparsity: 0.9687
Recovery epoch [4/10]: Avg Loss: 0.0492 | Avg Accuracy: 79.57 | Model Sparsity: 0.9687
Recovery epoch [5/10]: Avg Loss: 0.0436 | Avg Accuracy: 79.09 | Model Sparsity: 0.9687
Recovery epoch [6/10]: Avg Loss: 0.0418 | Avg Accuracy: 79.21 | Model Sparsity: 0.9687
Recovery epoch [7/10]: Avg Loss: 0.0376 | Avg Accuracy: 79.21 | Model Sparsity: 0.9687
Recovery epoch [8/10]: Avg Loss: 0.0368 | Avg Accuracy: 79.45 | Model Sparsity: 0.9687
Recovery epoch [9/10]: Avg Loss: 0.0340 | Avg Accuracy: 79.57 | Model Sparsity: 0.9687
Recovery epoch [10/10]: Avg Loss: 0.0322 | Avg Accuracy: 77.88 | Model Sparsity: 0.9687
Epoch [4/5]: Avg Loss: 0.0342 | Avg Accuracy: 79.09 | Model Sparsity: 0.9699
Recovery epoch [1/10]: Avg Loss: 0.0287 | Avg Accuracy: 79.33 | Model Sparsity: 0.9699
Recovery epoch [2/10]: Avg Loss: 0.0247 | Avg Accuracy: 78.61 | Model Sparsity: 0.9699
Recovery epoch [3/10]: Avg Loss: 0.0242 | Avg Accuracy: 78.37 | Model Sparsity: 0.9699
Recovery epoch [4/10]: Avg Loss: 0.0224 | Avg Accuracy: 78.61 | Model Sparsity: 0.9699
Recovery epoch [5/10]: Avg Loss: 0.0220 | Avg Accuracy: 78.12 | Model Sparsity: 0.9699
Recovery epoch [6/10]: Avg Loss: 0.0207 | Avg Accuracy: 78.61 | Model Sparsity: 0.9699
Recovery epoch [7/10]: Avg Loss: 0.0188 | Avg Accuracy: 78.25 | Model Sparsity: 0.9699
Recovery epoch [8/10]: Avg Loss: 0.0180 | Avg Accuracy: 78.25 | Model Sparsity: 0.9699
Recovery epoch [9/10]: Avg Loss: 0.0164 | Avg Accuracy: 77.88 | Model Sparsity: 0.9699
Recovery epoch [10/10]: Avg Loss: 0.0158 | Avg Accuracy: 78.25 | Model Sparsity: 0.9699
Epoch [5/5]: Avg Loss: 0.0149 | Avg Accuracy: 78.12 | Model Sparsity: 0.97
Recovery epoch [1/10]: Avg Loss: 0.0143 | Avg Accuracy: 78.49 | Model Sparsity: 0.97
Recovery epoch [2/10]: Avg Loss: 0.0141 | Avg Accuracy: 78.12 | Model Sparsity: 0.97
Recovery epoch [3/10]: Avg Loss: 0.0139 | Avg Accuracy: 77.88 | Model Sparsity: 0.97
Recovery epoch [4/10]: Avg Loss: 0.0133 | Avg Accuracy: 77.64 | Model Sparsity: 0.97
Recovery epoch [5/10]: Avg Loss: 0.0111 | Avg Accuracy: 77.40 | Model Sparsity: 0.97
Recovery epoch [6/10]: Avg Loss: 0.0121 | Avg Accuracy: 78.37 | Model Sparsity: 0.97
Recovery epoch [7/10]: Avg Loss: 0.0118 | Avg Accuracy: 77.04 | Model Sparsity: 0.97
Recovery epoch [8/10]: Avg Loss: 0.0107 | Avg Accuracy: 77.76 | Model Sparsity: 0.97
Recovery epoch [9/10]: Avg Loss: 0.0101 | Avg Accuracy: 77.88 | Model Sparsity: 0.97
Recovery epoch [10/10]: Avg Loss: 0.0100 | Avg Accuracy: 77.16 | Model Sparsity: 0.97
