Model : distilbert-base-uncased - Learning Type: baseline
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: wikitext2
num_classes: 2
embedding_dim: 768
epochs: 50
pruning_epochs: 50
recovery_epochs: 10
batch_size: 64
learning_rate: 1e-05
learning_type: baseline
scheduler_type: linear_with_warmup
optimizer_type: adamw
total_steps: 3550
warmup_steps: 355
prune: False
target_sparsity: 0
sparsity_scheduler: linear
delta_t: 35
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_baseline.pt
current_sparsity: 0.0

Epoch [1/50]: Avg Loss: 1.5129 | Avg Accuracy: 55.90 | Model Sparsity: 0.0
Epoch [2/50]: Avg Loss: 1.5168 | Avg Accuracy: 56.63 | Model Sparsity: 0.0
Epoch [3/50]: Avg Loss: 1.5127 | Avg Accuracy: 56.45 | Model Sparsity: 0.0
Epoch [4/50]: Avg Loss: 1.5033 | Avg Accuracy: 56.44 | Model Sparsity: 0.0
Epoch [5/50]: Avg Loss: 1.4975 | Avg Accuracy: 56.12 | Model Sparsity: 0.0
Epoch [6/50]: Avg Loss: 1.4986 | Avg Accuracy: 56.83 | Model Sparsity: 0.0
Epoch [7/50]: Avg Loss: 1.4964 | Avg Accuracy: 56.76 | Model Sparsity: 0.0
Epoch [8/50]: Avg Loss: 1.4917 | Avg Accuracy: 56.68 | Model Sparsity: 0.0
Epoch [9/50]: Avg Loss: 1.4907 | Avg Accuracy: 56.56 | Model Sparsity: 0.0
Epoch [10/50]: Avg Loss: 1.4873 | Avg Accuracy: 56.61 | Model Sparsity: 0.0
Epoch [11/50]: Avg Loss: 1.4810 | Avg Accuracy: 56.44 | Model Sparsity: 0.0
Epoch [12/50]: Avg Loss: 1.4759 | Avg Accuracy: 56.96 | Model Sparsity: 0.0
Epoch [13/50]: Avg Loss: 1.4757 | Avg Accuracy: 56.50 | Model Sparsity: 0.0
Epoch [14/50]: Avg Loss: 1.4798 | Avg Accuracy: 56.15 | Model Sparsity: 0.0
Epoch [15/50]: Avg Loss: 1.4736 | Avg Accuracy: 56.50 | Model Sparsity: 0.0
Epoch [16/50]: Avg Loss: 1.4699 | Avg Accuracy: 56.63 | Model Sparsity: 0.0
Epoch [17/50]: Avg Loss: 1.4720 | Avg Accuracy: 56.73 | Model Sparsity: 0.0
Epoch [18/50]: Avg Loss: 1.4687 | Avg Accuracy: 56.65 | Model Sparsity: 0.0
Epoch [19/50]: Avg Loss: 1.4645 | Avg Accuracy: 56.82 | Model Sparsity: 0.0
Epoch [20/50]: Avg Loss: 1.4639 | Avg Accuracy: 56.82 | Model Sparsity: 0.0
Epoch [21/50]: Avg Loss: 1.4576 | Avg Accuracy: 56.64 | Model Sparsity: 0.0
Epoch [22/50]: Avg Loss: 1.4561 | Avg Accuracy: 56.46 | Model Sparsity: 0.0
Epoch [23/50]: Avg Loss: 1.4550 | Avg Accuracy: 56.41 | Model Sparsity: 0.0
Epoch [24/50]: Avg Loss: 1.4677 | Avg Accuracy: 56.70 | Model Sparsity: 0.0
Epoch [25/50]: Avg Loss: 1.4538 | Avg Accuracy: 56.16 | Model Sparsity: 0.0
Epoch [26/50]: Avg Loss: 1.4583 | Avg Accuracy: 56.83 | Model Sparsity: 0.0
Epoch [27/50]: Avg Loss: 1.4527 | Avg Accuracy: 56.52 | Model Sparsity: 0.0
Epoch [28/50]: Avg Loss: 1.4534 | Avg Accuracy: 56.37 | Model Sparsity: 0.0
Epoch [29/50]: Avg Loss: 1.4577 | Avg Accuracy: 56.68 | Model Sparsity: 0.0
Epoch [30/50]: Avg Loss: 1.4552 | Avg Accuracy: 56.58 | Model Sparsity: 0.0
Epoch [31/50]: Avg Loss: 1.4464 | Avg Accuracy: 57.19 | Model Sparsity: 0.0
Epoch [32/50]: Avg Loss: 1.4518 | Avg Accuracy: 56.66 | Model Sparsity: 0.0
Epoch [33/50]: Avg Loss: 1.4452 | Avg Accuracy: 56.41 | Model Sparsity: 0.0
Epoch [34/50]: Avg Loss: 1.4456 | Avg Accuracy: 56.62 | Model Sparsity: 0.0
Epoch [35/50]: Avg Loss: 1.4463 | Avg Accuracy: 56.37 | Model Sparsity: 0.0
Epoch [36/50]: Avg Loss: 1.4497 | Avg Accuracy: 56.74 | Model Sparsity: 0.0
Epoch [37/50]: Avg Loss: 1.4464 | Avg Accuracy: 56.58 | Model Sparsity: 0.0
Epoch [38/50]: Avg Loss: 1.4493 | Avg Accuracy: 56.72 | Model Sparsity: 0.0
Epoch [39/50]: Avg Loss: 1.4407 | Avg Accuracy: 57.04 | Model Sparsity: 0.0
Epoch [40/50]: Avg Loss: 1.4531 | Avg Accuracy: 56.73 | Model Sparsity: 0.0
Epoch [41/50]: Avg Loss: 1.4378 | Avg Accuracy: 56.72 | Model Sparsity: 0.0
Epoch [42/50]: Avg Loss: 1.4405 | Avg Accuracy: 56.71 | Model Sparsity: 0.0
Epoch [43/50]: Avg Loss: 1.4387 | Avg Accuracy: 56.69 | Model Sparsity: 0.0
Epoch [44/50]: Avg Loss: 1.4406 | Avg Accuracy: 56.92 | Model Sparsity: 0.0
Epoch [45/50]: Avg Loss: 1.4416 | Avg Accuracy: 56.26 | Model Sparsity: 0.0
Epoch [46/50]: Avg Loss: 1.4411 | Avg Accuracy: 56.39 | Model Sparsity: 0.0
