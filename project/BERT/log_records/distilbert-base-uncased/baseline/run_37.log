Model : distilbert-base-uncased - Learning Type: baseline
Configuration:
model_type: llm
model_name: distilbert-base-uncased
model_task: wikitext2
num_classes: 2
embedding_dim: 768
epochs: 50
pruning_epochs: 50
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: baseline
scheduler_type: linear_with_warmup
optimizer_type: adamw
total_steps: 3550
warmup_steps: 355
prune: False
target_sparsity: 0
sparsity_scheduler: linear
delta_t: 35
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/distilbert-base-uncased/wikitext2/distilbert-base-uncased_wikitext2_baseline.pt
current_sparsity: 0.0

Epoch [1/50]: Avg Loss: 1.2226 | Avg Accuracy: 61.02 | Model Sparsity: 0.0
Epoch [2/50]: Avg Loss: 1.2159 | Avg Accuracy: 60.71 | Model Sparsity: 0.0
Epoch [3/50]: Avg Loss: 1.2134 | Avg Accuracy: 61.17 | Model Sparsity: 0.0
Epoch [4/50]: Avg Loss: 1.2148 | Avg Accuracy: 60.63 | Model Sparsity: 0.0
Epoch [5/50]: Avg Loss: 1.2089 | Avg Accuracy: 60.35 | Model Sparsity: 0.0
Epoch [6/50]: Avg Loss: 1.2070 | Avg Accuracy: 60.66 | Model Sparsity: 0.0
Epoch [7/50]: Avg Loss: 1.1921 | Avg Accuracy: 61.15 | Model Sparsity: 0.0
Epoch [8/50]: Avg Loss: 1.1935 | Avg Accuracy: 60.57 | Model Sparsity: 0.0
Epoch [9/50]: Avg Loss: 1.1849 | Avg Accuracy: 60.77 | Model Sparsity: 0.0
Epoch [10/50]: Avg Loss: 1.1921 | Avg Accuracy: 60.89 | Model Sparsity: 0.0
Epoch [11/50]: Avg Loss: 1.1800 | Avg Accuracy: 60.72 | Model Sparsity: 0.0
Epoch [12/50]: Avg Loss: 1.1593 | Avg Accuracy: 60.73 | Model Sparsity: 0.0
Epoch [13/50]: Avg Loss: 1.1588 | Avg Accuracy: 60.73 | Model Sparsity: 0.0
Epoch [14/50]: Avg Loss: 1.1584 | Avg Accuracy: 60.99 | Model Sparsity: 0.0
Epoch [15/50]: Avg Loss: 1.1522 | Avg Accuracy: 61.43 | Model Sparsity: 0.0
Epoch [16/50]: Avg Loss: 1.1433 | Avg Accuracy: 60.74 | Model Sparsity: 0.0
Epoch [17/50]: Avg Loss: 1.1407 | Avg Accuracy: 61.06 | Model Sparsity: 0.0
Epoch [18/50]: Avg Loss: 1.1337 | Avg Accuracy: 60.64 | Model Sparsity: 0.0
Epoch [19/50]: Avg Loss: 1.1306 | Avg Accuracy: 60.68 | Model Sparsity: 0.0
Epoch [20/50]: Avg Loss: 1.1217 | Avg Accuracy: 61.18 | Model Sparsity: 0.0
Epoch [21/50]: Avg Loss: 1.1121 | Avg Accuracy: 60.88 | Model Sparsity: 0.0
Epoch [22/50]: Avg Loss: 1.1102 | Avg Accuracy: 60.82 | Model Sparsity: 0.0
Epoch [23/50]: Avg Loss: 1.1146 | Avg Accuracy: 60.91 | Model Sparsity: 0.0
Epoch [24/50]: Avg Loss: 1.1005 | Avg Accuracy: 61.23 | Model Sparsity: 0.0
Epoch [25/50]: Avg Loss: 1.0999 | Avg Accuracy: 61.08 | Model Sparsity: 0.0
Epoch [26/50]: Avg Loss: 1.0980 | Avg Accuracy: 61.07 | Model Sparsity: 0.0
Epoch [27/50]: Avg Loss: 1.0947 | Avg Accuracy: 61.07 | Model Sparsity: 0.0
Epoch [28/50]: Avg Loss: 1.0955 | Avg Accuracy: 61.35 | Model Sparsity: 0.0
Epoch [29/50]: Avg Loss: 1.0839 | Avg Accuracy: 61.25 | Model Sparsity: 0.0
Epoch [30/50]: Avg Loss: 1.0827 | Avg Accuracy: 60.85 | Model Sparsity: 0.0
Epoch [31/50]: Avg Loss: 1.0680 | Avg Accuracy: 61.02 | Model Sparsity: 0.0
Epoch [32/50]: Avg Loss: 1.0760 | Avg Accuracy: 60.72 | Model Sparsity: 0.0
Epoch [33/50]: Avg Loss: 1.0703 | Avg Accuracy: 60.89 | Model Sparsity: 0.0
Epoch [34/50]: Avg Loss: 1.0689 | Avg Accuracy: 60.96 | Model Sparsity: 0.0
Epoch [35/50]: Avg Loss: 1.0601 | Avg Accuracy: 61.22 | Model Sparsity: 0.0
