Model : roberta-base - Learning Type: wikitext2/pruning/movement_pruning/0.99
Configuration:
model_type: llm
model_name: roberta-base
model_task: wikitext2
num_classes: 30522
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: movement_pruning
target_sparsity: 0.99
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_movement_pruning_0.99_pruning.pt
finetuned_weights: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_baseline.pt

Epoch [1/5]: Avg Loss: 2.6363 | Avg Accuracy: 60.95 | Model Sparsity: 0.4831
Recovery epoch [1/10]: Avg Loss: 2.1467 | Avg Accuracy: 62.35 | Model Sparsity: 0.4831
Recovery epoch [2/10]: Avg Loss: 2.0525 | Avg Accuracy: 63.71 | Model Sparsity: 0.4831
Recovery epoch [3/10]: Avg Loss: 1.9782 | Avg Accuracy: 64.06 | Model Sparsity: 0.4831
Recovery epoch [4/10]: Avg Loss: 1.9267 | Avg Accuracy: 64.66 | Model Sparsity: 0.4831
Recovery epoch [5/10]: Avg Loss: 1.8909 | Avg Accuracy: 64.99 | Model Sparsity: 0.4831
Recovery epoch [6/10]: Avg Loss: 1.8516 | Avg Accuracy: 65.17 | Model Sparsity: 0.4831
Recovery epoch [7/10]: Avg Loss: 1.8234 | Avg Accuracy: 65.52 | Model Sparsity: 0.4831
Recovery epoch [8/10]: Avg Loss: 1.7907 | Avg Accuracy: 65.23 | Model Sparsity: 0.4831
Recovery epoch [9/10]: Avg Loss: 1.7738 | Avg Accuracy: 65.64 | Model Sparsity: 0.4831
Recovery epoch [10/10]: Avg Loss: 1.7480 | Avg Accuracy: 65.59 | Model Sparsity: 0.4831
Epoch [2/5]: Avg Loss: 4.5424 | Avg Accuracy: 41.93 | Model Sparsity: 0.7762
Recovery epoch [1/10]: Avg Loss: 3.6032 | Avg Accuracy: 46.00 | Model Sparsity: 0.7762
Recovery epoch [2/10]: Avg Loss: 3.3584 | Avg Accuracy: 47.50 | Model Sparsity: 0.7762
Recovery epoch [3/10]: Avg Loss: 3.1992 | Avg Accuracy: 49.26 | Model Sparsity: 0.7762
Recovery epoch [4/10]: Avg Loss: 3.0967 | Avg Accuracy: 49.84 | Model Sparsity: 0.7762
Recovery epoch [5/10]: Avg Loss: 3.0115 | Avg Accuracy: 50.29 | Model Sparsity: 0.7762
Recovery epoch [6/10]: Avg Loss: 2.9569 | Avg Accuracy: 51.07 | Model Sparsity: 0.7762
Recovery epoch [7/10]: Avg Loss: 2.8876 | Avg Accuracy: 51.55 | Model Sparsity: 0.7762
Recovery epoch [8/10]: Avg Loss: 2.8409 | Avg Accuracy: 51.60 | Model Sparsity: 0.7762
Recovery epoch [9/10]: Avg Loss: 2.7946 | Avg Accuracy: 52.48 | Model Sparsity: 0.7762
Recovery epoch [10/10]: Avg Loss: 2.7539 | Avg Accuracy: 52.26 | Model Sparsity: 0.7762
Epoch [3/5]: Avg Loss: 5.9883 | Avg Accuracy: 29.95 | Model Sparsity: 0.9266
Recovery epoch [1/10]: Avg Loss: 4.8476 | Avg Accuracy: 32.94 | Model Sparsity: 0.9266
Recovery epoch [2/10]: Avg Loss: 4.5095 | Avg Accuracy: 35.12 | Model Sparsity: 0.9266
Recovery epoch [3/10]: Avg Loss: 4.3345 | Avg Accuracy: 36.29 | Model Sparsity: 0.9266
Recovery epoch [4/10]: Avg Loss: 4.1990 | Avg Accuracy: 37.20 | Model Sparsity: 0.9266
Recovery epoch [5/10]: Avg Loss: 4.0853 | Avg Accuracy: 38.24 | Model Sparsity: 0.9266
Recovery epoch [6/10]: Avg Loss: 4.0110 | Avg Accuracy: 38.50 | Model Sparsity: 0.9266
Recovery epoch [7/10]: Avg Loss: 3.9344 | Avg Accuracy: 38.63 | Model Sparsity: 0.9266
Recovery epoch [8/10]: Avg Loss: 3.8780 | Avg Accuracy: 40.14 | Model Sparsity: 0.9266
Recovery epoch [9/10]: Avg Loss: 3.8073 | Avg Accuracy: 40.33 | Model Sparsity: 0.9266
Recovery epoch [10/10]: Avg Loss: 3.7752 | Avg Accuracy: 40.82 | Model Sparsity: 0.9266
Epoch [4/5]: Avg Loss: 6.7248 | Avg Accuracy: 21.63 | Model Sparsity: 0.9821
Recovery epoch [1/10]: Avg Loss: 5.8740 | Avg Accuracy: 26.53 | Model Sparsity: 0.9821
Recovery epoch [2/10]: Avg Loss: 5.3885 | Avg Accuracy: 28.84 | Model Sparsity: 0.9821
Recovery epoch [3/10]: Avg Loss: 5.1145 | Avg Accuracy: 30.25 | Model Sparsity: 0.9821
Recovery epoch [4/10]: Avg Loss: 4.9604 | Avg Accuracy: 31.07 | Model Sparsity: 0.9821
Recovery epoch [5/10]: Avg Loss: 4.8511 | Avg Accuracy: 31.58 | Model Sparsity: 0.9821
Recovery epoch [6/10]: Avg Loss: 4.7536 | Avg Accuracy: 32.49 | Model Sparsity: 0.9821
Recovery epoch [7/10]: Avg Loss: 4.6741 | Avg Accuracy: 32.90 | Model Sparsity: 0.9821
Recovery epoch [8/10]: Avg Loss: 4.6052 | Avg Accuracy: 33.29 | Model Sparsity: 0.9821
Recovery epoch [9/10]: Avg Loss: 4.5347 | Avg Accuracy: 33.39 | Model Sparsity: 0.9821
Recovery epoch [10/10]: Avg Loss: 4.5000 | Avg Accuracy: 34.01 | Model Sparsity: 0.9821
Epoch [5/5]: Avg Loss: 5.0547 | Avg Accuracy: 31.59 | Model Sparsity: 0.99
Recovery epoch [1/10]: Avg Loss: 4.8253 | Avg Accuracy: 31.85 | Model Sparsity: 0.99
Recovery epoch [2/10]: Avg Loss: 4.7540 | Avg Accuracy: 32.02 | Model Sparsity: 0.99
Recovery epoch [3/10]: Avg Loss: 4.6805 | Avg Accuracy: 32.46 | Model Sparsity: 0.99
Recovery epoch [4/10]: Avg Loss: 4.6232 | Avg Accuracy: 33.01 | Model Sparsity: 0.99
Recovery epoch [5/10]: Avg Loss: 4.5699 | Avg Accuracy: 33.15 | Model Sparsity: 0.99
Recovery epoch [6/10]: Avg Loss: 4.5456 | Avg Accuracy: 33.58 | Model Sparsity: 0.99
Recovery epoch [7/10]: Avg Loss: 4.5096 | Avg Accuracy: 33.66 | Model Sparsity: 0.99
Recovery epoch [8/10]: Avg Loss: 4.4719 | Avg Accuracy: 33.66 | Model Sparsity: 0.99
Recovery epoch [9/10]: Avg Loss: 4.4354 | Avg Accuracy: 34.00 | Model Sparsity: 0.99
Recovery epoch [10/10]: Avg Loss: 4.4081 | Avg Accuracy: 33.81 | Model Sparsity: 0.99
