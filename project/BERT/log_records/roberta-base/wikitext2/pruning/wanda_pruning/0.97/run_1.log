Model : roberta-base - Learning Type: wikitext2/pruning/wanda_pruning/0.97
Configuration:
model_type: llm
model_name: roberta-base
model_task: wikitext2
num_classes: 30522
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: wanda_pruning
target_sparsity: 0.97
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_wanda_pruning_0.97_pruning.pt
finetuned_weights: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_baseline.pt

Epoch [1/5]: Avg Loss: 1.6998 | Avg Accuracy: 69.40 | Model Sparsity: 0.4734
Recovery epoch [1/10]: Avg Loss: 1.5446 | Avg Accuracy: 69.97 | Model Sparsity: 0.4734
Recovery epoch [2/10]: Avg Loss: 1.5089 | Avg Accuracy: 70.19 | Model Sparsity: 0.4734
Recovery epoch [3/10]: Avg Loss: 1.4808 | Avg Accuracy: 70.46 | Model Sparsity: 0.4734
Recovery epoch [4/10]: Avg Loss: 1.4658 | Avg Accuracy: 70.19 | Model Sparsity: 0.4734
Recovery epoch [5/10]: Avg Loss: 1.4507 | Avg Accuracy: 70.49 | Model Sparsity: 0.4734
Recovery epoch [6/10]: Avg Loss: 1.4447 | Avg Accuracy: 70.41 | Model Sparsity: 0.4734
Recovery epoch [7/10]: Avg Loss: 1.4206 | Avg Accuracy: 70.49 | Model Sparsity: 0.4734
Recovery epoch [8/10]: Avg Loss: 1.4185 | Avg Accuracy: 70.58 | Model Sparsity: 0.4734
Recovery epoch [9/10]: Avg Loss: 1.4088 | Avg Accuracy: 70.25 | Model Sparsity: 0.4734
Recovery epoch [10/10]: Avg Loss: 1.3921 | Avg Accuracy: 70.31 | Model Sparsity: 0.4734
Epoch [2/5]: Avg Loss: 3.7088 | Avg Accuracy: 51.56 | Model Sparsity: 0.7605
Recovery epoch [1/10]: Avg Loss: 2.9327 | Avg Accuracy: 53.48 | Model Sparsity: 0.7605
Recovery epoch [2/10]: Avg Loss: 2.7533 | Avg Accuracy: 55.35 | Model Sparsity: 0.7605
Recovery epoch [3/10]: Avg Loss: 2.6475 | Avg Accuracy: 55.50 | Model Sparsity: 0.7605
Recovery epoch [4/10]: Avg Loss: 2.5695 | Avg Accuracy: 56.36 | Model Sparsity: 0.7605
Recovery epoch [5/10]: Avg Loss: 2.5094 | Avg Accuracy: 57.20 | Model Sparsity: 0.7605
Recovery epoch [6/10]: Avg Loss: 2.4663 | Avg Accuracy: 57.05 | Model Sparsity: 0.7605
Recovery epoch [7/10]: Avg Loss: 2.4229 | Avg Accuracy: 57.43 | Model Sparsity: 0.7605
Recovery epoch [8/10]: Avg Loss: 2.3763 | Avg Accuracy: 58.09 | Model Sparsity: 0.7605
Recovery epoch [9/10]: Avg Loss: 2.3413 | Avg Accuracy: 58.00 | Model Sparsity: 0.7605
Recovery epoch [10/10]: Avg Loss: 2.3151 | Avg Accuracy: 58.14 | Model Sparsity: 0.7605
Epoch [3/5]: Avg Loss: 5.8994 | Avg Accuracy: 31.21 | Model Sparsity: 0.9079
Recovery epoch [1/10]: Avg Loss: 4.8297 | Avg Accuracy: 34.46 | Model Sparsity: 0.9079
Recovery epoch [2/10]: Avg Loss: 4.5181 | Avg Accuracy: 36.02 | Model Sparsity: 0.9079
Recovery epoch [3/10]: Avg Loss: 4.3241 | Avg Accuracy: 37.25 | Model Sparsity: 0.9079
Recovery epoch [4/10]: Avg Loss: 4.1909 | Avg Accuracy: 38.56 | Model Sparsity: 0.9079
Recovery epoch [5/10]: Avg Loss: 4.0690 | Avg Accuracy: 39.78 | Model Sparsity: 0.9079
Recovery epoch [6/10]: Avg Loss: 3.9751 | Avg Accuracy: 40.25 | Model Sparsity: 0.9079
Recovery epoch [7/10]: Avg Loss: 3.8965 | Avg Accuracy: 40.71 | Model Sparsity: 0.9079
Recovery epoch [8/10]: Avg Loss: 3.8134 | Avg Accuracy: 42.11 | Model Sparsity: 0.9079
Recovery epoch [9/10]: Avg Loss: 3.7617 | Avg Accuracy: 42.61 | Model Sparsity: 0.9079
Recovery epoch [10/10]: Avg Loss: 3.6919 | Avg Accuracy: 42.91 | Model Sparsity: 0.9079
Epoch [4/5]: Avg Loss: 5.3751 | Avg Accuracy: 31.79 | Model Sparsity: 0.9622
Recovery epoch [1/10]: Avg Loss: 4.8330 | Avg Accuracy: 33.71 | Model Sparsity: 0.9622
Recovery epoch [2/10]: Avg Loss: 4.6685 | Avg Accuracy: 33.91 | Model Sparsity: 0.9622
Recovery epoch [3/10]: Avg Loss: 4.5629 | Avg Accuracy: 34.66 | Model Sparsity: 0.9622
Recovery epoch [4/10]: Avg Loss: 4.4691 | Avg Accuracy: 35.30 | Model Sparsity: 0.9622
Recovery epoch [5/10]: Avg Loss: 4.4076 | Avg Accuracy: 35.73 | Model Sparsity: 0.9622
Recovery epoch [6/10]: Avg Loss: 4.3588 | Avg Accuracy: 36.55 | Model Sparsity: 0.9622
Recovery epoch [7/10]: Avg Loss: 4.2995 | Avg Accuracy: 37.05 | Model Sparsity: 0.9622
Recovery epoch [8/10]: Avg Loss: 4.2501 | Avg Accuracy: 36.88 | Model Sparsity: 0.9622
Recovery epoch [9/10]: Avg Loss: 4.2153 | Avg Accuracy: 37.27 | Model Sparsity: 0.9622
Recovery epoch [10/10]: Avg Loss: 4.1864 | Avg Accuracy: 37.47 | Model Sparsity: 0.9622
Epoch [5/5]: Avg Loss: 4.3029 | Avg Accuracy: 37.01 | Model Sparsity: 0.97
Recovery epoch [1/10]: Avg Loss: 4.1865 | Avg Accuracy: 36.57 | Model Sparsity: 0.97
Recovery epoch [2/10]: Avg Loss: 4.1434 | Avg Accuracy: 37.54 | Model Sparsity: 0.97
Recovery epoch [3/10]: Avg Loss: 4.0981 | Avg Accuracy: 37.76 | Model Sparsity: 0.97
Recovery epoch [4/10]: Avg Loss: 4.0576 | Avg Accuracy: 37.83 | Model Sparsity: 0.97
Recovery epoch [5/10]: Avg Loss: 4.0486 | Avg Accuracy: 37.72 | Model Sparsity: 0.97
Recovery epoch [6/10]: Avg Loss: 4.0082 | Avg Accuracy: 37.84 | Model Sparsity: 0.97
Recovery epoch [7/10]: Avg Loss: 4.0004 | Avg Accuracy: 38.64 | Model Sparsity: 0.97
Recovery epoch [8/10]: Avg Loss: 3.9654 | Avg Accuracy: 38.36 | Model Sparsity: 0.97
Recovery epoch [9/10]: Avg Loss: 3.9516 | Avg Accuracy: 38.64 | Model Sparsity: 0.97
Recovery epoch [10/10]: Avg Loss: 3.9309 | Avg Accuracy: 38.92 | Model Sparsity: 0.97
