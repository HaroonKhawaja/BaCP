Model : roberta-base - Learning Type: wikitext2/pruning/wanda_pruning/0.99
Configuration:
model_type: llm
model_name: roberta-base
model_task: wikitext2
num_classes: 30522
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: wanda_pruning
target_sparsity: 0.99
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_wanda_pruning_0.99_pruning.pt
finetuned_weights: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_baseline.pt

Epoch [1/5]: Avg Loss: 1.7519 | Avg Accuracy: 69.01 | Model Sparsity: 0.4831
Recovery epoch [1/10]: Avg Loss: 1.5704 | Avg Accuracy: 69.63 | Model Sparsity: 0.4831
Recovery epoch [2/10]: Avg Loss: 1.5383 | Avg Accuracy: 69.65 | Model Sparsity: 0.4831
Recovery epoch [3/10]: Avg Loss: 1.5131 | Avg Accuracy: 69.59 | Model Sparsity: 0.4831
Recovery epoch [4/10]: Avg Loss: 1.4951 | Avg Accuracy: 70.17 | Model Sparsity: 0.4831
Recovery epoch [5/10]: Avg Loss: 1.4748 | Avg Accuracy: 70.45 | Model Sparsity: 0.4831
Recovery epoch [6/10]: Avg Loss: 1.4619 | Avg Accuracy: 70.25 | Model Sparsity: 0.4831
Recovery epoch [7/10]: Avg Loss: 1.4520 | Avg Accuracy: 70.48 | Model Sparsity: 0.4831
Recovery epoch [8/10]: Avg Loss: 1.4346 | Avg Accuracy: 70.39 | Model Sparsity: 0.4831
Recovery epoch [9/10]: Avg Loss: 1.4238 | Avg Accuracy: 70.12 | Model Sparsity: 0.4831
Recovery epoch [10/10]: Avg Loss: 1.4172 | Avg Accuracy: 70.54 | Model Sparsity: 0.4831
Epoch [2/5]: Avg Loss: 4.2254 | Avg Accuracy: 48.19 | Model Sparsity: 0.7762
Recovery epoch [1/10]: Avg Loss: 3.2521 | Avg Accuracy: 51.36 | Model Sparsity: 0.7762
Recovery epoch [2/10]: Avg Loss: 3.0184 | Avg Accuracy: 52.15 | Model Sparsity: 0.7762
Recovery epoch [3/10]: Avg Loss: 2.8797 | Avg Accuracy: 52.83 | Model Sparsity: 0.7762
Recovery epoch [4/10]: Avg Loss: 2.7954 | Avg Accuracy: 54.20 | Model Sparsity: 0.7762
Recovery epoch [5/10]: Avg Loss: 2.7156 | Avg Accuracy: 54.89 | Model Sparsity: 0.7762
Recovery epoch [6/10]: Avg Loss: 2.6471 | Avg Accuracy: 54.98 | Model Sparsity: 0.7762
Recovery epoch [7/10]: Avg Loss: 2.6029 | Avg Accuracy: 55.83 | Model Sparsity: 0.7762
Recovery epoch [8/10]: Avg Loss: 2.5555 | Avg Accuracy: 55.82 | Model Sparsity: 0.7762
Recovery epoch [9/10]: Avg Loss: 2.5154 | Avg Accuracy: 56.87 | Model Sparsity: 0.7762
Recovery epoch [10/10]: Avg Loss: 2.4837 | Avg Accuracy: 56.47 | Model Sparsity: 0.7762
Epoch [3/5]: Avg Loss: 6.6125 | Avg Accuracy: 25.62 | Model Sparsity: 0.9266
Recovery epoch [1/10]: Avg Loss: 5.5554 | Avg Accuracy: 29.20 | Model Sparsity: 0.9266
Recovery epoch [2/10]: Avg Loss: 5.1534 | Avg Accuracy: 31.35 | Model Sparsity: 0.9266
Recovery epoch [3/10]: Avg Loss: 4.9157 | Avg Accuracy: 32.68 | Model Sparsity: 0.9266
Recovery epoch [4/10]: Avg Loss: 4.7442 | Avg Accuracy: 33.46 | Model Sparsity: 0.9266
Recovery epoch [5/10]: Avg Loss: 4.6116 | Avg Accuracy: 34.48 | Model Sparsity: 0.9266
Recovery epoch [6/10]: Avg Loss: 4.4948 | Avg Accuracy: 35.64 | Model Sparsity: 0.9266
Recovery epoch [7/10]: Avg Loss: 4.3949 | Avg Accuracy: 35.89 | Model Sparsity: 0.9266
Recovery epoch [8/10]: Avg Loss: 4.3126 | Avg Accuracy: 36.78 | Model Sparsity: 0.9266
Recovery epoch [9/10]: Avg Loss: 4.2469 | Avg Accuracy: 37.54 | Model Sparsity: 0.9266
Recovery epoch [10/10]: Avg Loss: 4.1768 | Avg Accuracy: 37.60 | Model Sparsity: 0.9266
Epoch [4/5]: Avg Loss: 6.6452 | Avg Accuracy: 22.77 | Model Sparsity: 0.9821
Recovery epoch [1/10]: Avg Loss: 6.0787 | Avg Accuracy: 25.61 | Model Sparsity: 0.9821
Recovery epoch [2/10]: Avg Loss: 5.8200 | Avg Accuracy: 26.62 | Model Sparsity: 0.9821
Recovery epoch [3/10]: Avg Loss: 5.6352 | Avg Accuracy: 27.85 | Model Sparsity: 0.9821
Recovery epoch [4/10]: Avg Loss: 5.4837 | Avg Accuracy: 28.12 | Model Sparsity: 0.9821
Recovery epoch [5/10]: Avg Loss: 5.3864 | Avg Accuracy: 29.36 | Model Sparsity: 0.9821
Recovery epoch [6/10]: Avg Loss: 5.2886 | Avg Accuracy: 29.53 | Model Sparsity: 0.9821
Recovery epoch [7/10]: Avg Loss: 5.2107 | Avg Accuracy: 29.91 | Model Sparsity: 0.9821
Recovery epoch [8/10]: Avg Loss: 5.1470 | Avg Accuracy: 30.34 | Model Sparsity: 0.9821
Recovery epoch [9/10]: Avg Loss: 5.0905 | Avg Accuracy: 30.37 | Model Sparsity: 0.9821
Recovery epoch [10/10]: Avg Loss: 5.0325 | Avg Accuracy: 30.96 | Model Sparsity: 0.9821
Epoch [5/5]: Avg Loss: 5.4338 | Avg Accuracy: 29.18 | Model Sparsity: 0.99
Recovery epoch [1/10]: Avg Loss: 5.2705 | Avg Accuracy: 29.51 | Model Sparsity: 0.99
Recovery epoch [2/10]: Avg Loss: 5.1884 | Avg Accuracy: 29.86 | Model Sparsity: 0.99
Recovery epoch [3/10]: Avg Loss: 5.1219 | Avg Accuracy: 29.99 | Model Sparsity: 0.99
Recovery epoch [4/10]: Avg Loss: 5.0765 | Avg Accuracy: 30.22 | Model Sparsity: 0.99
Recovery epoch [5/10]: Avg Loss: 5.0390 | Avg Accuracy: 30.67 | Model Sparsity: 0.99
Recovery epoch [6/10]: Avg Loss: 5.0098 | Avg Accuracy: 30.79 | Model Sparsity: 0.99
Recovery epoch [7/10]: Avg Loss: 4.9686 | Avg Accuracy: 31.08 | Model Sparsity: 0.99
Recovery epoch [8/10]: Avg Loss: 4.9351 | Avg Accuracy: 30.82 | Model Sparsity: 0.99
Recovery epoch [9/10]: Avg Loss: 4.9012 | Avg Accuracy: 31.60 | Model Sparsity: 0.99
Recovery epoch [10/10]: Avg Loss: 4.8659 | Avg Accuracy: 31.47 | Model Sparsity: 0.99
