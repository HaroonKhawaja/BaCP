Model : roberta-base - Learning Type: sst2/pruning/snip_pruning/0.99
Configuration:
model_type: llm
model_name: roberta-base
model_task: sst2
num_classes: 2
criterion: CrossEntropyLoss()
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 1e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: snip_pruning
target_sparsity: 0.99
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/sst2/roberta-base_sst2_snip_pruning_0.99_pruning.pt
finetuned_weights: /dbfs/research/roberta-base/sst2/roberta-base_sst2_baseline.pt

Epoch [1/5]: Avg Loss: 0.1042 | Avg Accuracy: 93.03 | Model Sparsity: 0.4831
Recovery epoch [1/10]: Avg Loss: 0.0806 | Avg Accuracy: 91.59 | Model Sparsity: 0.4831
Recovery epoch [2/10]: Avg Loss: 0.0675 | Avg Accuracy: 93.03 | Model Sparsity: 0.4831
Recovery epoch [3/10]: Avg Loss: 0.0596 | Avg Accuracy: 92.79 | Model Sparsity: 0.4831
Recovery epoch [4/10]: Avg Loss: 0.0510 | Avg Accuracy: 92.55 | Model Sparsity: 0.4831
Recovery epoch [5/10]: Avg Loss: 0.0460 | Avg Accuracy: 92.43 | Model Sparsity: 0.4831
Recovery epoch [6/10]: Avg Loss: 0.0408 | Avg Accuracy: 92.07 | Model Sparsity: 0.4831
Recovery epoch [7/10]: Avg Loss: 0.0354 | Avg Accuracy: 93.03 | Model Sparsity: 0.4831
Recovery epoch [8/10]: Avg Loss: 0.0320 | Avg Accuracy: 93.15 | Model Sparsity: 0.4831
Recovery epoch [9/10]: Avg Loss: 0.0297 | Avg Accuracy: 92.79 | Model Sparsity: 0.4831
Recovery epoch [10/10]: Avg Loss: 0.0269 | Avg Accuracy: 92.67 | Model Sparsity: 0.4831
Epoch [2/5]: Avg Loss: 0.2266 | Avg Accuracy: 89.06 | Model Sparsity: 0.7762
Recovery epoch [1/10]: Avg Loss: 0.1457 | Avg Accuracy: 89.30 | Model Sparsity: 0.7762
Recovery epoch [2/10]: Avg Loss: 0.1168 | Avg Accuracy: 89.90 | Model Sparsity: 0.7762
Recovery epoch [3/10]: Avg Loss: 0.0975 | Avg Accuracy: 89.78 | Model Sparsity: 0.7762
Recovery epoch [4/10]: Avg Loss: 0.0845 | Avg Accuracy: 89.78 | Model Sparsity: 0.7762
Recovery epoch [5/10]: Avg Loss: 0.0718 | Avg Accuracy: 90.50 | Model Sparsity: 0.7762
Recovery epoch [6/10]: Avg Loss: 0.0657 | Avg Accuracy: 89.54 | Model Sparsity: 0.7762
Recovery epoch [7/10]: Avg Loss: 0.0570 | Avg Accuracy: 90.02 | Model Sparsity: 0.7762
Recovery epoch [8/10]: Avg Loss: 0.0516 | Avg Accuracy: 89.54 | Model Sparsity: 0.7762
Recovery epoch [9/10]: Avg Loss: 0.0486 | Avg Accuracy: 89.78 | Model Sparsity: 0.7762
Recovery epoch [10/10]: Avg Loss: 0.0426 | Avg Accuracy: 90.14 | Model Sparsity: 0.7762
Epoch [3/5]: Avg Loss: 0.3241 | Avg Accuracy: 86.66 | Model Sparsity: 0.9266
Recovery epoch [1/10]: Avg Loss: 0.2451 | Avg Accuracy: 86.42 | Model Sparsity: 0.9266
Recovery epoch [2/10]: Avg Loss: 0.2106 | Avg Accuracy: 87.26 | Model Sparsity: 0.9266
Recovery epoch [3/10]: Avg Loss: 0.1861 | Avg Accuracy: 87.02 | Model Sparsity: 0.9266
Recovery epoch [4/10]: Avg Loss: 0.1692 | Avg Accuracy: 86.66 | Model Sparsity: 0.9266
Recovery epoch [5/10]: Avg Loss: 0.1543 | Avg Accuracy: 88.10 | Model Sparsity: 0.9266
Recovery epoch [6/10]: Avg Loss: 0.1426 | Avg Accuracy: 87.02 | Model Sparsity: 0.9266
Recovery epoch [7/10]: Avg Loss: 0.1318 | Avg Accuracy: 87.98 | Model Sparsity: 0.9266
Recovery epoch [8/10]: Avg Loss: 0.1205 | Avg Accuracy: 87.62 | Model Sparsity: 0.9266
Recovery epoch [9/10]: Avg Loss: 0.1151 | Avg Accuracy: 86.90 | Model Sparsity: 0.9266
Recovery epoch [10/10]: Avg Loss: 0.1059 | Avg Accuracy: 86.42 | Model Sparsity: 0.9266
Epoch [4/5]: Avg Loss: 0.6046 | Avg Accuracy: 81.73 | Model Sparsity: 0.9821
Recovery epoch [1/10]: Avg Loss: 0.3073 | Avg Accuracy: 82.21 | Model Sparsity: 0.9821
Recovery epoch [2/10]: Avg Loss: 0.2619 | Avg Accuracy: 82.69 | Model Sparsity: 0.9821
Recovery epoch [3/10]: Avg Loss: 0.2387 | Avg Accuracy: 83.05 | Model Sparsity: 0.9821
Recovery epoch [4/10]: Avg Loss: 0.2209 | Avg Accuracy: 83.65 | Model Sparsity: 0.9821
Recovery epoch [5/10]: Avg Loss: 0.2056 | Avg Accuracy: 83.65 | Model Sparsity: 0.9821
Recovery epoch [6/10]: Avg Loss: 0.1935 | Avg Accuracy: 84.62 | Model Sparsity: 0.9821
Recovery epoch [7/10]: Avg Loss: 0.1830 | Avg Accuracy: 84.86 | Model Sparsity: 0.9821
Recovery epoch [8/10]: Avg Loss: 0.1728 | Avg Accuracy: 84.50 | Model Sparsity: 0.9821
Recovery epoch [9/10]: Avg Loss: 0.1654 | Avg Accuracy: 84.98 | Model Sparsity: 0.9821
Recovery epoch [10/10]: Avg Loss: 0.1587 | Avg Accuracy: 84.62 | Model Sparsity: 0.9821
Epoch [5/5]: Avg Loss: 0.1929 | Avg Accuracy: 82.33 | Model Sparsity: 0.99
Recovery epoch [1/10]: Avg Loss: 0.1753 | Avg Accuracy: 83.65 | Model Sparsity: 0.99
Recovery epoch [2/10]: Avg Loss: 0.1653 | Avg Accuracy: 82.93 | Model Sparsity: 0.99
Recovery epoch [3/10]: Avg Loss: 0.1575 | Avg Accuracy: 83.05 | Model Sparsity: 0.99
Recovery epoch [4/10]: Avg Loss: 0.1520 | Avg Accuracy: 83.17 | Model Sparsity: 0.99
Recovery epoch [5/10]: Avg Loss: 0.1477 | Avg Accuracy: 82.57 | Model Sparsity: 0.99
Recovery epoch [6/10]: Avg Loss: 0.1439 | Avg Accuracy: 83.77 | Model Sparsity: 0.99
Recovery epoch [7/10]: Avg Loss: 0.1392 | Avg Accuracy: 82.69 | Model Sparsity: 0.99
Recovery epoch [8/10]: Avg Loss: 0.1349 | Avg Accuracy: 82.69 | Model Sparsity: 0.99
Recovery epoch [9/10]: Avg Loss: 0.1322 | Avg Accuracy: 83.17 | Model Sparsity: 0.99
Recovery epoch [10/10]: Avg Loss: 0.1281 | Avg Accuracy: 82.81 | Model Sparsity: 0.99
