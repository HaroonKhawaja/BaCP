Model : roberta-base - Learning Type: sst2/pruning/snip_pruning/0.97
Configuration:
model_type: llm
model_name: roberta-base
model_task: sst2
num_classes: 2
criterion: CrossEntropyLoss()
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 1e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: snip_pruning
target_sparsity: 0.97
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/sst2/roberta-base_sst2_snip_pruning_0.97_pruning.pt
finetuned_weights: /dbfs/research/roberta-base/sst2/roberta-base_sst2_baseline.pt

Epoch [1/5]: Avg Loss: 0.1166 | Avg Accuracy: 92.67 | Model Sparsity: 0.4734
Recovery epoch [1/10]: Avg Loss: 0.0892 | Avg Accuracy: 92.43 | Model Sparsity: 0.4734
Recovery epoch [2/10]: Avg Loss: 0.0751 | Avg Accuracy: 93.27 | Model Sparsity: 0.4734
Recovery epoch [3/10]: Avg Loss: 0.0643 | Avg Accuracy: 92.91 | Model Sparsity: 0.4734
Recovery epoch [4/10]: Avg Loss: 0.0549 | Avg Accuracy: 92.79 | Model Sparsity: 0.4734
Recovery epoch [5/10]: Avg Loss: 0.0479 | Avg Accuracy: 92.67 | Model Sparsity: 0.4734
Recovery epoch [6/10]: Avg Loss: 0.0437 | Avg Accuracy: 93.15 | Model Sparsity: 0.4734
Recovery epoch [7/10]: Avg Loss: 0.0387 | Avg Accuracy: 93.03 | Model Sparsity: 0.4734
Recovery epoch [8/10]: Avg Loss: 0.0346 | Avg Accuracy: 93.63 | Model Sparsity: 0.4734
Recovery epoch [9/10]: Avg Loss: 0.0314 | Avg Accuracy: 93.63 | Model Sparsity: 0.4734
Recovery epoch [10/10]: Avg Loss: 0.0262 | Avg Accuracy: 93.27 | Model Sparsity: 0.4734
Epoch [2/5]: Avg Loss: 0.1806 | Avg Accuracy: 89.30 | Model Sparsity: 0.7605
Recovery epoch [1/10]: Avg Loss: 0.1161 | Avg Accuracy: 90.14 | Model Sparsity: 0.7605
Recovery epoch [2/10]: Avg Loss: 0.0911 | Avg Accuracy: 90.02 | Model Sparsity: 0.7605
Recovery epoch [3/10]: Avg Loss: 0.0755 | Avg Accuracy: 89.78 | Model Sparsity: 0.7605
Recovery epoch [4/10]: Avg Loss: 0.0658 | Avg Accuracy: 90.02 | Model Sparsity: 0.7605
Recovery epoch [5/10]: Avg Loss: 0.0587 | Avg Accuracy: 89.90 | Model Sparsity: 0.7605
Recovery epoch [6/10]: Avg Loss: 0.0509 | Avg Accuracy: 90.26 | Model Sparsity: 0.7605
Recovery epoch [7/10]: Avg Loss: 0.0464 | Avg Accuracy: 91.59 | Model Sparsity: 0.7605
Recovery epoch [8/10]: Avg Loss: 0.0424 | Avg Accuracy: 90.38 | Model Sparsity: 0.7605
Recovery epoch [9/10]: Avg Loss: 0.0391 | Avg Accuracy: 90.38 | Model Sparsity: 0.7605
Recovery epoch [10/10]: Avg Loss: 0.0358 | Avg Accuracy: 90.38 | Model Sparsity: 0.7605
Epoch [3/5]: Avg Loss: 0.3270 | Avg Accuracy: 85.10 | Model Sparsity: 0.9079
Recovery epoch [1/10]: Avg Loss: 0.2281 | Avg Accuracy: 87.26 | Model Sparsity: 0.9079
Recovery epoch [2/10]: Avg Loss: 0.1935 | Avg Accuracy: 86.54 | Model Sparsity: 0.9079
Recovery epoch [3/10]: Avg Loss: 0.1693 | Avg Accuracy: 88.46 | Model Sparsity: 0.9079
Recovery epoch [4/10]: Avg Loss: 0.1520 | Avg Accuracy: 88.22 | Model Sparsity: 0.9079
Recovery epoch [5/10]: Avg Loss: 0.1347 | Avg Accuracy: 88.22 | Model Sparsity: 0.9079
Recovery epoch [6/10]: Avg Loss: 0.1225 | Avg Accuracy: 88.58 | Model Sparsity: 0.9079
Recovery epoch [7/10]: Avg Loss: 0.1124 | Avg Accuracy: 88.70 | Model Sparsity: 0.9079
Recovery epoch [8/10]: Avg Loss: 0.1039 | Avg Accuracy: 87.50 | Model Sparsity: 0.9079
Recovery epoch [9/10]: Avg Loss: 0.0920 | Avg Accuracy: 88.22 | Model Sparsity: 0.9079
Recovery epoch [10/10]: Avg Loss: 0.0894 | Avg Accuracy: 88.82 | Model Sparsity: 0.9079
Epoch [4/5]: Avg Loss: 0.2784 | Avg Accuracy: 84.13 | Model Sparsity: 0.9622
Recovery epoch [1/10]: Avg Loss: 0.2180 | Avg Accuracy: 85.10 | Model Sparsity: 0.9622
Recovery epoch [2/10]: Avg Loss: 0.1935 | Avg Accuracy: 84.74 | Model Sparsity: 0.9622
Recovery epoch [3/10]: Avg Loss: 0.1759 | Avg Accuracy: 84.50 | Model Sparsity: 0.9622
Recovery epoch [4/10]: Avg Loss: 0.1616 | Avg Accuracy: 84.50 | Model Sparsity: 0.9622
Recovery epoch [5/10]: Avg Loss: 0.1501 | Avg Accuracy: 84.13 | Model Sparsity: 0.9622
Recovery epoch [6/10]: Avg Loss: 0.1409 | Avg Accuracy: 84.74 | Model Sparsity: 0.9622
Recovery epoch [7/10]: Avg Loss: 0.1350 | Avg Accuracy: 85.58 | Model Sparsity: 0.9622
Recovery epoch [8/10]: Avg Loss: 0.1291 | Avg Accuracy: 84.62 | Model Sparsity: 0.9622
Recovery epoch [9/10]: Avg Loss: 0.1218 | Avg Accuracy: 84.74 | Model Sparsity: 0.9622
Recovery epoch [10/10]: Avg Loss: 0.1160 | Avg Accuracy: 84.98 | Model Sparsity: 0.9622
Epoch [5/5]: Avg Loss: 0.1421 | Avg Accuracy: 84.50 | Model Sparsity: 0.97
Recovery epoch [1/10]: Avg Loss: 0.1286 | Avg Accuracy: 83.89 | Model Sparsity: 0.97
Recovery epoch [2/10]: Avg Loss: 0.1200 | Avg Accuracy: 84.01 | Model Sparsity: 0.97
Recovery epoch [3/10]: Avg Loss: 0.1159 | Avg Accuracy: 84.25 | Model Sparsity: 0.97
Recovery epoch [4/10]: Avg Loss: 0.1095 | Avg Accuracy: 84.50 | Model Sparsity: 0.97
Recovery epoch [5/10]: Avg Loss: 0.1067 | Avg Accuracy: 84.86 | Model Sparsity: 0.97
Recovery epoch [6/10]: Avg Loss: 0.1009 | Avg Accuracy: 84.98 | Model Sparsity: 0.97
Recovery epoch [7/10]: Avg Loss: 0.0967 | Avg Accuracy: 84.38 | Model Sparsity: 0.97
Recovery epoch [8/10]: Avg Loss: 0.0939 | Avg Accuracy: 85.58 | Model Sparsity: 0.97
Recovery epoch [9/10]: Avg Loss: 0.0920 | Avg Accuracy: 84.50 | Model Sparsity: 0.97
Recovery epoch [10/10]: Avg Loss: 0.0879 | Avg Accuracy: 84.74 | Model Sparsity: 0.97
