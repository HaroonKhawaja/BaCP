Model : roberta-base - Learning Type: sst2/pruning/wanda_pruning/0.97
Configuration:
model_type: llm
model_name: roberta-base
model_task: sst2
num_classes: 2
criterion: CrossEntropyLoss()
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 1e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: wanda_pruning
target_sparsity: 0.97
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/sst2/roberta-base_sst2_wanda_pruning_0.97_pruning.pt
finetuned_weights: /dbfs/research/roberta-base/sst2/roberta-base_sst2_baseline.pt

Epoch [1/5]: Avg Loss: 0.2348 | Avg Accuracy: 91.47 | Model Sparsity: 0.4734
Recovery epoch [1/10]: Avg Loss: 0.1615 | Avg Accuracy: 91.59 | Model Sparsity: 0.4734
Recovery epoch [2/10]: Avg Loss: 0.1291 | Avg Accuracy: 91.59 | Model Sparsity: 0.4734
Recovery epoch [3/10]: Avg Loss: 0.1112 | Avg Accuracy: 91.35 | Model Sparsity: 0.4734
Recovery epoch [4/10]: Avg Loss: 0.0970 | Avg Accuracy: 91.95 | Model Sparsity: 0.4734
Recovery epoch [5/10]: Avg Loss: 0.0859 | Avg Accuracy: 92.55 | Model Sparsity: 0.4734
Recovery epoch [6/10]: Avg Loss: 0.0763 | Avg Accuracy: 92.19 | Model Sparsity: 0.4734
Recovery epoch [7/10]: Avg Loss: 0.0683 | Avg Accuracy: 93.03 | Model Sparsity: 0.4734
Recovery epoch [8/10]: Avg Loss: 0.0606 | Avg Accuracy: 92.43 | Model Sparsity: 0.4734
Recovery epoch [9/10]: Avg Loss: 0.0551 | Avg Accuracy: 92.07 | Model Sparsity: 0.4734
Recovery epoch [10/10]: Avg Loss: 0.0484 | Avg Accuracy: 92.19 | Model Sparsity: 0.4734
Epoch [2/5]: Avg Loss: 0.4252 | Avg Accuracy: 83.89 | Model Sparsity: 0.7605
Recovery epoch [1/10]: Avg Loss: 0.3345 | Avg Accuracy: 83.53 | Model Sparsity: 0.7605
Recovery epoch [2/10]: Avg Loss: 0.2902 | Avg Accuracy: 84.86 | Model Sparsity: 0.7605
Recovery epoch [3/10]: Avg Loss: 0.2623 | Avg Accuracy: 85.34 | Model Sparsity: 0.7605
Recovery epoch [4/10]: Avg Loss: 0.2364 | Avg Accuracy: 85.82 | Model Sparsity: 0.7605
Recovery epoch [5/10]: Avg Loss: 0.2179 | Avg Accuracy: 86.06 | Model Sparsity: 0.7605
Recovery epoch [6/10]: Avg Loss: 0.1999 | Avg Accuracy: 85.70 | Model Sparsity: 0.7605
Recovery epoch [7/10]: Avg Loss: 0.1861 | Avg Accuracy: 86.66 | Model Sparsity: 0.7605
Recovery epoch [8/10]: Avg Loss: 0.1725 | Avg Accuracy: 85.82 | Model Sparsity: 0.7605
Recovery epoch [9/10]: Avg Loss: 0.1643 | Avg Accuracy: 86.90 | Model Sparsity: 0.7605
Recovery epoch [10/10]: Avg Loss: 0.1503 | Avg Accuracy: 84.74 | Model Sparsity: 0.7605
Epoch [3/5]: Avg Loss: 0.3583 | Avg Accuracy: 81.49 | Model Sparsity: 0.9079
Recovery epoch [1/10]: Avg Loss: 0.2887 | Avg Accuracy: 81.01 | Model Sparsity: 0.9079
Recovery epoch [2/10]: Avg Loss: 0.2624 | Avg Accuracy: 81.49 | Model Sparsity: 0.9079
Recovery epoch [3/10]: Avg Loss: 0.2426 | Avg Accuracy: 81.61 | Model Sparsity: 0.9079
Recovery epoch [4/10]: Avg Loss: 0.2276 | Avg Accuracy: 82.09 | Model Sparsity: 0.9079
Recovery epoch [5/10]: Avg Loss: 0.2142 | Avg Accuracy: 82.69 | Model Sparsity: 0.9079
Recovery epoch [6/10]: Avg Loss: 0.2034 | Avg Accuracy: 81.37 | Model Sparsity: 0.9079
Recovery epoch [7/10]: Avg Loss: 0.1954 | Avg Accuracy: 81.85 | Model Sparsity: 0.9079
Recovery epoch [8/10]: Avg Loss: 0.1864 | Avg Accuracy: 82.57 | Model Sparsity: 0.9079
Recovery epoch [9/10]: Avg Loss: 0.1798 | Avg Accuracy: 82.93 | Model Sparsity: 0.9079
Recovery epoch [10/10]: Avg Loss: 0.1727 | Avg Accuracy: 82.33 | Model Sparsity: 0.9079
Epoch [4/5]: Avg Loss: 0.3465 | Avg Accuracy: 81.25 | Model Sparsity: 0.9622
Recovery epoch [1/10]: Avg Loss: 0.2658 | Avg Accuracy: 82.09 | Model Sparsity: 0.9622
Recovery epoch [2/10]: Avg Loss: 0.2461 | Avg Accuracy: 81.49 | Model Sparsity: 0.9622
Recovery epoch [3/10]: Avg Loss: 0.2294 | Avg Accuracy: 81.49 | Model Sparsity: 0.9622
Recovery epoch [4/10]: Avg Loss: 0.2178 | Avg Accuracy: 82.21 | Model Sparsity: 0.9622
Recovery epoch [5/10]: Avg Loss: 0.2082 | Avg Accuracy: 81.37 | Model Sparsity: 0.9622
Recovery epoch [6/10]: Avg Loss: 0.2006 | Avg Accuracy: 82.57 | Model Sparsity: 0.9622
Recovery epoch [7/10]: Avg Loss: 0.1914 | Avg Accuracy: 81.61 | Model Sparsity: 0.9622
Recovery epoch [8/10]: Avg Loss: 0.1860 | Avg Accuracy: 82.57 | Model Sparsity: 0.9622
Recovery epoch [9/10]: Avg Loss: 0.1834 | Avg Accuracy: 82.09 | Model Sparsity: 0.9622
Recovery epoch [10/10]: Avg Loss: 0.1760 | Avg Accuracy: 82.33 | Model Sparsity: 0.9622
Epoch [5/5]: Avg Loss: 0.1933 | Avg Accuracy: 82.57 | Model Sparsity: 0.97
Recovery epoch [1/10]: Avg Loss: 0.1803 | Avg Accuracy: 81.97 | Model Sparsity: 0.97
Recovery epoch [2/10]: Avg Loss: 0.1728 | Avg Accuracy: 82.09 | Model Sparsity: 0.97
Recovery epoch [3/10]: Avg Loss: 0.1685 | Avg Accuracy: 81.85 | Model Sparsity: 0.97
Recovery epoch [4/10]: Avg Loss: 0.1636 | Avg Accuracy: 82.09 | Model Sparsity: 0.97
Recovery epoch [5/10]: Avg Loss: 0.1599 | Avg Accuracy: 81.49 | Model Sparsity: 0.97
Recovery epoch [6/10]: Avg Loss: 0.1556 | Avg Accuracy: 81.73 | Model Sparsity: 0.97
Recovery epoch [7/10]: Avg Loss: 0.1534 | Avg Accuracy: 81.61 | Model Sparsity: 0.97
Recovery epoch [8/10]: Avg Loss: 0.1491 | Avg Accuracy: 81.49 | Model Sparsity: 0.97
Recovery epoch [9/10]: Avg Loss: 0.1466 | Avg Accuracy: 81.85 | Model Sparsity: 0.97
Recovery epoch [10/10]: Avg Loss: 0.1445 | Avg Accuracy: 81.73 | Model Sparsity: 0.97
