Model : roberta-base - Learning Type: pruning
Configuration:
model_type: llm
model_name: roberta-base
model_task: wikitext2
num_classes: 2
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: movement_pruning
target_sparsity: 0.99
sparsity_scheduler: cubic
delta_t: 37
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_movement_pruning_0.99.pt
finetuned_weights: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_baseline.pt
current_sparsity: 0.0

Epoch [1/5]: Avg Loss: 2.1393 | Avg Accuracy: 59.54 | Model Sparsity: 0.4831
Recovery epoch [1/10]: Avg Loss: 2.2439 | Avg Accuracy: 61.37 | Model Sparsity: 0.4831
Recovery epoch [2/10]: Avg Loss: 2.1008 | Avg Accuracy: 63.12 | Model Sparsity: 0.4831
Recovery epoch [3/10]: Avg Loss: 2.0207 | Avg Accuracy: 63.43 | Model Sparsity: 0.4831
Recovery epoch [4/10]: Avg Loss: 1.9599 | Avg Accuracy: 64.07 | Model Sparsity: 0.4831
Recovery epoch [5/10]: Avg Loss: 1.9143 | Avg Accuracy: 65.04 | Model Sparsity: 0.4831
Recovery epoch [6/10]: Avg Loss: 1.8773 | Avg Accuracy: 65.61 | Model Sparsity: 0.4831
Recovery epoch [7/10]: Avg Loss: 1.8389 | Avg Accuracy: 65.44 | Model Sparsity: 0.4831
Recovery epoch [8/10]: Avg Loss: 1.8238 | Avg Accuracy: 65.37 | Model Sparsity: 0.4831
Recovery epoch [9/10]: Avg Loss: 1.8000 | Avg Accuracy: 65.60 | Model Sparsity: 0.4831
Recovery epoch [10/10]: Avg Loss: 1.7629 | Avg Accuracy: 65.46 | Model Sparsity: 0.4831
Epoch [2/5]: Avg Loss: 3.0529 | Avg Accuracy: 43.10 | Model Sparsity: 0.7305
Recovery epoch [1/10]: Avg Loss: 3.3864 | Avg Accuracy: 48.82 | Model Sparsity: 0.7305
Recovery epoch [2/10]: Avg Loss: 3.1065 | Avg Accuracy: 50.57 | Model Sparsity: 0.7305
Recovery epoch [3/10]: Avg Loss: 2.9683 | Avg Accuracy: 51.80 | Model Sparsity: 0.7305
Recovery epoch [4/10]: Avg Loss: 2.8564 | Avg Accuracy: 52.14 | Model Sparsity: 0.7305
Recovery epoch [5/10]: Avg Loss: 2.7892 | Avg Accuracy: 52.77 | Model Sparsity: 0.7305
Recovery epoch [6/10]: Avg Loss: 2.7272 | Avg Accuracy: 54.22 | Model Sparsity: 0.7305
Recovery epoch [7/10]: Avg Loss: 2.6766 | Avg Accuracy: 53.55 | Model Sparsity: 0.7305
Recovery epoch [8/10]: Avg Loss: 2.6325 | Avg Accuracy: 54.78 | Model Sparsity: 0.7305
Recovery epoch [9/10]: Avg Loss: 2.5855 | Avg Accuracy: 55.19 | Model Sparsity: 0.7305
Recovery epoch [10/10]: Avg Loss: 2.5649 | Avg Accuracy: 55.51 | Model Sparsity: 0.7305
Epoch [3/5]: Avg Loss: 3.5992 | Avg Accuracy: 37.45 | Model Sparsity: 0.8571
Recovery epoch [1/10]: Avg Loss: 3.9239 | Avg Accuracy: 42.06 | Model Sparsity: 0.8571
Recovery epoch [2/10]: Avg Loss: 3.6613 | Avg Accuracy: 44.04 | Model Sparsity: 0.8571
Recovery epoch [3/10]: Avg Loss: 3.5240 | Avg Accuracy: 45.11 | Model Sparsity: 0.8571
Recovery epoch [4/10]: Avg Loss: 3.4190 | Avg Accuracy: 45.56 | Model Sparsity: 0.8571
Recovery epoch [5/10]: Avg Loss: 3.3411 | Avg Accuracy: 46.35 | Model Sparsity: 0.8571
Recovery epoch [6/10]: Avg Loss: 3.2683 | Avg Accuracy: 46.62 | Model Sparsity: 0.8571
Recovery epoch [7/10]: Avg Loss: 3.2250 | Avg Accuracy: 47.71 | Model Sparsity: 0.8571
Recovery epoch [8/10]: Avg Loss: 3.1785 | Avg Accuracy: 48.17 | Model Sparsity: 0.8571
Recovery epoch [9/10]: Avg Loss: 3.1345 | Avg Accuracy: 48.44 | Model Sparsity: 0.8571
Recovery epoch [10/10]: Avg Loss: 3.0916 | Avg Accuracy: 48.26 | Model Sparsity: 0.8571
Epoch [4/5]: Avg Loss: 4.0381 | Avg Accuracy: 35.11 | Model Sparsity: 0.922
Recovery epoch [1/10]: Avg Loss: 4.2672 | Avg Accuracy: 38.16 | Model Sparsity: 0.922
Recovery epoch [2/10]: Avg Loss: 4.0359 | Avg Accuracy: 40.28 | Model Sparsity: 0.922
Recovery epoch [3/10]: Avg Loss: 3.8880 | Avg Accuracy: 41.21 | Model Sparsity: 0.922
Recovery epoch [4/10]: Avg Loss: 3.7964 | Avg Accuracy: 41.38 | Model Sparsity: 0.922
Recovery epoch [5/10]: Avg Loss: 3.7144 | Avg Accuracy: 42.55 | Model Sparsity: 0.922
Recovery epoch [6/10]: Avg Loss: 3.6576 | Avg Accuracy: 42.51 | Model Sparsity: 0.922
Recovery epoch [7/10]: Avg Loss: 3.6000 | Avg Accuracy: 43.15 | Model Sparsity: 0.922
Recovery epoch [8/10]: Avg Loss: 3.5584 | Avg Accuracy: 43.66 | Model Sparsity: 0.922
Recovery epoch [9/10]: Avg Loss: 3.5094 | Avg Accuracy: 44.09 | Model Sparsity: 0.922
Recovery epoch [10/10]: Avg Loss: 3.4824 | Avg Accuracy: 44.91 | Model Sparsity: 0.922
Epoch [5/5]: Avg Loss: 4.2018 | Avg Accuracy: 33.97 | Model Sparsity: 0.9552
Recovery epoch [1/10]: Avg Loss: 4.3775 | Avg Accuracy: 36.89 | Model Sparsity: 0.9552
Recovery epoch [2/10]: Avg Loss: 4.1878 | Avg Accuracy: 37.76 | Model Sparsity: 0.9552
Recovery epoch [3/10]: Avg Loss: 4.0764 | Avg Accuracy: 38.80 | Model Sparsity: 0.9552
Recovery epoch [4/10]: Avg Loss: 4.0036 | Avg Accuracy: 39.05 | Model Sparsity: 0.9552
Recovery epoch [5/10]: Avg Loss: 3.9258 | Avg Accuracy: 40.06 | Model Sparsity: 0.9552
Recovery epoch [6/10]: Avg Loss: 3.8828 | Avg Accuracy: 40.31 | Model Sparsity: 0.9552
Recovery epoch [7/10]: Avg Loss: 3.8271 | Avg Accuracy: 40.49 | Model Sparsity: 0.9552
Recovery epoch [8/10]: Avg Loss: 3.7869 | Avg Accuracy: 41.26 | Model Sparsity: 0.9552
Recovery epoch [9/10]: Avg Loss: 3.7477 | Avg Accuracy: 41.59 | Model Sparsity: 0.9552
Recovery epoch [10/10]: Avg Loss: 3.7048 | Avg Accuracy: 41.87 | Model Sparsity: 0.9552
