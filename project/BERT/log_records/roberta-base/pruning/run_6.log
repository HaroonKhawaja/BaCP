Model : roberta-base - Learning Type: pruning
Configuration:
model_type: llm
model_name: roberta-base
model_task: wikitext2
num_classes: 2
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: movement_pruning
target_sparsity: 0.99
sparsity_scheduler: cubic
delta_t: 37
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_movement_pruning_0.99.pt
finetuned_weights: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_baseline.pt
current_sparsity: 0.0

Epoch [1/5]: Avg Loss: 2.1360 | Avg Accuracy: 58.64 | Model Sparsity: 0.4831
Recovery epoch [1/10]: Avg Loss: 2.2496 | Avg Accuracy: 61.50 | Model Sparsity: 0.4831
Recovery epoch [2/10]: Avg Loss: 2.0834 | Avg Accuracy: 62.95 | Model Sparsity: 0.4831
Recovery epoch [3/10]: Avg Loss: 2.0234 | Avg Accuracy: 63.47 | Model Sparsity: 0.4831
Recovery epoch [4/10]: Avg Loss: 1.9613 | Avg Accuracy: 63.87 | Model Sparsity: 0.4831
Recovery epoch [5/10]: Avg Loss: 1.9190 | Avg Accuracy: 64.64 | Model Sparsity: 0.4831
Recovery epoch [6/10]: Avg Loss: 1.8880 | Avg Accuracy: 64.36 | Model Sparsity: 0.4831
Recovery epoch [7/10]: Avg Loss: 1.8552 | Avg Accuracy: 65.03 | Model Sparsity: 0.4831
Recovery epoch [8/10]: Avg Loss: 1.8210 | Avg Accuracy: 64.99 | Model Sparsity: 0.4831
Recovery epoch [9/10]: Avg Loss: 1.8018 | Avg Accuracy: 65.50 | Model Sparsity: 0.4831
Recovery epoch [10/10]: Avg Loss: 1.7804 | Avg Accuracy: 65.57 | Model Sparsity: 0.4831
Epoch [2/5]: Avg Loss: 2.9887 | Avg Accuracy: 44.31 | Model Sparsity: 0.7305
Recovery epoch [1/10]: Avg Loss: 3.3279 | Avg Accuracy: 48.90 | Model Sparsity: 0.7305
Recovery epoch [2/10]: Avg Loss: 3.0703 | Avg Accuracy: 50.49 | Model Sparsity: 0.7305
Recovery epoch [3/10]: Avg Loss: 2.9268 | Avg Accuracy: 51.83 | Model Sparsity: 0.7305
Recovery epoch [4/10]: Avg Loss: 2.8354 | Avg Accuracy: 53.03 | Model Sparsity: 0.7305
Recovery epoch [5/10]: Avg Loss: 2.7610 | Avg Accuracy: 52.82 | Model Sparsity: 0.7305
Recovery epoch [6/10]: Avg Loss: 2.7044 | Avg Accuracy: 54.21 | Model Sparsity: 0.7305
Recovery epoch [7/10]: Avg Loss: 2.6473 | Avg Accuracy: 54.15 | Model Sparsity: 0.7305
Recovery epoch [8/10]: Avg Loss: 2.6065 | Avg Accuracy: 54.62 | Model Sparsity: 0.7305
Recovery epoch [9/10]: Avg Loss: 2.5740 | Avg Accuracy: 54.90 | Model Sparsity: 0.7305
Recovery epoch [10/10]: Avg Loss: 2.5352 | Avg Accuracy: 55.61 | Model Sparsity: 0.7305
Epoch [3/5]: Avg Loss: 3.6184 | Avg Accuracy: 38.11 | Model Sparsity: 0.8571
Recovery epoch [1/10]: Avg Loss: 3.9317 | Avg Accuracy: 41.69 | Model Sparsity: 0.8571
Recovery epoch [2/10]: Avg Loss: 3.6704 | Avg Accuracy: 43.91 | Model Sparsity: 0.8571
Recovery epoch [3/10]: Avg Loss: 3.5123 | Avg Accuracy: 44.87 | Model Sparsity: 0.8571
Recovery epoch [4/10]: Avg Loss: 3.4248 | Avg Accuracy: 45.84 | Model Sparsity: 0.8571
Recovery epoch [5/10]: Avg Loss: 3.3503 | Avg Accuracy: 46.50 | Model Sparsity: 0.8571
Recovery epoch [6/10]: Avg Loss: 3.2771 | Avg Accuracy: 47.18 | Model Sparsity: 0.8571
Recovery epoch [7/10]: Avg Loss: 3.2245 | Avg Accuracy: 47.52 | Model Sparsity: 0.8571
Recovery epoch [8/10]: Avg Loss: 3.1651 | Avg Accuracy: 48.16 | Model Sparsity: 0.8571
Recovery epoch [9/10]: Avg Loss: 3.1337 | Avg Accuracy: 48.46 | Model Sparsity: 0.8571
Recovery epoch [10/10]: Avg Loss: 3.0923 | Avg Accuracy: 48.99 | Model Sparsity: 0.8571
Epoch [4/5]: Avg Loss: 4.0295 | Avg Accuracy: 35.42 | Model Sparsity: 0.922
Recovery epoch [1/10]: Avg Loss: 4.2398 | Avg Accuracy: 38.93 | Model Sparsity: 0.922
Recovery epoch [2/10]: Avg Loss: 3.9918 | Avg Accuracy: 39.69 | Model Sparsity: 0.922
Recovery epoch [3/10]: Avg Loss: 3.8605 | Avg Accuracy: 40.91 | Model Sparsity: 0.922
Recovery epoch [4/10]: Avg Loss: 3.7676 | Avg Accuracy: 41.31 | Model Sparsity: 0.922
Recovery epoch [5/10]: Avg Loss: 3.6940 | Avg Accuracy: 42.51 | Model Sparsity: 0.922
Recovery epoch [6/10]: Avg Loss: 3.6347 | Avg Accuracy: 42.27 | Model Sparsity: 0.922
Recovery epoch [7/10]: Avg Loss: 3.5917 | Avg Accuracy: 43.37 | Model Sparsity: 0.922
Recovery epoch [8/10]: Avg Loss: 3.5362 | Avg Accuracy: 43.86 | Model Sparsity: 0.922
Recovery epoch [9/10]: Avg Loss: 3.4967 | Avg Accuracy: 44.00 | Model Sparsity: 0.922
Recovery epoch [10/10]: Avg Loss: 3.4649 | Avg Accuracy: 44.32 | Model Sparsity: 0.922
Epoch [5/5]: Avg Loss: 4.2078 | Avg Accuracy: 34.17 | Model Sparsity: 0.9552
Recovery epoch [1/10]: Avg Loss: 4.3886 | Avg Accuracy: 36.80 | Model Sparsity: 0.9552
Recovery epoch [2/10]: Avg Loss: 4.1888 | Avg Accuracy: 37.59 | Model Sparsity: 0.9552
Recovery epoch [3/10]: Avg Loss: 4.0721 | Avg Accuracy: 38.31 | Model Sparsity: 0.9552
Recovery epoch [4/10]: Avg Loss: 3.9916 | Avg Accuracy: 39.10 | Model Sparsity: 0.9552
Recovery epoch [5/10]: Avg Loss: 3.9275 | Avg Accuracy: 39.45 | Model Sparsity: 0.9552
Recovery epoch [6/10]: Avg Loss: 3.8751 | Avg Accuracy: 40.44 | Model Sparsity: 0.9552
Recovery epoch [7/10]: Avg Loss: 3.8227 | Avg Accuracy: 40.29 | Model Sparsity: 0.9552
Recovery epoch [8/10]: Avg Loss: 3.7856 | Avg Accuracy: 41.15 | Model Sparsity: 0.9552
Recovery epoch [9/10]: Avg Loss: 3.7409 | Avg Accuracy: 40.92 | Model Sparsity: 0.9552
Recovery epoch [10/10]: Avg Loss: 3.7256 | Avg Accuracy: 41.37 | Model Sparsity: 0.9552
