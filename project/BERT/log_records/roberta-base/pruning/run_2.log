Model : roberta-base - Learning Type: pruning
Configuration:
model_type: llm
model_name: roberta-base
model_task: wikitext2
num_classes: 2
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.97
sparsity_scheduler: cubic
delta_t: 37
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_magnitude_pruning_0.97.pt
finetuned_weights: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_baseline.pt
current_sparsity: 0.0

Epoch [1/5]: Avg Loss: 2.5723 | Avg Accuracy: 64.42 | Model Sparsity: 0.4734
Recovery epoch [1/10]: Avg Loss: 1.9203 | Avg Accuracy: 67.42 | Model Sparsity: 0.4734
Recovery epoch [2/10]: Avg Loss: 1.7662 | Avg Accuracy: 67.95 | Model Sparsity: 0.4734
Recovery epoch [3/10]: Avg Loss: 1.7005 | Avg Accuracy: 68.35 | Model Sparsity: 0.4734
Recovery epoch [4/10]: Avg Loss: 1.6578 | Avg Accuracy: 68.35 | Model Sparsity: 0.4734
Recovery epoch [5/10]: Avg Loss: 1.6206 | Avg Accuracy: 68.76 | Model Sparsity: 0.4734
Recovery epoch [6/10]: Avg Loss: 1.5923 | Avg Accuracy: 68.87 | Model Sparsity: 0.4734
Recovery epoch [7/10]: Avg Loss: 1.5728 | Avg Accuracy: 69.61 | Model Sparsity: 0.4734
Recovery epoch [8/10]: Avg Loss: 1.5445 | Avg Accuracy: 69.85 | Model Sparsity: 0.4734
Recovery epoch [9/10]: Avg Loss: 1.5350 | Avg Accuracy: 69.70 | Model Sparsity: 0.4734
Recovery epoch [10/10]: Avg Loss: 1.5166 | Avg Accuracy: 70.14 | Model Sparsity: 0.4734
Epoch [2/5]: Avg Loss: 4.0980 | Avg Accuracy: 28.54 | Model Sparsity: 0.7157
Recovery epoch [1/10]: Avg Loss: 4.2704 | Avg Accuracy: 47.18 | Model Sparsity: 0.7157
Recovery epoch [2/10]: Avg Loss: 3.3804 | Avg Accuracy: 50.76 | Model Sparsity: 0.7157
Recovery epoch [3/10]: Avg Loss: 3.0839 | Avg Accuracy: 52.81 | Model Sparsity: 0.7157
Recovery epoch [4/10]: Avg Loss: 2.9285 | Avg Accuracy: 54.70 | Model Sparsity: 0.7157
Recovery epoch [5/10]: Avg Loss: 2.8025 | Avg Accuracy: 54.93 | Model Sparsity: 0.7157
Recovery epoch [6/10]: Avg Loss: 2.7278 | Avg Accuracy: 55.49 | Model Sparsity: 0.7157
Recovery epoch [7/10]: Avg Loss: 2.6613 | Avg Accuracy: 56.68 | Model Sparsity: 0.7157
Recovery epoch [8/10]: Avg Loss: 2.5847 | Avg Accuracy: 56.84 | Model Sparsity: 0.7157
Recovery epoch [9/10]: Avg Loss: 2.5428 | Avg Accuracy: 57.31 | Model Sparsity: 0.7157
Recovery epoch [10/10]: Avg Loss: 2.5060 | Avg Accuracy: 57.83 | Model Sparsity: 0.7157
Epoch [3/5]: Avg Loss: 4.4216 | Avg Accuracy: 29.74 | Model Sparsity: 0.8398
Recovery epoch [1/10]: Avg Loss: 4.7998 | Avg Accuracy: 37.73 | Model Sparsity: 0.8398
Recovery epoch [2/10]: Avg Loss: 4.2881 | Avg Accuracy: 39.59 | Model Sparsity: 0.8398
Recovery epoch [3/10]: Avg Loss: 4.0514 | Avg Accuracy: 41.68 | Model Sparsity: 0.8398
Recovery epoch [4/10]: Avg Loss: 3.8828 | Avg Accuracy: 42.69 | Model Sparsity: 0.8398
Recovery epoch [5/10]: Avg Loss: 3.7538 | Avg Accuracy: 43.83 | Model Sparsity: 0.8398
Recovery epoch [6/10]: Avg Loss: 3.6615 | Avg Accuracy: 44.70 | Model Sparsity: 0.8398
Recovery epoch [7/10]: Avg Loss: 3.5831 | Avg Accuracy: 45.52 | Model Sparsity: 0.8398
Recovery epoch [8/10]: Avg Loss: 3.5181 | Avg Accuracy: 45.84 | Model Sparsity: 0.8398
Recovery epoch [9/10]: Avg Loss: 3.4580 | Avg Accuracy: 46.97 | Model Sparsity: 0.8398
Recovery epoch [10/10]: Avg Loss: 3.4150 | Avg Accuracy: 47.65 | Model Sparsity: 0.8398
Epoch [4/5]: Avg Loss: 4.8223 | Avg Accuracy: 29.45 | Model Sparsity: 0.9033
Recovery epoch [1/10]: Avg Loss: 5.0257 | Avg Accuracy: 34.27 | Model Sparsity: 0.9033
Recovery epoch [2/10]: Avg Loss: 4.5913 | Avg Accuracy: 36.39 | Model Sparsity: 0.9033
Recovery epoch [3/10]: Avg Loss: 4.4011 | Avg Accuracy: 38.15 | Model Sparsity: 0.9033
Recovery epoch [4/10]: Avg Loss: 4.2561 | Avg Accuracy: 38.67 | Model Sparsity: 0.9033
Recovery epoch [5/10]: Avg Loss: 4.1662 | Avg Accuracy: 39.81 | Model Sparsity: 0.9033
Recovery epoch [6/10]: Avg Loss: 4.0662 | Avg Accuracy: 40.04 | Model Sparsity: 0.9033
Recovery epoch [7/10]: Avg Loss: 4.0194 | Avg Accuracy: 40.90 | Model Sparsity: 0.9033
Recovery epoch [8/10]: Avg Loss: 3.9544 | Avg Accuracy: 41.21 | Model Sparsity: 0.9033
Recovery epoch [9/10]: Avg Loss: 3.9170 | Avg Accuracy: 40.92 | Model Sparsity: 0.9033
Recovery epoch [10/10]: Avg Loss: 3.8644 | Avg Accuracy: 42.61 | Model Sparsity: 0.9033
Epoch [5/5]: Avg Loss: 4.7198 | Avg Accuracy: 31.42 | Model Sparsity: 0.9359
Recovery epoch [1/10]: Avg Loss: 4.8065 | Avg Accuracy: 34.91 | Model Sparsity: 0.9359
Recovery epoch [2/10]: Avg Loss: 4.5340 | Avg Accuracy: 36.09 | Model Sparsity: 0.9359
Recovery epoch [3/10]: Avg Loss: 4.3947 | Avg Accuracy: 37.28 | Model Sparsity: 0.9359
Recovery epoch [4/10]: Avg Loss: 4.2922 | Avg Accuracy: 37.99 | Model Sparsity: 0.9359
Recovery epoch [5/10]: Avg Loss: 4.2246 | Avg Accuracy: 38.66 | Model Sparsity: 0.9359
Recovery epoch [6/10]: Avg Loss: 4.1746 | Avg Accuracy: 39.08 | Model Sparsity: 0.9359
Recovery epoch [7/10]: Avg Loss: 4.1166 | Avg Accuracy: 39.00 | Model Sparsity: 0.9359
Recovery epoch [8/10]: Avg Loss: 4.0763 | Avg Accuracy: 39.36 | Model Sparsity: 0.9359
Recovery epoch [9/10]: Avg Loss: 4.0393 | Avg Accuracy: 39.56 | Model Sparsity: 0.9359
Recovery epoch [10/10]: Avg Loss: 4.0068 | Avg Accuracy: 39.94 | Model Sparsity: 0.9359
