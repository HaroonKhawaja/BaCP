Model : roberta-base - Learning Type: pruning
Configuration:
model_type: llm
model_name: roberta-base
model_task: wikitext2
num_classes: 2
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: wanda_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
delta_t: 37
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_wanda_pruning_0.95.pt
finetuned_weights: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_baseline.pt
current_sparsity: 0.0

Epoch [1/5]: Avg Loss: 1.5582 | Avg Accuracy: 69.29 | Model Sparsity: 0.4604
Recovery epoch [1/10]: Avg Loss: 1.5530 | Avg Accuracy: 70.03 | Model Sparsity: 0.4604
Recovery epoch [2/10]: Avg Loss: 1.5040 | Avg Accuracy: 69.93 | Model Sparsity: 0.4604
Recovery epoch [3/10]: Avg Loss: 1.4754 | Avg Accuracy: 70.41 | Model Sparsity: 0.4604
Recovery epoch [4/10]: Avg Loss: 1.4553 | Avg Accuracy: 70.12 | Model Sparsity: 0.4604
Recovery epoch [5/10]: Avg Loss: 1.4377 | Avg Accuracy: 70.80 | Model Sparsity: 0.4604
Recovery epoch [6/10]: Avg Loss: 1.4215 | Avg Accuracy: 70.65 | Model Sparsity: 0.4604
Recovery epoch [7/10]: Avg Loss: 1.4138 | Avg Accuracy: 70.82 | Model Sparsity: 0.4604
Recovery epoch [8/10]: Avg Loss: 1.4009 | Avg Accuracy: 70.75 | Model Sparsity: 0.4604
Recovery epoch [9/10]: Avg Loss: 1.3946 | Avg Accuracy: 70.78 | Model Sparsity: 0.4604
Recovery epoch [10/10]: Avg Loss: 1.3783 | Avg Accuracy: 71.04 | Model Sparsity: 0.4604
Epoch [2/5]: Avg Loss: 2.1127 | Avg Accuracy: 57.56 | Model Sparsity: 0.6945
Recovery epoch [1/10]: Avg Loss: 2.3615 | Avg Accuracy: 60.02 | Model Sparsity: 0.6945
Recovery epoch [2/10]: Avg Loss: 2.2234 | Avg Accuracy: 60.65 | Model Sparsity: 0.6945
Recovery epoch [3/10]: Avg Loss: 2.1589 | Avg Accuracy: 61.31 | Model Sparsity: 0.6945
Recovery epoch [4/10]: Avg Loss: 2.0988 | Avg Accuracy: 61.84 | Model Sparsity: 0.6945
Recovery epoch [5/10]: Avg Loss: 2.0637 | Avg Accuracy: 61.92 | Model Sparsity: 0.6945
Recovery epoch [6/10]: Avg Loss: 2.0196 | Avg Accuracy: 62.81 | Model Sparsity: 0.6945
Recovery epoch [7/10]: Avg Loss: 1.9930 | Avg Accuracy: 63.22 | Model Sparsity: 0.6945
Recovery epoch [8/10]: Avg Loss: 1.9665 | Avg Accuracy: 62.90 | Model Sparsity: 0.6945
Recovery epoch [9/10]: Avg Loss: 1.9372 | Avg Accuracy: 63.02 | Model Sparsity: 0.6945
Recovery epoch [10/10]: Avg Loss: 1.9188 | Avg Accuracy: 62.70 | Model Sparsity: 0.6945
Epoch [3/5]: Avg Loss: 2.6992 | Avg Accuracy: 49.75 | Model Sparsity: 0.8135
Recovery epoch [1/10]: Avg Loss: 3.0278 | Avg Accuracy: 52.06 | Model Sparsity: 0.8135
Recovery epoch [2/10]: Avg Loss: 2.8715 | Avg Accuracy: 52.47 | Model Sparsity: 0.8135
Recovery epoch [3/10]: Avg Loss: 2.7754 | Avg Accuracy: 53.53 | Model Sparsity: 0.8135
Recovery epoch [4/10]: Avg Loss: 2.7119 | Avg Accuracy: 54.28 | Model Sparsity: 0.8135
Recovery epoch [5/10]: Avg Loss: 2.6564 | Avg Accuracy: 54.80 | Model Sparsity: 0.8135
Recovery epoch [6/10]: Avg Loss: 2.6159 | Avg Accuracy: 55.14 | Model Sparsity: 0.8135
Recovery epoch [7/10]: Avg Loss: 2.5802 | Avg Accuracy: 55.00 | Model Sparsity: 0.8135
Recovery epoch [8/10]: Avg Loss: 2.5455 | Avg Accuracy: 56.01 | Model Sparsity: 0.8135
Recovery epoch [9/10]: Avg Loss: 2.5206 | Avg Accuracy: 55.63 | Model Sparsity: 0.8135
Recovery epoch [10/10]: Avg Loss: 2.4856 | Avg Accuracy: 56.18 | Model Sparsity: 0.8135
Epoch [4/5]: Avg Loss: 3.0715 | Avg Accuracy: 46.98 | Model Sparsity: 0.8741
Recovery epoch [1/10]: Avg Loss: 3.2764 | Avg Accuracy: 49.21 | Model Sparsity: 0.8741
Recovery epoch [2/10]: Avg Loss: 3.1162 | Avg Accuracy: 49.63 | Model Sparsity: 0.8741
Recovery epoch [3/10]: Avg Loss: 3.0411 | Avg Accuracy: 50.11 | Model Sparsity: 0.8741
Recovery epoch [4/10]: Avg Loss: 2.9770 | Avg Accuracy: 50.53 | Model Sparsity: 0.8741
Recovery epoch [5/10]: Avg Loss: 2.9441 | Avg Accuracy: 50.86 | Model Sparsity: 0.8741
Recovery epoch [6/10]: Avg Loss: 2.8907 | Avg Accuracy: 51.32 | Model Sparsity: 0.8741
Recovery epoch [7/10]: Avg Loss: 2.8670 | Avg Accuracy: 51.33 | Model Sparsity: 0.8741
Recovery epoch [8/10]: Avg Loss: 2.8349 | Avg Accuracy: 51.54 | Model Sparsity: 0.8741
Recovery epoch [9/10]: Avg Loss: 2.8103 | Avg Accuracy: 51.76 | Model Sparsity: 0.8741
Recovery epoch [10/10]: Avg Loss: 2.7753 | Avg Accuracy: 51.75 | Model Sparsity: 0.8741
Epoch [5/5]: Avg Loss: 3.2118 | Avg Accuracy: 45.92 | Model Sparsity: 0.9048
Recovery epoch [1/10]: Avg Loss: 3.2755 | Avg Accuracy: 48.32 | Model Sparsity: 0.9048
Recovery epoch [2/10]: Avg Loss: 3.1533 | Avg Accuracy: 48.76 | Model Sparsity: 0.9048
Recovery epoch [3/10]: Avg Loss: 3.0871 | Avg Accuracy: 49.15 | Model Sparsity: 0.9048
Recovery epoch [4/10]: Avg Loss: 3.0370 | Avg Accuracy: 49.60 | Model Sparsity: 0.9048
Recovery epoch [5/10]: Avg Loss: 3.0017 | Avg Accuracy: 50.08 | Model Sparsity: 0.9048
Recovery epoch [6/10]: Avg Loss: 2.9683 | Avg Accuracy: 50.07 | Model Sparsity: 0.9048
Recovery epoch [7/10]: Avg Loss: 2.9468 | Avg Accuracy: 50.15 | Model Sparsity: 0.9048
Recovery epoch [8/10]: Avg Loss: 2.9281 | Avg Accuracy: 50.77 | Model Sparsity: 0.9048
Recovery epoch [9/10]: Avg Loss: 2.8958 | Avg Accuracy: 50.74 | Model Sparsity: 0.9048
Recovery epoch [10/10]: Avg Loss: 2.8891 | Avg Accuracy: 51.40 | Model Sparsity: 0.9048
