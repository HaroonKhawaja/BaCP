Model : roberta-base - Learning Type: pruning
Configuration:
model_type: llm
model_name: roberta-base
model_task: wikitext2
num_classes: 2
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
delta_t: 37
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_magnitude_pruning_0.95.pt
finetuned_weights: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_baseline.pt
current_sparsity: 0.0

Epoch [1/5]: Avg Loss: 2.4602 | Avg Accuracy: 64.34 | Model Sparsity: 0.4636
Recovery epoch [1/10]: Avg Loss: 1.8743 | Avg Accuracy: 66.92 | Model Sparsity: 0.4636
Recovery epoch [2/10]: Avg Loss: 1.7189 | Avg Accuracy: 68.58 | Model Sparsity: 0.4636
Recovery epoch [3/10]: Avg Loss: 1.6678 | Avg Accuracy: 68.41 | Model Sparsity: 0.4636
Recovery epoch [4/10]: Avg Loss: 1.6263 | Avg Accuracy: 69.02 | Model Sparsity: 0.4636
Recovery epoch [5/10]: Avg Loss: 1.5967 | Avg Accuracy: 69.15 | Model Sparsity: 0.4636
Recovery epoch [6/10]: Avg Loss: 1.5672 | Avg Accuracy: 69.58 | Model Sparsity: 0.4636
Recovery epoch [7/10]: Avg Loss: 1.5415 | Avg Accuracy: 69.60 | Model Sparsity: 0.4636
Recovery epoch [8/10]: Avg Loss: 1.5277 | Avg Accuracy: 69.74 | Model Sparsity: 0.4636
Recovery epoch [9/10]: Avg Loss: 1.4979 | Avg Accuracy: 69.86 | Model Sparsity: 0.4636
Recovery epoch [10/10]: Avg Loss: 1.4839 | Avg Accuracy: 70.06 | Model Sparsity: 0.4636
Epoch [2/5]: Avg Loss: 3.6612 | Avg Accuracy: 38.30 | Model Sparsity: 0.701
Recovery epoch [1/10]: Avg Loss: 3.5904 | Avg Accuracy: 51.58 | Model Sparsity: 0.701
Recovery epoch [2/10]: Avg Loss: 2.9969 | Avg Accuracy: 54.65 | Model Sparsity: 0.701
Recovery epoch [3/10]: Avg Loss: 2.7850 | Avg Accuracy: 56.17 | Model Sparsity: 0.701
Recovery epoch [4/10]: Avg Loss: 2.6616 | Avg Accuracy: 57.03 | Model Sparsity: 0.701
Recovery epoch [5/10]: Avg Loss: 2.5785 | Avg Accuracy: 58.19 | Model Sparsity: 0.701
Recovery epoch [6/10]: Avg Loss: 2.5014 | Avg Accuracy: 58.56 | Model Sparsity: 0.701
Recovery epoch [7/10]: Avg Loss: 2.4439 | Avg Accuracy: 57.99 | Model Sparsity: 0.701
Recovery epoch [8/10]: Avg Loss: 2.3984 | Avg Accuracy: 58.71 | Model Sparsity: 0.701
Recovery epoch [9/10]: Avg Loss: 2.3538 | Avg Accuracy: 59.41 | Model Sparsity: 0.701
Recovery epoch [10/10]: Avg Loss: 2.3050 | Avg Accuracy: 59.61 | Model Sparsity: 0.701
Epoch [3/5]: Avg Loss: 3.8479 | Avg Accuracy: 36.51 | Model Sparsity: 0.8225
Recovery epoch [1/10]: Avg Loss: 4.1447 | Avg Accuracy: 42.83 | Model Sparsity: 0.8225
Recovery epoch [2/10]: Avg Loss: 3.7637 | Avg Accuracy: 45.17 | Model Sparsity: 0.8225
Recovery epoch [3/10]: Avg Loss: 3.5684 | Avg Accuracy: 46.94 | Model Sparsity: 0.8225
Recovery epoch [4/10]: Avg Loss: 3.4331 | Avg Accuracy: 47.06 | Model Sparsity: 0.8225
Recovery epoch [5/10]: Avg Loss: 3.3399 | Avg Accuracy: 48.11 | Model Sparsity: 0.8225
Recovery epoch [6/10]: Avg Loss: 3.2653 | Avg Accuracy: 49.31 | Model Sparsity: 0.8225
Recovery epoch [7/10]: Avg Loss: 3.2114 | Avg Accuracy: 49.51 | Model Sparsity: 0.8225
Recovery epoch [8/10]: Avg Loss: 3.1422 | Avg Accuracy: 49.47 | Model Sparsity: 0.8225
Recovery epoch [9/10]: Avg Loss: 3.1018 | Avg Accuracy: 50.41 | Model Sparsity: 0.8225
Recovery epoch [10/10]: Avg Loss: 3.0501 | Avg Accuracy: 50.12 | Model Sparsity: 0.8225
Epoch [4/5]: Avg Loss: 4.1438 | Avg Accuracy: 35.97 | Model Sparsity: 0.8847
Recovery epoch [1/10]: Avg Loss: 4.2724 | Avg Accuracy: 40.49 | Model Sparsity: 0.8847
Recovery epoch [2/10]: Avg Loss: 3.9564 | Avg Accuracy: 42.12 | Model Sparsity: 0.8847
Recovery epoch [3/10]: Avg Loss: 3.8064 | Avg Accuracy: 43.15 | Model Sparsity: 0.8847
Recovery epoch [4/10]: Avg Loss: 3.7106 | Avg Accuracy: 43.96 | Model Sparsity: 0.8847
Recovery epoch [5/10]: Avg Loss: 3.6367 | Avg Accuracy: 44.79 | Model Sparsity: 0.8847
Recovery epoch [6/10]: Avg Loss: 3.5644 | Avg Accuracy: 44.82 | Model Sparsity: 0.8847
Recovery epoch [7/10]: Avg Loss: 3.5200 | Avg Accuracy: 45.60 | Model Sparsity: 0.8847
Recovery epoch [8/10]: Avg Loss: 3.4776 | Avg Accuracy: 45.79 | Model Sparsity: 0.8847
Recovery epoch [9/10]: Avg Loss: 3.4327 | Avg Accuracy: 46.41 | Model Sparsity: 0.8847
Recovery epoch [10/10]: Avg Loss: 3.3966 | Avg Accuracy: 46.12 | Model Sparsity: 0.8847
Epoch [5/5]: Avg Loss: 4.1099 | Avg Accuracy: 37.60 | Model Sparsity: 0.9166
Recovery epoch [1/10]: Avg Loss: 4.1183 | Avg Accuracy: 40.55 | Model Sparsity: 0.9166
Recovery epoch [2/10]: Avg Loss: 3.9001 | Avg Accuracy: 41.89 | Model Sparsity: 0.9166
Recovery epoch [3/10]: Avg Loss: 3.7850 | Avg Accuracy: 43.07 | Model Sparsity: 0.9166
Recovery epoch [4/10]: Avg Loss: 3.7054 | Avg Accuracy: 42.82 | Model Sparsity: 0.9166
Recovery epoch [5/10]: Avg Loss: 3.6516 | Avg Accuracy: 43.55 | Model Sparsity: 0.9166
