Model : roberta-base - Learning Type: pruning
Configuration:
model_type: llm
model_name: roberta-base
model_task: wikitext2
num_classes: 2
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: wanda_pruning
target_sparsity: 0.97
sparsity_scheduler: cubic
delta_t: 37
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_wanda_pruning_0.97.pt
finetuned_weights: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_baseline.pt
current_sparsity: 0.0

Epoch [1/5]: Avg Loss: 1.5512 | Avg Accuracy: 68.83 | Model Sparsity: 0.4701
Recovery epoch [1/10]: Avg Loss: 1.5624 | Avg Accuracy: 69.72 | Model Sparsity: 0.4701
Recovery epoch [2/10]: Avg Loss: 1.5235 | Avg Accuracy: 69.80 | Model Sparsity: 0.4701
Recovery epoch [3/10]: Avg Loss: 1.4912 | Avg Accuracy: 70.43 | Model Sparsity: 0.4701
Recovery epoch [4/10]: Avg Loss: 1.4862 | Avg Accuracy: 70.29 | Model Sparsity: 0.4701
Recovery epoch [5/10]: Avg Loss: 1.4556 | Avg Accuracy: 70.23 | Model Sparsity: 0.4701
Recovery epoch [6/10]: Avg Loss: 1.4483 | Avg Accuracy: 70.41 | Model Sparsity: 0.4701
Recovery epoch [7/10]: Avg Loss: 1.4325 | Avg Accuracy: 70.45 | Model Sparsity: 0.4701
Recovery epoch [8/10]: Avg Loss: 1.4159 | Avg Accuracy: 70.63 | Model Sparsity: 0.4701
Recovery epoch [9/10]: Avg Loss: 1.4026 | Avg Accuracy: 70.74 | Model Sparsity: 0.4701
Recovery epoch [10/10]: Avg Loss: 1.3902 | Avg Accuracy: 70.88 | Model Sparsity: 0.4701
Epoch [2/5]: Avg Loss: 2.2339 | Avg Accuracy: 56.12 | Model Sparsity: 0.7091
Recovery epoch [1/10]: Avg Loss: 2.5054 | Avg Accuracy: 58.37 | Model Sparsity: 0.7091
Recovery epoch [2/10]: Avg Loss: 2.3485 | Avg Accuracy: 59.28 | Model Sparsity: 0.7091
Recovery epoch [3/10]: Avg Loss: 2.2622 | Avg Accuracy: 60.21 | Model Sparsity: 0.7091
Recovery epoch [4/10]: Avg Loss: 2.1982 | Avg Accuracy: 60.68 | Model Sparsity: 0.7091
Recovery epoch [5/10]: Avg Loss: 2.1729 | Avg Accuracy: 60.71 | Model Sparsity: 0.7091
Recovery epoch [6/10]: Avg Loss: 2.1190 | Avg Accuracy: 61.61 | Model Sparsity: 0.7091
Recovery epoch [7/10]: Avg Loss: 2.0805 | Avg Accuracy: 61.21 | Model Sparsity: 0.7091
Recovery epoch [8/10]: Avg Loss: 2.0510 | Avg Accuracy: 61.50 | Model Sparsity: 0.7091
Recovery epoch [9/10]: Avg Loss: 2.0295 | Avg Accuracy: 62.39 | Model Sparsity: 0.7091
Recovery epoch [10/10]: Avg Loss: 1.9987 | Avg Accuracy: 61.94 | Model Sparsity: 0.7091
Epoch [3/5]: Avg Loss: 2.9523 | Avg Accuracy: 46.90 | Model Sparsity: 0.8307
Recovery epoch [1/10]: Avg Loss: 3.2811 | Avg Accuracy: 49.50 | Model Sparsity: 0.8307
Recovery epoch [2/10]: Avg Loss: 3.0871 | Avg Accuracy: 51.37 | Model Sparsity: 0.8307
Recovery epoch [3/10]: Avg Loss: 2.9735 | Avg Accuracy: 51.37 | Model Sparsity: 0.8307
Recovery epoch [4/10]: Avg Loss: 2.9107 | Avg Accuracy: 52.02 | Model Sparsity: 0.8307
Recovery epoch [5/10]: Avg Loss: 2.8475 | Avg Accuracy: 52.64 | Model Sparsity: 0.8307
Recovery epoch [6/10]: Avg Loss: 2.7853 | Avg Accuracy: 52.23 | Model Sparsity: 0.8307
Recovery epoch [7/10]: Avg Loss: 2.7435 | Avg Accuracy: 53.53 | Model Sparsity: 0.8307
Recovery epoch [8/10]: Avg Loss: 2.7119 | Avg Accuracy: 53.76 | Model Sparsity: 0.8307
Recovery epoch [9/10]: Avg Loss: 2.6716 | Avg Accuracy: 54.23 | Model Sparsity: 0.8307
Recovery epoch [10/10]: Avg Loss: 2.6531 | Avg Accuracy: 53.92 | Model Sparsity: 0.8307
Epoch [4/5]: Avg Loss: 3.3347 | Avg Accuracy: 43.21 | Model Sparsity: 0.8925
Recovery epoch [1/10]: Avg Loss: 3.5655 | Avg Accuracy: 46.11 | Model Sparsity: 0.8925
Recovery epoch [2/10]: Avg Loss: 3.4013 | Avg Accuracy: 46.56 | Model Sparsity: 0.8925
Recovery epoch [3/10]: Avg Loss: 3.3005 | Avg Accuracy: 47.13 | Model Sparsity: 0.8925
Recovery epoch [4/10]: Avg Loss: 3.2315 | Avg Accuracy: 47.75 | Model Sparsity: 0.8925
Recovery epoch [5/10]: Avg Loss: 3.1798 | Avg Accuracy: 48.64 | Model Sparsity: 0.8925
Recovery epoch [6/10]: Avg Loss: 3.1412 | Avg Accuracy: 48.21 | Model Sparsity: 0.8925
Recovery epoch [7/10]: Avg Loss: 3.1037 | Avg Accuracy: 49.67 | Model Sparsity: 0.8925
Recovery epoch [8/10]: Avg Loss: 3.0777 | Avg Accuracy: 49.31 | Model Sparsity: 0.8925
Recovery epoch [9/10]: Avg Loss: 3.0417 | Avg Accuracy: 49.72 | Model Sparsity: 0.8925
Recovery epoch [10/10]: Avg Loss: 3.0142 | Avg Accuracy: 50.13 | Model Sparsity: 0.8925
Epoch [5/5]: Avg Loss: 3.5217 | Avg Accuracy: 42.48 | Model Sparsity: 0.9239
Recovery epoch [1/10]: Avg Loss: 3.6165 | Avg Accuracy: 45.00 | Model Sparsity: 0.9239
Recovery epoch [2/10]: Avg Loss: 3.4840 | Avg Accuracy: 45.84 | Model Sparsity: 0.9239
Recovery epoch [3/10]: Avg Loss: 3.4000 | Avg Accuracy: 46.19 | Model Sparsity: 0.9239
Recovery epoch [4/10]: Avg Loss: 3.3258 | Avg Accuracy: 46.53 | Model Sparsity: 0.9239
Recovery epoch [5/10]: Avg Loss: 3.2991 | Avg Accuracy: 46.63 | Model Sparsity: 0.9239
Recovery epoch [6/10]: Avg Loss: 3.2631 | Avg Accuracy: 46.74 | Model Sparsity: 0.9239
Recovery epoch [7/10]: Avg Loss: 3.2278 | Avg Accuracy: 47.11 | Model Sparsity: 0.9239
Recovery epoch [8/10]: Avg Loss: 3.2114 | Avg Accuracy: 47.36 | Model Sparsity: 0.9239
Recovery epoch [9/10]: Avg Loss: 3.1716 | Avg Accuracy: 47.77 | Model Sparsity: 0.9239
Recovery epoch [10/10]: Avg Loss: 3.1432 | Avg Accuracy: 47.80 | Model Sparsity: 0.9239
