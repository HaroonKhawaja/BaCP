Model : roberta-base - Learning Type: pruning
Configuration:
model_type: llm
model_name: roberta-base
model_task: wikitext2
num_classes: 2
embedding_dim: 768
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 64
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.99
sparsity_scheduler: cubic
delta_t: 37
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_magnitude_pruning_0.99.pt
finetuned_weights: /dbfs/research/roberta-base/wikitext2/roberta-base_wikitext2_baseline.pt
current_sparsity: 0.0

Epoch [1/5]: Avg Loss: 2.5868 | Avg Accuracy: 63.13 | Model Sparsity: 0.4831
Recovery epoch [1/10]: Avg Loss: 1.9663 | Avg Accuracy: 66.31 | Model Sparsity: 0.4831
Recovery epoch [2/10]: Avg Loss: 1.8062 | Avg Accuracy: 67.08 | Model Sparsity: 0.4831
Recovery epoch [3/10]: Avg Loss: 1.7300 | Avg Accuracy: 67.75 | Model Sparsity: 0.4831
Recovery epoch [4/10]: Avg Loss: 1.6857 | Avg Accuracy: 68.08 | Model Sparsity: 0.4831
Recovery epoch [5/10]: Avg Loss: 1.6477 | Avg Accuracy: 69.08 | Model Sparsity: 0.4831
Recovery epoch [6/10]: Avg Loss: 1.6234 | Avg Accuracy: 68.76 | Model Sparsity: 0.4831
Recovery epoch [7/10]: Avg Loss: 1.6010 | Avg Accuracy: 69.25 | Model Sparsity: 0.4831
Recovery epoch [8/10]: Avg Loss: 1.5710 | Avg Accuracy: 69.41 | Model Sparsity: 0.4831
Recovery epoch [9/10]: Avg Loss: 1.5486 | Avg Accuracy: 69.55 | Model Sparsity: 0.4831
Recovery epoch [10/10]: Avg Loss: 1.5368 | Avg Accuracy: 69.50 | Model Sparsity: 0.4831
Epoch [2/5]: Avg Loss: 4.3755 | Avg Accuracy: 21.40 | Model Sparsity: 0.7305
Recovery epoch [1/10]: Avg Loss: 5.0255 | Avg Accuracy: 40.86 | Model Sparsity: 0.7305
Recovery epoch [2/10]: Avg Loss: 3.8205 | Avg Accuracy: 47.22 | Model Sparsity: 0.7305
Recovery epoch [3/10]: Avg Loss: 3.4068 | Avg Accuracy: 50.34 | Model Sparsity: 0.7305
Recovery epoch [4/10]: Avg Loss: 3.1702 | Avg Accuracy: 51.76 | Model Sparsity: 0.7305
Recovery epoch [5/10]: Avg Loss: 3.0273 | Avg Accuracy: 52.92 | Model Sparsity: 0.7305
Recovery epoch [6/10]: Avg Loss: 2.9146 | Avg Accuracy: 53.65 | Model Sparsity: 0.7305
Recovery epoch [7/10]: Avg Loss: 2.8452 | Avg Accuracy: 54.78 | Model Sparsity: 0.7305
Recovery epoch [8/10]: Avg Loss: 2.7707 | Avg Accuracy: 55.01 | Model Sparsity: 0.7305
Recovery epoch [9/10]: Avg Loss: 2.7071 | Avg Accuracy: 55.22 | Model Sparsity: 0.7305
Recovery epoch [10/10]: Avg Loss: 2.6712 | Avg Accuracy: 55.97 | Model Sparsity: 0.7305
Epoch [3/5]: Avg Loss: 4.6900 | Avg Accuracy: 25.55 | Model Sparsity: 0.8571
Recovery epoch [1/10]: Avg Loss: 5.3109 | Avg Accuracy: 32.92 | Model Sparsity: 0.8571
Recovery epoch [2/10]: Avg Loss: 4.7193 | Avg Accuracy: 36.15 | Model Sparsity: 0.8571
Recovery epoch [3/10]: Avg Loss: 4.4495 | Avg Accuracy: 37.30 | Model Sparsity: 0.8571
Recovery epoch [4/10]: Avg Loss: 4.2707 | Avg Accuracy: 38.91 | Model Sparsity: 0.8571
Recovery epoch [5/10]: Avg Loss: 4.1285 | Avg Accuracy: 40.17 | Model Sparsity: 0.8571
Recovery epoch [6/10]: Avg Loss: 4.0148 | Avg Accuracy: 41.39 | Model Sparsity: 0.8571
Recovery epoch [7/10]: Avg Loss: 3.9235 | Avg Accuracy: 41.29 | Model Sparsity: 0.8571
Recovery epoch [8/10]: Avg Loss: 3.8425 | Avg Accuracy: 42.72 | Model Sparsity: 0.8571
Recovery epoch [9/10]: Avg Loss: 3.7734 | Avg Accuracy: 42.65 | Model Sparsity: 0.8571
Recovery epoch [10/10]: Avg Loss: 3.7137 | Avg Accuracy: 43.61 | Model Sparsity: 0.8571
Epoch [4/5]: Avg Loss: 5.2644 | Avg Accuracy: 24.97 | Model Sparsity: 0.922
Recovery epoch [1/10]: Avg Loss: 5.6011 | Avg Accuracy: 29.87 | Model Sparsity: 0.922
Recovery epoch [2/10]: Avg Loss: 5.1310 | Avg Accuracy: 32.02 | Model Sparsity: 0.922
Recovery epoch [3/10]: Avg Loss: 4.8951 | Avg Accuracy: 33.31 | Model Sparsity: 0.922
Recovery epoch [4/10]: Avg Loss: 4.7482 | Avg Accuracy: 33.78 | Model Sparsity: 0.922
Recovery epoch [5/10]: Avg Loss: 4.6253 | Avg Accuracy: 34.91 | Model Sparsity: 0.922
Recovery epoch [6/10]: Avg Loss: 4.5493 | Avg Accuracy: 35.25 | Model Sparsity: 0.922
Recovery epoch [7/10]: Avg Loss: 4.4693 | Avg Accuracy: 36.28 | Model Sparsity: 0.922
Recovery epoch [8/10]: Avg Loss: 4.4091 | Avg Accuracy: 36.16 | Model Sparsity: 0.922
Recovery epoch [9/10]: Avg Loss: 4.3441 | Avg Accuracy: 36.95 | Model Sparsity: 0.922
Recovery epoch [10/10]: Avg Loss: 4.2934 | Avg Accuracy: 37.63 | Model Sparsity: 0.922
Epoch [5/5]: Avg Loss: 5.2736 | Avg Accuracy: 26.59 | Model Sparsity: 0.9552
Recovery epoch [1/10]: Avg Loss: 5.4541 | Avg Accuracy: 30.28 | Model Sparsity: 0.9552
Recovery epoch [2/10]: Avg Loss: 5.1286 | Avg Accuracy: 31.68 | Model Sparsity: 0.9552
Recovery epoch [3/10]: Avg Loss: 4.9614 | Avg Accuracy: 32.31 | Model Sparsity: 0.9552
Recovery epoch [4/10]: Avg Loss: 4.8553 | Avg Accuracy: 32.67 | Model Sparsity: 0.9552
Recovery epoch [5/10]: Avg Loss: 4.7795 | Avg Accuracy: 33.28 | Model Sparsity: 0.9552
Recovery epoch [6/10]: Avg Loss: 4.7196 | Avg Accuracy: 33.22 | Model Sparsity: 0.9552
Recovery epoch [7/10]: Avg Loss: 4.6649 | Avg Accuracy: 33.50 | Model Sparsity: 0.9552
Recovery epoch [8/10]: Avg Loss: 4.6189 | Avg Accuracy: 33.99 | Model Sparsity: 0.9552
Recovery epoch [9/10]: Avg Loss: 4.5834 | Avg Accuracy: 34.28 | Model Sparsity: 0.9552
Recovery epoch [10/10]: Avg Loss: 4.5401 | Avg Accuracy: 35.25 | Model Sparsity: 0.9552
