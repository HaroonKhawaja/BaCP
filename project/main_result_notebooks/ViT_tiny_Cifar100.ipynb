{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f54e966b-7ff2-4970-943d-3aac60708d21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e7dfa07-3f93-4761-9624-5667e6011be5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from constants import (\n",
    "    TARGET_SPARSITY_LOW, TARGET_SPARSITY_MID, TARGET_SPARSITY_HIGH,\n",
    "    BATCH_SIZE_CNN, BATCH_SIZE_VIT, BATCH_SIZE_LLM,\n",
    "    EPOCHS_SMALL_MODEL, EPOCHS_LARGE_MODEL, EPOCHS_VIT\n",
    ")\n",
    "from utils import get_device, get_num_workers, load_weights, print_statistics\n",
    "from unstructured_pruning import check_model_sparsity, check_sparsity_distribution\n",
    "from trainer import TrainingArguments, Trainer\n",
    "from bacp import BaCPTrainingArguments, BaCPTrainer\n",
    "\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "disable_progress_bar()\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/dbfs/hf_datasets\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42800ed7-1ff4-4ad6-91ad-6528c5b5f71c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = get_device()\n",
    "NUM_WORKERS = get_num_workers()\n",
    "print(\"Using device:\", DEVICE)\n",
    "print(\"Using\", NUM_WORKERS, \"workers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45d6dfb0-8f3c-4f01-8967-63405f3cbe3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ViT-Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a5d677d-7dc6-4a71-895d-6e6a26a3c852",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Notebook specific variables\n",
    "MODEL_NAME = 'vit_tiny'\n",
    "MODEL_TASK = 'cifar100'\n",
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64abd2b8-5626-4af3-95c7-6156e6d2e54a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "356a8caa-cf41-4280-89ea-8500ab3932c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.01),\n",
    "    scheduler_type='linear_with_warmup',\n",
    "    epochs=10,\n",
    "    learning_type=\"baseline\",\n",
    "    db=False\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if False:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c42e7a7-7ec4-400a-880f-d795c3488ba2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pruning Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d52b36d-1357-4357-b3af-597ff9ee5958",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Magnitude Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "986acd97-7675-499d-93b8-954bd0e255eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('adamw', 0.001),\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17f6b6a3-4923-44f5-a914-d654b11a2fc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('adamw', 0.001),\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b40d89be-4870-4c84-9e9a-b424ad9e356e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('adamw', 0.001),\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2764b56-71b5-4342-bfd8-764b69deed30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SNIP-it Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9108458a-ba42-4559-b995-1e1d9824f124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('adamw', 0.001),\n",
    "    pruning_type=\"snip_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c142d32-dc70-4b5f-81e5-81f5f57b78fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('adamw', 0.001),\n",
    "    pruning_type=\"snip_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b34a40e7-3087-4506-ac9c-537766579b18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('adamw', 0.001),\n",
    "    pruning_type=\"snip_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fec20c2a-3641-4525-bb90-c04770a2c917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Wanda Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "317bd431-94a5-4b5b-ae0a-919f097029bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('adamw', 0.001),\n",
    "    pruning_type=\"wanda_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dead20e4-55cb-4f07-be3c-399b87c1e2fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('adamw', 0.001),\n",
    "    pruning_type=\"wanda_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3a50b0e-5478-4663-9f9b-71291eb2c5c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('adamw', 0.001),\n",
    "    pruning_type=\"wanda_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "956d54dd-72b4-4d82-b70f-ec16e84750fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## BaCP Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b1f60ba-0f4d-48f5-9b88-fc11fc393ffa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Magnitude Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0424487-8c14-43d7-9999-6f2b019791e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m bacp_trainer \u001b[38;5;241m=\u001b[39m BaCPTrainer(bacp_training_args\u001b[38;5;241m=\u001b[39mbacp_training_args)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAIN:\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mbacp_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Finetuning Phase\u001b[39;00m\n\u001b[1;32m     21\u001b[0m bacp_trainer\u001b[38;5;241m.\u001b[39mgenerate_mask_from_model()\n",
      "File \u001b[0;32m~/BaCP-5/project/bacp.py:228\u001b[0m, in \u001b[0;36mBaCPTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[BaCP] weights saved!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpruner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m          \n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msnapshots) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpruning_epochs:\n\u001b[1;32m    231\u001b[0m     state \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "File \u001b[0;32m~/BaCP-5/project/bacp.py:240\u001b[0m, in \u001b[0;36mBaCPTrainer.retrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecovery_epochs):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetraining epoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecovery_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# Printing statistics\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     sparsity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sparsity_key()\n",
      "File \u001b[0;32m~/BaCP-5/project/bacp.py:408\u001b[0m, in \u001b[0;36mBaCPTrainer.train_epoch\u001b[0;34m(self, epoch, desc)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[38;5;66;03m# snapshot_embeddings = snapshot_embeddings[mask]\u001b[39;00m\n\u001b[1;32m    407\u001b[0m     sup_features_snc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((current_embeddings, snapshot_embeddings))\n\u001b[0;32m--> 408\u001b[0m     L_snc_sup \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_supervised_criterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43msup_features_snc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m     L_snc_unsup \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unsupervised_criterion(current_embeddings, snapshot_embeddings)\n\u001b[1;32m    410\u001b[0m L_snc_total \u001b[38;5;241m=\u001b[39m L_snc_sup \u001b[38;5;241m+\u001b[39m L_snc_unsup\n",
      "File \u001b[0;32m~/BaCP-5/project/bacp.py:512\u001b[0m, in \u001b[0;36mBaCPTrainer._supervised_criterion\u001b[0;34m(self, features, labels)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_supervised_criterion\u001b[39m(\u001b[38;5;28mself\u001b[39m, features, labels):\n\u001b[0;32m--> 512\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupervised_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/BaCP-5/project/loss_fn.py:45\u001b[0m, in \u001b[0;36mSupConLoss.forward\u001b[0;34m(self, features, labels)\u001b[0m\n\u001b[1;32m     42\u001b[0m num_positive_per_sample \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(num_positive_per_sample \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;241m1\u001b[39m, num_positive_per_sample)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Creating mask to exclude self-similarity in denominator of contrastive loss\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m self_mask_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmultiview_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m all_but_self_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mscatter(torch\u001b[38;5;241m.\u001b[39mones_like(positive_pair_mask), \u001b[38;5;241m1\u001b[39m, self_mask_indices, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Calculating similarity between all samples (dot product of normalized features)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='magnitude_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47d6c83f-81f1-44a1-8be5-db227d8bf1bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='magnitude_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbe46c80-1ee0-43f7-a6a3-e614fe315788",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='magnitude_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "509ed5ac-5006-4ed9-bbb2-a1937584efff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SNIP-it Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72d93df1-8f98-499a-b09f-7900e2f9f55d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='snip_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f443a43b-ab9a-4491-ab18-5c6b16758ea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='snip_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f71f25cd-d28b-47c7-abdc-bffe8bad99af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='snip_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ea78f67-2f91-4097-a350-3c2362ff5832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Wanda Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc0ba1b1-a9ca-4891-a7ae-dffdf7be8155",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='wanda_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ef1d229-7e68-481e-8f70-a242f8515361",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='wanda_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "899a564c-4db6-46cc-af83-b3f05d9a6cd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='wanda_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ResNet50_Cifar10",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
