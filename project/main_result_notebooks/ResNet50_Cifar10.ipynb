{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f54e966b-7ff2-4970-943d-3aac60708d21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e7dfa07-3f93-4761-9624-5667e6011be5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from constants import (\n",
    "    TARGET_SPARSITY_LOW, TARGET_SPARSITY_MID, TARGET_SPARSITY_HIGH,\n",
    "    BATCH_SIZE_CNN, BATCH_SIZE_VIT, BATCH_SIZE_LLM,\n",
    "    EPOCHS_SMALL_MODEL, EPOCHS_LARGE_MODEL, EPOCHS_VIT\n",
    ")\n",
    "from utils import get_device, get_num_workers, load_weights, print_statistics\n",
    "from unstructured_pruning import check_model_sparsity, check_sparsity_distribution\n",
    "from trainer import TrainingArguments, Trainer\n",
    "from bacp import BaCPTrainingArguments, BaCPTrainer\n",
    "\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "disable_progress_bar()\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/dbfs/hf_datasets\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42800ed7-1ff4-4ad6-91ad-6528c5b5f71c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using 288 workers\n"
     ]
    }
   ],
   "source": [
    "DEVICE = get_device()\n",
    "NUM_WORKERS = get_num_workers()\n",
    "print(\"Using device:\", DEVICE)\n",
    "print(\"Using\", NUM_WORKERS, \"workers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a5d677d-7dc6-4a71-895d-6e6a26a3c852",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Notebook specific variables\n",
    "MODEL_NAME = 'resnet50'\n",
    "MODEL_TASK = 'cifar10'\n",
    "TRAIN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64abd2b8-5626-4af3-95c7-6156e6d2e54a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "356a8caa-cf41-4280-89ea-8500ab3932c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.01)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Linear scheduler initialized with warmup steps: 830 and total steps: 8300\n",
      "[TRAINER] Pruning not initialized\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     93.02%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.0000 (0.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        baseline\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.01\n",
      "  Optimizer:            sgd\n",
      "  Epochs:               100\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.01),\n",
    "    scheduler_type='linear_with_warmup',\n",
    "    epochs=100,\n",
    "    learning_type=\"baseline\",\n",
    "    patience=50,\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "if False:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c42e7a7-7ec4-400a-880f-d795c3488ba2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pruning Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d52b36d-1357-4357-b3af-597ff9ee5958",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Magnitude Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "986acd97-7675-499d-93b8-954bd0e255eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.01)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: magnitude_pruning\n",
      "[TRAINER] Target sparsity: 0.95\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.95_pruning.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.95_pruning.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     91.97%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9500 (95.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        pruning\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.01\n",
      "  Optimizer:            sgd\n",
      "  Epochs:               5\n",
      "\n",
      "Pruning Configuration:\n",
      "------------------------------\n",
      "  Pruning Type:         magnitude_pruning\n",
      "  Target Sparsity:      0.95\n",
      "  Sparsity Scheduler:   cubic\n",
      "  Recovery Epochs:      10\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.01),\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17f6b6a3-4923-44f5-a914-d654b11a2fc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.01)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: magnitude_pruning\n",
      "[TRAINER] Target sparsity: 0.97\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.97_pruning.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.97_pruning.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     91.39%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9700 (97.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        pruning\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.01\n",
      "  Optimizer:            sgd\n",
      "  Epochs:               5\n",
      "\n",
      "Pruning Configuration:\n",
      "------------------------------\n",
      "  Pruning Type:         magnitude_pruning\n",
      "  Target Sparsity:      0.97\n",
      "  Sparsity Scheduler:   cubic\n",
      "  Recovery Epochs:      10\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.01),\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b40d89be-4870-4c84-9e9a-b424ad9e356e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.01)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: magnitude_pruning\n",
      "[TRAINER] Target sparsity: 0.99\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.99_pruning.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.99_pruning.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     89.87%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9900 (99.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        pruning\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.01\n",
      "  Optimizer:            sgd\n",
      "  Epochs:               5\n",
      "\n",
      "Pruning Configuration:\n",
      "------------------------------\n",
      "  Pruning Type:         magnitude_pruning\n",
      "  Target Sparsity:      0.99\n",
      "  Sparsity Scheduler:   cubic\n",
      "  Recovery Epochs:      10\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.01),\n",
    "    pruning_type=\"magnitude_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2764b56-71b5-4342-bfd8-764b69deed30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SNIP-it Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9108458a-ba42-4559-b995-1e1d9824f124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.01)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: snip_pruning\n",
      "[TRAINER] Target sparsity: 0.95\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.95_pruning.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.95_pruning.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     90.77%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9500 (95.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        pruning\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.01\n",
      "  Optimizer:            sgd\n",
      "  Epochs:               5\n",
      "\n",
      "Pruning Configuration:\n",
      "------------------------------\n",
      "  Pruning Type:         snip_pruning\n",
      "  Target Sparsity:      0.95\n",
      "  Sparsity Scheduler:   cubic\n",
      "  Recovery Epochs:      10\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.01),\n",
    "    pruning_type=\"snip_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c142d32-dc70-4b5f-81e5-81f5f57b78fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.01)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: snip_pruning\n",
      "[TRAINER] Target sparsity: 0.97\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.97_pruning.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.97_pruning.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     90.58%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9700 (97.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        pruning\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.01\n",
      "  Optimizer:            sgd\n",
      "  Epochs:               5\n",
      "\n",
      "Pruning Configuration:\n",
      "------------------------------\n",
      "  Pruning Type:         snip_pruning\n",
      "  Target Sparsity:      0.97\n",
      "  Sparsity Scheduler:   cubic\n",
      "  Recovery Epochs:      10\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.01),\n",
    "    pruning_type=\"snip_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b34a40e7-3087-4506-ac9c-537766579b18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.01)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: snip_pruning\n",
      "[TRAINER] Target sparsity: 0.99\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.99_pruning.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.99_pruning.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     88.18%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9900 (99.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        pruning\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.01\n",
      "  Optimizer:            sgd\n",
      "  Epochs:               5\n",
      "\n",
      "Pruning Configuration:\n",
      "------------------------------\n",
      "  Pruning Type:         snip_pruning\n",
      "  Target Sparsity:      0.99\n",
      "  Sparsity Scheduler:   cubic\n",
      "  Recovery Epochs:      10\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.01),\n",
    "    pruning_type=\"snip_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fec20c2a-3641-4525-bb90-c04770a2c917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Wanda Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "317bd431-94a5-4b5b-ae0a-919f097029bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.01)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: wanda_pruning\n",
      "[TRAINER] Target sparsity: 0.95\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.95_pruning.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.95_pruning.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     91.78%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9500 (95.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        pruning\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.01\n",
      "  Optimizer:            sgd\n",
      "  Epochs:               5\n",
      "\n",
      "Pruning Configuration:\n",
      "------------------------------\n",
      "  Pruning Type:         wanda_pruning\n",
      "  Target Sparsity:      0.95\n",
      "  Sparsity Scheduler:   cubic\n",
      "  Recovery Epochs:      10\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.01),\n",
    "    pruning_type=\"wanda_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dead20e4-55cb-4f07-be3c-399b87c1e2fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.01)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: wanda_pruning\n",
      "[TRAINER] Target sparsity: 0.97\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.97_pruning.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.97_pruning.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     90.81%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9700 (97.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        pruning\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.01\n",
      "  Optimizer:            sgd\n",
      "  Epochs:               5\n",
      "\n",
      "Pruning Configuration:\n",
      "------------------------------\n",
      "  Pruning Type:         wanda_pruning\n",
      "  Target Sparsity:      0.97\n",
      "  Sparsity Scheduler:   cubic\n",
      "  Recovery Epochs:      10\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.01),\n",
    "    pruning_type=\"wanda_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3a50b0e-5478-4663-9f9b-71291eb2c5c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.01)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: wanda_pruning\n",
      "[TRAINER] Target sparsity: 0.99\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.99_pruning.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.99_pruning.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     86.59%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9900 (99.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        pruning\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.01\n",
      "  Optimizer:            sgd\n",
      "  Epochs:               5\n",
      "\n",
      "Pruning Configuration:\n",
      "------------------------------\n",
      "  Pruning Type:         wanda_pruning\n",
      "  Target Sparsity:      0.99\n",
      "  Sparsity Scheduler:   cubic\n",
      "  Recovery Epochs:      10\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.01),\n",
    "    pruning_type=\"wanda_pruning\",\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type=\"pruning\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "956d54dd-72b4-4d82-b70f-ec16e84750fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## BaCP Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b1f60ba-0f4d-48f5-9b88-fc11fc393ffa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Magnitude Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0424487-8c14-43d7-9999-6f2b019791e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Initialized BaCP models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.1)\n",
      "[TRAINER] No scheduler initialized\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: magnitude_pruning\n",
      "[TRAINER] Target sparsity: 0.95\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.95_bacp_pruning.pt\n",
      "[BaCP TRAINER] Mask generated from current model.\n",
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.95_bacp_pruning.pt\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.95_bacp_pruning.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (adamw, 0.0001)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Finetuning initialized\n",
      "[TRAINER] Pruning type: magnitude_pruning\n",
      "[TRAINER] Current sparsity: 0.9500\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.95_bacp_finetune.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.95_bacp_finetune.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     93.58%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9500 (95.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        bacp_finetune\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.0001\n",
      "  Optimizer:            adamw\n",
      "  Epochs:               50\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='magnitude_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47d6c83f-81f1-44a1-8be5-db227d8bf1bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Initialized BaCP models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.1)\n",
      "[TRAINER] No scheduler initialized\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: magnitude_pruning\n",
      "[TRAINER] Target sparsity: 0.97\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.97_bacp_pruning.pt\n",
      "[BaCP TRAINER] Mask generated from current model.\n",
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.97_bacp_pruning.pt\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.97_bacp_pruning.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (adamw, 0.0001)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Finetuning initialized\n",
      "[TRAINER] Pruning type: magnitude_pruning\n",
      "[TRAINER] Current sparsity: 0.9700\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.97_bacp_finetune.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.97_bacp_finetune.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     93.27%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9700 (97.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        bacp_finetune\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.0001\n",
      "  Optimizer:            adamw\n",
      "  Epochs:               50\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='magnitude_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbe46c80-1ee0-43f7-a6a3-e614fe315788",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Initialized BaCP models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.1)\n",
      "[TRAINER] No scheduler initialized\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: magnitude_pruning\n",
      "[TRAINER] Target sparsity: 0.99\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.99_bacp_pruning.pt\n",
      "[BaCP TRAINER] Mask generated from current model.\n",
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.99_bacp_pruning.pt\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.99_bacp_pruning.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (adamw, 0.0001)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Finetuning initialized\n",
      "[TRAINER] Pruning type: magnitude_pruning\n",
      "[TRAINER] Current sparsity: 0.9900\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.99_bacp_finetune.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.99_bacp_finetune.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     92.32%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9900 (99.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        bacp_finetune\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.0001\n",
      "  Optimizer:            adamw\n",
      "  Epochs:               50\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='magnitude_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "509ed5ac-5006-4ed9-bbb2-a1937584efff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SNIP-it Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72d93df1-8f98-499a-b09f-7900e2f9f55d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Initialized BaCP models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.1)\n",
      "[TRAINER] No scheduler initialized\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: snip_pruning\n",
      "[TRAINER] Target sparsity: 0.95\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.95_bacp_pruning.pt\n",
      "[BaCP TRAINER] Mask generated from current model.\n",
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.95_bacp_pruning.pt\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.95_bacp_pruning.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (adamw, 0.0001)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Finetuning initialized\n",
      "[TRAINER] Pruning type: snip_pruning\n",
      "[TRAINER] Current sparsity: 0.9500\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.95_bacp_finetune.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.95_bacp_finetune.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     93.12%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9500 (95.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        bacp_finetune\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.0001\n",
      "  Optimizer:            adamw\n",
      "  Epochs:               50\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='snip_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f443a43b-ab9a-4491-ab18-5c6b16758ea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Initialized BaCP models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.1)\n",
      "[TRAINER] No scheduler initialized\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: snip_pruning\n",
      "[TRAINER] Target sparsity: 0.97\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.97_bacp_pruning.pt\n",
      "[BaCP TRAINER] Mask generated from current model.\n",
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.97_bacp_pruning.pt\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.97_bacp_pruning.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (adamw, 0.0001)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Finetuning initialized\n",
      "[TRAINER] Pruning type: snip_pruning\n",
      "[TRAINER] Current sparsity: 0.9700\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.97_bacp_finetune.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.97_bacp_finetune.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     92.71%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9700 (97.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        bacp_finetune\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.0001\n",
      "  Optimizer:            adamw\n",
      "  Epochs:               50\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='snip_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f71f25cd-d28b-47c7-abdc-bffe8bad99af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Initialized BaCP models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.1)\n",
      "[TRAINER] No scheduler initialized\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: snip_pruning\n",
      "[TRAINER] Target sparsity: 0.99\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.99_bacp_pruning.pt\n",
      "[BaCP TRAINER] Mask generated from current model.\n",
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.99_bacp_pruning.pt\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.99_bacp_pruning.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (adamw, 0.0001)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Finetuning initialized\n",
      "[TRAINER] Pruning type: snip_pruning\n",
      "[TRAINER] Current sparsity: 0.9900\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.99_bacp_finetune.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_snip_pruning_0.99_bacp_finetune.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     91.90%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9900 (99.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        bacp_finetune\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.0001\n",
      "  Optimizer:            adamw\n",
      "  Epochs:               50\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='snip_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ea78f67-2f91-4097-a350-3c2362ff5832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Wanda Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc0ba1b1-a9ca-4891-a7ae-dffdf7be8155",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Initialized BaCP models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.1)\n",
      "[TRAINER] No scheduler initialized\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: wanda_pruning\n",
      "[TRAINER] Target sparsity: 0.95\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.95_bacp_pruning.pt\n",
      "[BaCP TRAINER] Mask generated from current model.\n",
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.95_bacp_pruning.pt\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.95_bacp_pruning.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (adamw, 0.0001)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Finetuning initialized\n",
      "[TRAINER] Pruning type: wanda_pruning\n",
      "[TRAINER] Current sparsity: 0.9500\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.95_bacp_finetune.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.95_bacp_finetune.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     93.15%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9500 (95.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        bacp_finetune\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.0001\n",
      "  Optimizer:            adamw\n",
      "  Epochs:               50\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='wanda_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_LOW,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ef1d229-7e68-481e-8f70-a242f8515361",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Initialized BaCP models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.1)\n",
      "[TRAINER] No scheduler initialized\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: wanda_pruning\n",
      "[TRAINER] Target sparsity: 0.97\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.97_bacp_pruning.pt\n",
      "[BaCP TRAINER] Mask generated from current model.\n",
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.97_bacp_pruning.pt\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.97_bacp_pruning.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (adamw, 0.0001)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Finetuning initialized\n",
      "[TRAINER] Pruning type: wanda_pruning\n",
      "[TRAINER] Current sparsity: 0.9700\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.97_bacp_finetune.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.97_bacp_finetune.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     93.02%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9700 (97.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        bacp_finetune\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.0001\n",
      "  Optimizer:            adamw\n",
      "  Epochs:               50\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='wanda_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "899a564c-4db6-46cc-af83-b3f05d9a6cd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Initialized BaCP models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.1)\n",
      "[TRAINER] No scheduler initialized\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: wanda_pruning\n",
      "[TRAINER] Target sparsity: 0.99\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.99_bacp_pruning.pt\n",
      "[BaCP TRAINER] Mask generated from current model.\n",
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.99_bacp_pruning.pt\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.99_bacp_pruning.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded\n",
      "[TRAINER] Optimizer type w/ learning rate: (adamw, 0.0001)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] No scheduler initialized\n",
      "[TRAINER] Finetuning initialized\n",
      "[TRAINER] Pruning type: wanda_pruning\n",
      "[TRAINER] Current sparsity: 0.9900\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.99_bacp_finetune.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_wanda_pruning_0.99_bacp_finetune.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     90.87%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "  Model Sparsity:       0.9900 (99.00%)\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        bacp_finetune\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.0001\n",
      "  Optimizer:            adamw\n",
      "  Epochs:               50\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='wanda_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args=bacp_training_args)\n",
    "if TRAIN:\n",
    "    bacp_trainer.train()\n",
    "\n",
    "# Finetuning Phase\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "VGG11_Cifar10",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
