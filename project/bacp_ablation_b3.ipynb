{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4923879",
   "metadata": {},
   "source": [
    "# BaCP Ablation B3: Supervised vs. Self-Supervised Contrastive Loss Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167e615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bacp import BaCPTrainer, BaCPTrainingArguments\n",
    "from trainer import Trainer, TrainingArguments\n",
    "from utils import print_statistics, get_device, get_num_workers, print_dynamic_lambdas_statistics, load_object, save_object\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a64972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using 288 workers\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'resnet50'\n",
    "MODEL_TASK = 'cifar10'\n",
    "FINETUNED_WEIGHTS = './research/resnet50/cifar10/resnet50_cifar10_baseline.pt'\n",
    "TRAIN = False\n",
    "DEVICE = get_device()\n",
    "NUM_WORKERS = get_num_workers()\n",
    "print(\"Using device:\", DEVICE)\n",
    "print(\"Using\", NUM_WORKERS, \"workers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af42d04",
   "metadata": {},
   "source": [
    "## Baseline Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95fb69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[TRAINER] Initialized models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.01)\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Linear scheduler initialized with warmup steps: 830 and total steps: 8300\n",
      "[TRAINER] Pruning not initialized\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Loading weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Model Sparsity: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STATISTICS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "------------------------------\n",
      "  Accuracy:     93.02%\n",
      "\n",
      "Model Information:\n",
      "------------------------------\n",
      "  Total Parameters:     23,520,842\n",
      "  Trainable Parameters: 23,520,842\n",
      "\n",
      "Training Configuration:\n",
      "------------------------------\n",
      "  Model:                resnet50\n",
      "  Task:                 cifar10\n",
      "  Learning Type:        baseline\n",
      "  Batch Size:           512\n",
      "  Learning Rate:        0.01\n",
      "  Optimizer:            sgd\n",
      "  Epochs:               100\n",
      "\n",
      "System Information:\n",
      "------------------------------\n",
      "  Device:               cuda\n",
      "  Mixed Precision:      True\n",
      "  Workers:              24\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.01),\n",
    "    scheduler_type='linear_with_warmup',\n",
    "    epochs=100,\n",
    "    learning_type=\"baseline\",\n",
    "    patience=50,\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args=training_args)\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbec3b7",
   "metadata": {},
   "source": [
    "## BaCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb9507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Disabling self-supervised contrastive loss for this training cycle.\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Initialized BaCP models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.1)\n",
      "[TRAINER] No scheduler initialized\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: magnitude_pruning\n",
      "[TRAINER] Target sparsity: 0.95\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.95_bacp_pruning_b3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/5]:   0%|          | 0/83 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pruner] Cubic Sparsity ratio increased to 0.464.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]: Avg Total Loss: 7.4489 | Avg PrC Loss: 3.5383 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 3.5503 | Avg CE Loss: 0.3603 | Model Sparsity: 0.4636\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [1/10]: Avg Total Loss: 6.7209 | Avg PrC Loss: 3.4658 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 3.0877 | Avg CE Loss: 0.1674 | Model Sparsity: 0.4636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [2/10]: Avg Total Loss: 6.5307 | Avg PrC Loss: 3.4501 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.9605 | Avg CE Loss: 0.1201 | Model Sparsity: 0.4636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [3/10]: Avg Total Loss: 6.4599 | Avg PrC Loss: 3.4411 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.9212 | Avg CE Loss: 0.0976 | Model Sparsity: 0.4636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [4/10]: Avg Total Loss: 6.4121 | Avg PrC Loss: 3.4350 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.8933 | Avg CE Loss: 0.0839 | Model Sparsity: 0.4636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [5/10]: Avg Total Loss: 6.3825 | Avg PrC Loss: 3.4301 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.8765 | Avg CE Loss: 0.0758 | Model Sparsity: 0.4636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [6/10]: Avg Total Loss: 6.3650 | Avg PrC Loss: 3.4275 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.8665 | Avg CE Loss: 0.0709 | Model Sparsity: 0.4636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [7/10]: Avg Total Loss: 6.3566 | Avg PrC Loss: 3.4268 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.8615 | Avg CE Loss: 0.0683 | Model Sparsity: 0.4636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [8/10]: Avg Total Loss: 6.3481 | Avg PrC Loss: 3.4243 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.8568 | Avg CE Loss: 0.0670 | Model Sparsity: 0.4636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [9/10]: Avg Total Loss: 6.3418 | Avg PrC Loss: 3.4225 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.8554 | Avg CE Loss: 0.0639 | Model Sparsity: 0.4636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [10/10]: Avg Total Loss: 6.3366 | Avg PrC Loss: 3.4219 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.8512 | Avg CE Loss: 0.0635 | Model Sparsity: 0.4636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [2/5]:   0%|          | 0/83 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pruner] Cubic Sparsity ratio increased to 0.745.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5]: Avg Total Loss: 8.9345 | Avg PrC Loss: 3.4529 | Avg SnC Loss: 2.5663 | Avg FiC Loss: 2.8448 | Avg CE Loss: 0.0705 | Model Sparsity: 0.7448\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [1/10]: Avg Total Loss: 8.9388 | Avg PrC Loss: 3.4520 | Avg SnC Loss: 2.5696 | Avg FiC Loss: 2.8465 | Avg CE Loss: 0.0706 | Model Sparsity: 0.7448\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [2/10]: Avg Total Loss: 8.9224 | Avg PrC Loss: 3.4520 | Avg SnC Loss: 2.5635 | Avg FiC Loss: 2.8389 | Avg CE Loss: 0.0681 | Model Sparsity: 0.7448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [3/10]: Avg Total Loss: 8.9128 | Avg PrC Loss: 3.4518 | Avg SnC Loss: 2.5588 | Avg FiC Loss: 2.8361 | Avg CE Loss: 0.0661 | Model Sparsity: 0.7448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [4/10]: Avg Total Loss: 8.9162 | Avg PrC Loss: 3.4503 | Avg SnC Loss: 2.5606 | Avg FiC Loss: 2.8384 | Avg CE Loss: 0.0668 | Model Sparsity: 0.7448\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [5/10]: Avg Total Loss: 8.9077 | Avg PrC Loss: 3.4499 | Avg SnC Loss: 2.5574 | Avg FiC Loss: 2.8340 | Avg CE Loss: 0.0663 | Model Sparsity: 0.7448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [6/10]: Avg Total Loss: 8.9039 | Avg PrC Loss: 3.4487 | Avg SnC Loss: 2.5566 | Avg FiC Loss: 2.8330 | Avg CE Loss: 0.0657 | Model Sparsity: 0.7448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [7/10]: Avg Total Loss: 8.8910 | Avg PrC Loss: 3.4482 | Avg SnC Loss: 2.5525 | Avg FiC Loss: 2.8274 | Avg CE Loss: 0.0629 | Model Sparsity: 0.7448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [8/10]: Avg Total Loss: 8.9030 | Avg PrC Loss: 3.4492 | Avg SnC Loss: 2.5564 | Avg FiC Loss: 2.8316 | Avg CE Loss: 0.0657 | Model Sparsity: 0.7448\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [9/10]: Avg Total Loss: 8.9040 | Avg PrC Loss: 3.4491 | Avg SnC Loss: 2.5563 | Avg FiC Loss: 2.8322 | Avg CE Loss: 0.0665 | Model Sparsity: 0.7448\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [10/10]: Avg Total Loss: 8.9114 | Avg PrC Loss: 3.4489 | Avg SnC Loss: 2.5600 | Avg FiC Loss: 2.8349 | Avg CE Loss: 0.0676 | Model Sparsity: 0.7448\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [3/5]:   0%|          | 0/83 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pruner] Cubic Sparsity ratio increased to 0.889.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5]: Avg Total Loss: 11.4688 | Avg PrC Loss: 3.4766 | Avg SnC Loss: 5.0695 | Avg FiC Loss: 2.8410 | Avg CE Loss: 0.0817 | Model Sparsity: 0.8892\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [1/10]: Avg Total Loss: 11.4526 | Avg PrC Loss: 3.4737 | Avg SnC Loss: 5.0627 | Avg FiC Loss: 2.8378 | Avg CE Loss: 0.0785 | Model Sparsity: 0.8892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [2/10]: Avg Total Loss: 11.4366 | Avg PrC Loss: 3.4734 | Avg SnC Loss: 5.0539 | Avg FiC Loss: 2.8337 | Avg CE Loss: 0.0757 | Model Sparsity: 0.8892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [3/10]: Avg Total Loss: 11.4288 | Avg PrC Loss: 3.4730 | Avg SnC Loss: 5.0499 | Avg FiC Loss: 2.8321 | Avg CE Loss: 0.0738 | Model Sparsity: 0.8892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [4/10]: Avg Total Loss: 11.4218 | Avg PrC Loss: 3.4732 | Avg SnC Loss: 5.0463 | Avg FiC Loss: 2.8301 | Avg CE Loss: 0.0722 | Model Sparsity: 0.8892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [5/10]: Avg Total Loss: 11.4105 | Avg PrC Loss: 3.4722 | Avg SnC Loss: 5.0391 | Avg FiC Loss: 2.8276 | Avg CE Loss: 0.0716 | Model Sparsity: 0.8892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [6/10]: Avg Total Loss: 11.4130 | Avg PrC Loss: 3.4725 | Avg SnC Loss: 5.0408 | Avg FiC Loss: 2.8293 | Avg CE Loss: 0.0705 | Model Sparsity: 0.8892\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [7/10]: Avg Total Loss: 11.4137 | Avg PrC Loss: 3.4721 | Avg SnC Loss: 5.0405 | Avg FiC Loss: 2.8282 | Avg CE Loss: 0.0729 | Model Sparsity: 0.8892\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [8/10]: Avg Total Loss: 11.4086 | Avg PrC Loss: 3.4718 | Avg SnC Loss: 5.0391 | Avg FiC Loss: 2.8262 | Avg CE Loss: 0.0715 | Model Sparsity: 0.8892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [9/10]: Avg Total Loss: 11.3982 | Avg PrC Loss: 3.4716 | Avg SnC Loss: 5.0334 | Avg FiC Loss: 2.8238 | Avg CE Loss: 0.0693 | Model Sparsity: 0.8892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [10/10]: Avg Total Loss: 11.3987 | Avg PrC Loss: 3.4713 | Avg SnC Loss: 5.0323 | Avg FiC Loss: 2.8258 | Avg CE Loss: 0.0693 | Model Sparsity: 0.8892\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [4/5]:   0%|          | 0/83 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pruner] Cubic Sparsity ratio increased to 0.942.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5]: Avg Total Loss: 13.9411 | Avg PrC Loss: 3.4925 | Avg SnC Loss: 7.5287 | Avg FiC Loss: 2.8355 | Avg CE Loss: 0.0844 | Model Sparsity: 0.9424\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [1/10]: Avg Total Loss: 13.9150 | Avg PrC Loss: 3.4925 | Avg SnC Loss: 7.5112 | Avg FiC Loss: 2.8308 | Avg CE Loss: 0.0804 | Model Sparsity: 0.9424\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [2/10]: Avg Total Loss: 13.9065 | Avg PrC Loss: 3.4904 | Avg SnC Loss: 7.5093 | Avg FiC Loss: 2.8293 | Avg CE Loss: 0.0775 | Model Sparsity: 0.9424\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [3/10]: Avg Total Loss: 13.9080 | Avg PrC Loss: 3.4920 | Avg SnC Loss: 7.5076 | Avg FiC Loss: 2.8296 | Avg CE Loss: 0.0787 | Model Sparsity: 0.9424\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining epoch [4/10]:  17%|█▋        | 14/83 [00:05<00:23,  2.93it/s, Loss=13.9, PrC Loss=3.48, SnC Loss=7.48, FiC Loss=2.83, CE Loss=0.0657]"
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "all_metrics = {}\n",
    "disable_loss_types = ['self', 'sup', 'all']\n",
    "for disable_type in disable_loss_types:\n",
    "    loss_types = {\n",
    "        'self': 'self-supervised contrastive loss',\n",
    "        'sup': 'supervised contrastive loss',\n",
    "        'all': 'all contrastive losses',\n",
    "    }\n",
    "\n",
    "    print('='*80)\n",
    "    print(f\"Disabling {loss_types[disable_type]} for this training cycle.\")\n",
    "    print('='*80)\n",
    "\n",
    "    bacp_training_args = BaCPTrainingArguments(\n",
    "        model_name=MODEL_NAME,\n",
    "        model_task=MODEL_TASK,\n",
    "        batch_size=BATCH_SIZE_CNN,\n",
    "        optimizer_type_and_lr=('sgd', 0.1),\n",
    "        pruning_type='magnitude_pruning',\n",
    "        target_sparsity=TARGET_SPARSITY_LOW,\n",
    "        sparsity_scheduler='cubic',\n",
    "        finetuned_weights=finetuned_weights,\n",
    "        learning_type='bacp_pruning_b3',\n",
    "        db=False,\n",
    "        log_epochs=False,\n",
    "    )\n",
    "    bacp_trainer = BaCPTrainer(bacp_training_args)\n",
    "    bacp_trainer.disable = disable_type\n",
    "    if True:\n",
    "        bacp_trainer.train()\n",
    "\n",
    "    bacp_trainer.generate_mask_from_model()\n",
    "    training_args = TrainingArguments(\n",
    "        model_name=bacp_trainer.model_name,\n",
    "        model_task=bacp_trainer.model_task,\n",
    "        batch_size=bacp_trainer.batch_size,\n",
    "        optimizer_type_and_lr=('adamw', 0.0001),\n",
    "        pruner=bacp_trainer.get_pruner(),\n",
    "        pruning_type=bacp_trainer.pruning_type,\n",
    "        target_sparsity=bacp_trainer.target_sparsity,\n",
    "        epochs=50,\n",
    "        finetuned_weights=bacp_trainer.save_path,\n",
    "        finetune=True,\n",
    "        learning_type=\"bacp_b3_finetune\",\n",
    "        db=False,\n",
    "        log_epochs=False,\n",
    "    )\n",
    "    trainer = Trainer(training_args)\n",
    "    if True:\n",
    "        trainer.train()\n",
    "\n",
    "    metrics = trainer.evaluate()\n",
    "    print_statistics(metrics, trainer)\n",
    "\n",
    "    all_metrics[disable_type] = metrics\n",
    "\n",
    "save_object(all_metrics, f'{MODEL_NAME}_{MODEL_TASK}_{bacp_trainer.pruning_type}_{bacp_trainer.target_sparsity}_b3_metrics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Image size: 32\n",
      "[ERROR] Could not load weights: ./research/resnet50/cifar10/resnet50_cifar10_baseline.pt\n",
      "[ERROR] Attempting partial load\n",
      "[TRAINER] Weights loaded successfully\n",
      "[TRAINER] Initialized BaCP models\n",
      "[TRAINER] Optimizer type w/ learning rate: (sgd, 0.1)\n",
      "[TRAINER] No scheduler initialized\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Data Initialized for model task: cifar10\n",
      "[TRAINER] Batch size: 512\n",
      "[TRAINER] Number of dataloders: 3\n",
      "[TRAINER] Pruning initialized\n",
      "[TRAINER] Pruning type: magnitude_pruning\n",
      "[TRAINER] Target sparsity: 0.97\n",
      "[TRAINER] Sparsity scheduler: cubic\n",
      "[TRAINER] Pruning epochs: 5\n",
      "[TRAINER] Current sparsity: 0.0000\n",
      "[TRAINER] Saving model to: ./research/resnet50/cifar10/resnet50_cifar10_magnitude_pruning_0.97_bacp_pruning_b1.pt\n",
      "[LOGGER] Log file created at location: ./log_records/resnet50/cifar10/bacp_pruning_b1/magnitude_pruning/0.97/run_1.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/5]:   1%|          | 1/83 [00:01<02:15,  1.66s/it, Loss=7.62, PrC Loss=3.6, SnC Loss=0, FiC Loss=3.43, CE Loss=0.594]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pruner] Cubic Sparsity ratio increased to 0.473.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]: Avg Total Loss: 7.2755 | Avg PrC Loss: 3.4377 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 3.4236 | Avg CE Loss: 0.4142 | Model Sparsity: 0.4734\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [1/10]: Avg Total Loss: 6.1858 | Avg PrC Loss: 3.1238 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.8219 | Avg CE Loss: 0.2401 | Model Sparsity: 0.4734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [2/10]: Avg Total Loss: 5.5748 | Avg PrC Loss: 2.8696 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.5291 | Avg CE Loss: 0.1762 | Model Sparsity: 0.4734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [3/10]: Avg Total Loss: 5.1092 | Avg PrC Loss: 2.6358 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.3295 | Avg CE Loss: 0.1439 | Model Sparsity: 0.4734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [4/10]: Avg Total Loss: 4.7031 | Avg PrC Loss: 2.4222 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.1525 | Avg CE Loss: 0.1284 | Model Sparsity: 0.4734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [5/10]: Avg Total Loss: 4.3441 | Avg PrC Loss: 2.2272 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 1.9960 | Avg CE Loss: 0.1208 | Model Sparsity: 0.4734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [6/10]: Avg Total Loss: 4.0126 | Avg PrC Loss: 2.0505 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 1.8503 | Avg CE Loss: 0.1118 | Model Sparsity: 0.4734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [7/10]: Avg Total Loss: 3.7196 | Avg PrC Loss: 1.8908 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 1.7192 | Avg CE Loss: 0.1096 | Model Sparsity: 0.4734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [8/10]: Avg Total Loss: 3.4517 | Avg PrC Loss: 1.7465 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 1.5991 | Avg CE Loss: 0.1062 | Model Sparsity: 0.4734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [9/10]: Avg Total Loss: 3.2077 | Avg PrC Loss: 1.6162 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 1.4883 | Avg CE Loss: 0.1032 | Model Sparsity: 0.4734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [10/10]: Avg Total Loss: 2.9967 | Avg PrC Loss: 1.5001 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 1.3908 | Avg CE Loss: 0.1058 | Model Sparsity: 0.4734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [2/5]:   1%|          | 1/83 [00:01<01:25,  1.04s/it, Loss=7.04, PrC Loss=1.44, SnC Loss=4.17, FiC Loss=1.34, CE Loss=0.093]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pruner] Cubic Sparsity ratio increased to 0.760.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5]: Avg Total Loss: 7.0185 | Avg PrC Loss: 1.4386 | Avg SnC Loss: 4.1177 | Avg FiC Loss: 1.3240 | Avg CE Loss: 0.1382 | Model Sparsity: 0.7605\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [1/10]: Avg Total Loss: 6.6348 | Avg PrC Loss: 1.3732 | Avg SnC Loss: 3.8373 | Avg FiC Loss: 1.2729 | Avg CE Loss: 0.1513 | Model Sparsity: 0.7605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [2/10]: Avg Total Loss: 6.1898 | Avg PrC Loss: 1.3025 | Avg SnC Loss: 3.5248 | Avg FiC Loss: 1.2122 | Avg CE Loss: 0.1503 | Model Sparsity: 0.7605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [3/10]: Avg Total Loss: 5.7540 | Avg PrC Loss: 1.2280 | Avg SnC Loss: 3.2241 | Avg FiC Loss: 1.1490 | Avg CE Loss: 0.1528 | Model Sparsity: 0.7605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [4/10]: Avg Total Loss: 5.3178 | Avg PrC Loss: 1.1506 | Avg SnC Loss: 2.9292 | Avg FiC Loss: 1.0811 | Avg CE Loss: 0.1570 | Model Sparsity: 0.7605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [5/10]: Avg Total Loss: 4.9149 | Avg PrC Loss: 1.0724 | Avg SnC Loss: 2.6603 | Avg FiC Loss: 1.0141 | Avg CE Loss: 0.1681 | Model Sparsity: 0.7605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [6/10]: Avg Total Loss: 4.5035 | Avg PrC Loss: 0.9952 | Avg SnC Loss: 2.3939 | Avg FiC Loss: 0.9444 | Avg CE Loss: 0.1700 | Model Sparsity: 0.7605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [7/10]: Avg Total Loss: 4.1487 | Avg PrC Loss: 0.9206 | Avg SnC Loss: 2.1595 | Avg FiC Loss: 0.8775 | Avg CE Loss: 0.1911 | Model Sparsity: 0.7605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [8/10]: Avg Total Loss: 3.8003 | Avg PrC Loss: 0.8503 | Avg SnC Loss: 1.9423 | Avg FiC Loss: 0.8131 | Avg CE Loss: 0.1947 | Model Sparsity: 0.7605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [9/10]: Avg Total Loss: 3.4849 | Avg PrC Loss: 0.7847 | Avg SnC Loss: 1.7502 | Avg FiC Loss: 0.7530 | Avg CE Loss: 0.1970 | Model Sparsity: 0.7605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [10/10]: Avg Total Loss: 3.2158 | Avg PrC Loss: 0.7245 | Avg SnC Loss: 1.5824 | Avg FiC Loss: 0.6977 | Avg CE Loss: 0.2112 | Model Sparsity: 0.7605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [3/5]:   1%|          | 1/83 [00:01<01:29,  1.10s/it, Loss=4.5, PrC Loss=0.696, SnC Loss=2.94, FiC Loss=0.673, CE Loss=0.188]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pruner] Cubic Sparsity ratio increased to 0.908.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5]: Avg Total Loss: 4.2765 | Avg PrC Loss: 0.6702 | Avg SnC Loss: 2.7425 | Avg FiC Loss: 0.6419 | Avg CE Loss: 0.2220 | Model Sparsity: 0.9079\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [1/10]: Avg Total Loss: 3.7258 | Avg PrC Loss: 0.6061 | Avg SnC Loss: 2.3211 | Avg FiC Loss: 0.5815 | Avg CE Loss: 0.2171 | Model Sparsity: 0.9079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [2/10]: Avg Total Loss: 3.2961 | Avg PrC Loss: 0.5503 | Avg SnC Loss: 1.9943 | Avg FiC Loss: 0.5293 | Avg CE Loss: 0.2221 | Model Sparsity: 0.9079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [3/10]: Avg Total Loss: 2.9455 | Avg PrC Loss: 0.5023 | Avg SnC Loss: 1.7331 | Avg FiC Loss: 0.4842 | Avg CE Loss: 0.2260 | Model Sparsity: 0.9079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [4/10]: Avg Total Loss: 2.6362 | Avg PrC Loss: 0.4607 | Avg SnC Loss: 1.5193 | Avg FiC Loss: 0.4440 | Avg CE Loss: 0.2122 | Model Sparsity: 0.9079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [5/10]: Avg Total Loss: 2.4025 | Avg PrC Loss: 0.4249 | Avg SnC Loss: 1.3525 | Avg FiC Loss: 0.4104 | Avg CE Loss: 0.2147 | Model Sparsity: 0.9079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [6/10]: Avg Total Loss: 2.2065 | Avg PrC Loss: 0.3937 | Avg SnC Loss: 1.2127 | Avg FiC Loss: 0.3809 | Avg CE Loss: 0.2193 | Model Sparsity: 0.9079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [7/10]: Avg Total Loss: 2.0426 | Avg PrC Loss: 0.3665 | Avg SnC Loss: 1.0960 | Avg FiC Loss: 0.3551 | Avg CE Loss: 0.2249 | Model Sparsity: 0.9079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [8/10]: Avg Total Loss: 1.9065 | Avg PrC Loss: 0.3428 | Avg SnC Loss: 0.9999 | Avg FiC Loss: 0.3326 | Avg CE Loss: 0.2313 | Model Sparsity: 0.9079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [9/10]: Avg Total Loss: 1.7836 | Avg PrC Loss: 0.3216 | Avg SnC Loss: 0.9160 | Avg FiC Loss: 0.3122 | Avg CE Loss: 0.2338 | Model Sparsity: 0.9079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [10/10]: Avg Total Loss: 1.6683 | Avg PrC Loss: 0.3028 | Avg SnC Loss: 0.8424 | Avg FiC Loss: 0.2940 | Avg CE Loss: 0.2291 | Model Sparsity: 0.9079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [4/5]:   1%|          | 1/83 [00:01<01:26,  1.06s/it, Loss=2, PrC Loss=0.293, SnC Loss=1.21, FiC Loss=0.285, CE Loss=0.212]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pruner] Cubic Sparsity ratio increased to 0.962.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5]: Avg Total Loss: 1.9790 | Avg PrC Loss: 0.2867 | Avg SnC Loss: 1.1544 | Avg FiC Loss: 0.2778 | Avg CE Loss: 0.2601 | Model Sparsity: 0.9622\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [1/10]: Avg Total Loss: 1.8142 | Avg PrC Loss: 0.2684 | Avg SnC Loss: 1.0450 | Avg FiC Loss: 0.2603 | Avg CE Loss: 0.2405 | Model Sparsity: 0.9622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [2/10]: Avg Total Loss: 1.6871 | Avg PrC Loss: 0.2523 | Avg SnC Loss: 0.9530 | Avg FiC Loss: 0.2447 | Avg CE Loss: 0.2372 | Model Sparsity: 0.9622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [3/10]: Avg Total Loss: 1.5815 | Avg PrC Loss: 0.2381 | Avg SnC Loss: 0.8755 | Avg FiC Loss: 0.2311 | Avg CE Loss: 0.2368 | Model Sparsity: 0.9622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [4/10]: Avg Total Loss: 1.4987 | Avg PrC Loss: 0.2256 | Avg SnC Loss: 0.8101 | Avg FiC Loss: 0.2192 | Avg CE Loss: 0.2439 | Model Sparsity: 0.9622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [5/10]: Avg Total Loss: 1.4091 | Avg PrC Loss: 0.2142 | Avg SnC Loss: 0.7515 | Avg FiC Loss: 0.2081 | Avg CE Loss: 0.2353 | Model Sparsity: 0.9622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [6/10]: Avg Total Loss: 1.3409 | Avg PrC Loss: 0.2039 | Avg SnC Loss: 0.7014 | Avg FiC Loss: 0.1985 | Avg CE Loss: 0.2371 | Model Sparsity: 0.9622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [7/10]: Avg Total Loss: 1.2811 | Avg PrC Loss: 0.1947 | Avg SnC Loss: 0.6564 | Avg FiC Loss: 0.1895 | Avg CE Loss: 0.2405 | Model Sparsity: 0.9622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [8/10]: Avg Total Loss: 1.2255 | Avg PrC Loss: 0.1864 | Avg SnC Loss: 0.6175 | Avg FiC Loss: 0.1815 | Avg CE Loss: 0.2401 | Model Sparsity: 0.9622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [9/10]: Avg Total Loss: 1.1701 | Avg PrC Loss: 0.1787 | Avg SnC Loss: 0.5812 | Avg FiC Loss: 0.1739 | Avg CE Loss: 0.2364 | Model Sparsity: 0.9622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [10/10]: Avg Total Loss: 1.1345 | Avg PrC Loss: 0.1716 | Avg SnC Loss: 0.5506 | Avg FiC Loss: 0.1673 | Avg CE Loss: 0.2450 | Model Sparsity: 0.9622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [5/5]:   1%|          | 1/83 [00:01<01:33,  1.14s/it, Loss=1.26, PrC Loss=0.168, SnC Loss=0.706, FiC Loss=0.164, CE Loss=0.221]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pruner] Cubic Sparsity ratio increased to 0.970.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]: Avg Total Loss: 1.2531 | Avg PrC Loss: 0.1654 | Avg SnC Loss: 0.6876 | Avg FiC Loss: 0.1607 | Avg CE Loss: 0.2392 | Model Sparsity: 0.97\n",
      "\n",
      "[BaCP] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [1/10]: Avg Total Loss: 1.1980 | Avg PrC Loss: 0.1585 | Avg SnC Loss: 0.6461 | Avg FiC Loss: 0.1541 | Avg CE Loss: 0.2393 | Model Sparsity: 0.97\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [2/10]: Avg Total Loss: 1.1464 | Avg PrC Loss: 0.1520 | Avg SnC Loss: 0.6080 | Avg FiC Loss: 0.1479 | Avg CE Loss: 0.2384 | Model Sparsity: 0.97\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Epoch [3/10]: Avg Total Loss: 1.0974 | Avg PrC Loss: 0.1462 | Avg SnC Loss: 0.5742 | Avg FiC Loss: 0.1423 | Avg CE Loss: 0.2347 | Model Sparsity: 0.97\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m bacp_trainer \u001b[38;5;241m=\u001b[39m BaCPTrainer(bacp_training_args, lambdas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mbacp_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     print_dynamic_lambdas_statistics(bacp_trainer)\n\u001b[1;32m     21\u001b[0m bacp_trainer\u001b[38;5;241m.\u001b[39mgenerate_mask_from_model()\n",
      "File \u001b[0;32m~/BaCP-1/project/bacp.py:225\u001b[0m, in \u001b[0;36mBaCPTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[BaCP] weights saved!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpruner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m          \n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msnapshots) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpruning_epochs:\n\u001b[1;32m    228\u001b[0m     state \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "File \u001b[0;32m~/BaCP-1/project/bacp.py:237\u001b[0m, in \u001b[0;36mBaCPTrainer.retrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecovery_epochs):\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetraining epoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecovery_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# Printing statistics\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     sparsity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sparsity_key()\n",
      "File \u001b[0;32m~/BaCP-1/project/bacp.py:417\u001b[0m, in \u001b[0;36mBaCPTrainer.train_epoch\u001b[0;34m(self, epoch, desc)\u001b[0m\n\u001b[1;32m    415\u001b[0m             sup_features_snc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((current_embeddings, snapshot_embeddings))\n\u001b[1;32m    416\u001b[0m             L_snc_sup \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_supervised_criterion(sup_features_snc, labels)\n\u001b[0;32m--> 417\u001b[0m             L_snc_unsup \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unsupervised_criterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m         L_snc_total \u001b[38;5;241m=\u001b[39m L_snc_sup \u001b[38;5;241m+\u001b[39m L_snc_unsup\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Total loss calculation\u001b[39;00m\n",
      "File \u001b[0;32m~/BaCP-1/project/bacp.py:525\u001b[0m, in \u001b[0;36mBaCPTrainer._unsupervised_criterion\u001b[0;34m(self, features1, features2)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_unsupervised_criterion\u001b[39m(\u001b[38;5;28mself\u001b[39m, features1, features2):\n\u001b[0;32m--> 525\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsupervised_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/BaCP-1/project/loss_fn.py:90\u001b[0m, in \u001b[0;36mNTXentLoss.forward\u001b[0;34m(self, features1, features2)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Creating a mask where mask[i, j] = 1 if samples i and j are from different views of the same sample\u001b[39;00m\n\u001b[1;32m     89\u001b[0m labels \u001b[38;5;241m=\u001b[39m repeated_indices\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: [2N, 1]\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m positive_pair_mask \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Calculating similarity between all samples (dot product of normalized features)\u001b[39;00m\n\u001b[1;32m     93\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(features, features\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='magnitude_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_MID,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning_b1',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args, lambdas=None)\n",
    "if True:\n",
    "    bacp_trainer.train()\n",
    "    print_dynamic_lambdas_statistics(bacp_trainer)\n",
    "\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_b1_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)\n",
    "\n",
    "save_object(\n",
    "    bacp_trainer.lambda_history, \n",
    "    f'{MODEL_NAME}_{MODEL_TASK}_{bacp_trainer.pruning_type}_{bacp_trainer.target_sparsity}_lambda_history.pkl'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing finetuned weights path\n",
    "finetuned_weights = f\"./research/{MODEL_NAME}/{MODEL_TASK}/{MODEL_NAME}_{MODEL_TASK}_baseline.pt\"\n",
    "\n",
    "bacp_training_args = BaCPTrainingArguments(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_task=MODEL_TASK,\n",
    "    batch_size=BATCH_SIZE_CNN,\n",
    "    optimizer_type_and_lr=('sgd', 0.1),\n",
    "    pruning_type='magnitude_pruning',\n",
    "    target_sparsity=TARGET_SPARSITY_HIGH,\n",
    "    sparsity_scheduler='cubic',\n",
    "    finetuned_weights=finetuned_weights,\n",
    "    learning_type='bacp_pruning_b1',\n",
    "    db=False,\n",
    ")\n",
    "bacp_trainer = BaCPTrainer(bacp_training_args, lambdas=None)\n",
    "if True:\n",
    "    bacp_trainer.train()\n",
    "    print_dynamic_lambdas_statistics(bacp_trainer)\n",
    "\n",
    "bacp_trainer.generate_mask_from_model()\n",
    "training_args = TrainingArguments(\n",
    "    model_name=bacp_trainer.model_name,\n",
    "    model_task=bacp_trainer.model_task,\n",
    "    batch_size=bacp_trainer.batch_size,\n",
    "    optimizer_type_and_lr=('adamw', 0.0001),\n",
    "    pruner=bacp_trainer.get_pruner(),\n",
    "    pruning_type=bacp_trainer.pruning_type,\n",
    "    target_sparsity=bacp_trainer.target_sparsity,\n",
    "    epochs=50,\n",
    "    finetuned_weights=bacp_trainer.save_path,\n",
    "    finetune=True,\n",
    "    learning_type=\"bacp_b1_finetune\",\n",
    "    db=False,\n",
    ")\n",
    "trainer = Trainer(training_args)\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print_statistics(metrics, trainer)\n",
    "\n",
    "save_object(\n",
    "    bacp_trainer.lambda_history, \n",
    "    f'{MODEL_NAME}_{MODEL_TASK}_{bacp_trainer.pruning_type}_{bacp_trainer.target_sparsity}_lambda_history.pkl'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
