Model : vit_small - Learning Type: cifar10/bacp_pruning/magnitude_pruning/0.95
Configuration:
model_name: vit_small
model_task: cifar10
model_type: cv
num_classes: 10
batch_size: 256
learning_rate: 0.1
optimizer_type: sgd
epochs: 10
recovery_epochs: 0
patience: 20
pruning_type: magnitude_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
pruning_epochs: 10
n_views: 2
temperature: 0.15
base_temperature: 0.15
device: cuda
enable_mixed_precision: True
num_workers: 24
train_batches: 166
val_batches: 29
current_model_path: /dbfs/research/vit_small/cifar10/vit_small_cifar10_magnitude_pruning_0.95_bacp_pruning.pt

Epoch [1/10]: Avg Total Loss: 6.0928 | Avg PrC Loss: 2.9736 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.7703 | Avg CE Loss: 0.3489 | Model Sparsity: 0.95
Epoch [2/10]: Avg Total Loss: 7.9907 | Avg PrC Loss: 2.8374 | Avg SnC Loss: 2.3633 | Avg FiC Loss: 2.5407 | Avg CE Loss: 0.2493 | Model Sparsity: 0.95
Epoch [3/10]: Avg Total Loss: 10.3098 | Avg PrC Loss: 2.8349 | Avg SnC Loss: 4.6889 | Avg FiC Loss: 2.5359 | Avg CE Loss: 0.2501 | Model Sparsity: 0.95
