Model : vit_tiny - Learning Type: emnist/pruning/magnitude_pruning/0.99
Configuration:
model_type: cv
model_name: vit_tiny
model_task: emnist
num_classes: 47
criterion: CrossEntropyLoss()
embedding_dim: 192
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 256
learning_rate: 0.01
learning_type: pruning
optimizer_type: sgd
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.99
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vit_tiny/emnist/vit_tiny_emnist_magnitude_pruning_0.99_pruning.pt
finetuned_weights: /dbfs/research/vit_tiny/emnist/vit_tiny_emnist_baseline.pt

Epoch [1/5]: Avg Loss: 0.2874 | Avg Accuracy: 88.59 | Avg Perplexity: 0.000 |Model Sparsity: 0.4831
Recovery epoch [1/10]: Avg Loss: 0.2548 | Avg Accuracy: 89.22 | Model Sparsity: 0.4831
Recovery epoch [2/10]: Avg Loss: 0.2439 | Avg Accuracy: 89.31 | Model Sparsity: 0.4831
Recovery epoch [3/10]: Avg Loss: 0.2371 | Avg Accuracy: 89.09 | Model Sparsity: 0.4831
Recovery epoch [4/10]: Avg Loss: 0.2314 | Avg Accuracy: 88.64 | Model Sparsity: 0.4831
Recovery epoch [5/10]: Avg Loss: 0.2281 | Avg Accuracy: 88.77 | Model Sparsity: 0.4831
Recovery epoch [6/10]: Avg Loss: 0.2244 | Avg Accuracy: 89.39 | Model Sparsity: 0.4831
Recovery epoch [7/10]: Avg Loss: 0.2240 | Avg Accuracy: 88.95 | Model Sparsity: 0.4831
Recovery epoch [8/10]: Avg Loss: 0.2189 | Avg Accuracy: 89.48 | Model Sparsity: 0.4831
Recovery epoch [9/10]: Avg Loss: 0.2179 | Avg Accuracy: 88.99 | Model Sparsity: 0.4831
Recovery epoch [10/10]: Avg Loss: 0.2173 | Avg Accuracy: 89.33 | Model Sparsity: 0.4831
Epoch [2/5]: Avg Loss: 3.5321 | Avg Accuracy: 10.88 | Avg Perplexity: 0.000 |Model Sparsity: 0.7762
Recovery epoch [1/10]: Avg Loss: 1.6323 | Avg Accuracy: 77.66 | Model Sparsity: 0.7762
Recovery epoch [2/10]: Avg Loss: 0.4674 | Avg Accuracy: 85.52 | Model Sparsity: 0.7762
Recovery epoch [3/10]: Avg Loss: 0.3737 | Avg Accuracy: 86.35 | Model Sparsity: 0.7762
Recovery epoch [4/10]: Avg Loss: 0.3432 | Avg Accuracy: 86.64 | Model Sparsity: 0.7762
Recovery epoch [5/10]: Avg Loss: 0.3253 | Avg Accuracy: 86.36 | Model Sparsity: 0.7762
Recovery epoch [6/10]: Avg Loss: 0.3171 | Avg Accuracy: 87.03 | Model Sparsity: 0.7762
Recovery epoch [7/10]: Avg Loss: 0.3061 | Avg Accuracy: 87.85 | Model Sparsity: 0.7762
Recovery epoch [8/10]: Avg Loss: 0.3007 | Avg Accuracy: 87.86 | Model Sparsity: 0.7762
Recovery epoch [9/10]: Avg Loss: 0.2951 | Avg Accuracy: 87.90 | Model Sparsity: 0.7762
Recovery epoch [10/10]: Avg Loss: 0.2916 | Avg Accuracy: 87.72 | Model Sparsity: 0.7762
Epoch [3/5]: Avg Loss: 0.7035 | Avg Accuracy: 85.14 | Avg Perplexity: 0.000 |Model Sparsity: 0.9266
Recovery epoch [1/10]: Avg Loss: 0.3781 | Avg Accuracy: 85.92 | Model Sparsity: 0.9266
Recovery epoch [2/10]: Avg Loss: 0.3550 | Avg Accuracy: 86.20 | Model Sparsity: 0.9266
Recovery epoch [3/10]: Avg Loss: 0.3437 | Avg Accuracy: 86.41 | Model Sparsity: 0.9266
Recovery epoch [4/10]: Avg Loss: 0.3362 | Avg Accuracy: 86.77 | Model Sparsity: 0.9266
Recovery epoch [5/10]: Avg Loss: 0.3354 | Avg Accuracy: 86.97 | Model Sparsity: 0.9266
Recovery epoch [6/10]: Avg Loss: 0.3260 | Avg Accuracy: 86.36 | Model Sparsity: 0.9266
Recovery epoch [7/10]: Avg Loss: 0.3246 | Avg Accuracy: 86.76 | Model Sparsity: 0.9266
Recovery epoch [8/10]: Avg Loss: 0.3226 | Avg Accuracy: 87.04 | Model Sparsity: 0.9266
Recovery epoch [9/10]: Avg Loss: 0.3238 | Avg Accuracy: 87.51 | Model Sparsity: 0.9266
Recovery epoch [10/10]: Avg Loss: 0.3216 | Avg Accuracy: 86.69 | Model Sparsity: 0.9266
Epoch [4/5]: Avg Loss: 0.4985 | Avg Accuracy: 84.93 | Avg Perplexity: 0.000 |Model Sparsity: 0.9821
Recovery epoch [1/10]: Avg Loss: 0.3761 | Avg Accuracy: 86.07 | Model Sparsity: 0.9821
Recovery epoch [2/10]: Avg Loss: 0.3604 | Avg Accuracy: 85.33 | Model Sparsity: 0.9821
Recovery epoch [3/10]: Avg Loss: 0.3530 | Avg Accuracy: 85.13 | Model Sparsity: 0.9821
Recovery epoch [4/10]: Avg Loss: 0.3554 | Avg Accuracy: 85.97 | Model Sparsity: 0.9821
Recovery epoch [5/10]: Avg Loss: 0.3455 | Avg Accuracy: 85.71 | Model Sparsity: 0.9821
Recovery epoch [6/10]: Avg Loss: 0.3436 | Avg Accuracy: 86.72 | Model Sparsity: 0.9821
Recovery epoch [7/10]: Avg Loss: 0.3433 | Avg Accuracy: 86.57 | Model Sparsity: 0.9821
Recovery epoch [8/10]: Avg Loss: 0.3453 | Avg Accuracy: 87.16 | Model Sparsity: 0.9821
Recovery epoch [9/10]: Avg Loss: 0.3367 | Avg Accuracy: 86.87 | Model Sparsity: 0.9821
Recovery epoch [10/10]: Avg Loss: 0.3397 | Avg Accuracy: 86.62 | Model Sparsity: 0.9821
Epoch [5/5]: Avg Loss: 0.3513 | Avg Accuracy: 86.47 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Recovery epoch [1/10]: Avg Loss: 0.3406 | Avg Accuracy: 86.79 | Model Sparsity: 0.99
Recovery epoch [2/10]: Avg Loss: 0.3422 | Avg Accuracy: 86.42 | Model Sparsity: 0.99
Recovery epoch [3/10]: Avg Loss: 0.3367 | Avg Accuracy: 86.71 | Model Sparsity: 0.99
Recovery epoch [4/10]: Avg Loss: 0.3411 | Avg Accuracy: 86.93 | Model Sparsity: 0.99
Recovery epoch [5/10]: Avg Loss: 0.3356 | Avg Accuracy: 86.66 | Model Sparsity: 0.99
Recovery epoch [6/10]: Avg Loss: 0.3389 | Avg Accuracy: 86.79 | Model Sparsity: 0.99
Recovery epoch [7/10]: Avg Loss: 0.3363 | Avg Accuracy: 86.90 | Model Sparsity: 0.99
Recovery epoch [8/10]: Avg Loss: 0.3330 | Avg Accuracy: 86.74 | Model Sparsity: 0.99
Recovery epoch [9/10]: Avg Loss: 0.3332 | Avg Accuracy: 86.90 | Model Sparsity: 0.99
Recovery epoch [10/10]: Avg Loss: 0.3368 | Avg Accuracy: 86.61 | Model Sparsity: 0.99
