Model : vit_tiny - Learning Type: emnist/bacp_finetune/magnitude_pruning/0.97
Configuration:
model_type: cv
model_name: vit_tiny
model_task: emnist
num_classes: 47
criterion: CrossEntropyLoss()
embedding_dim: 192
epochs: 50
pruning_epochs: 50
recovery_epochs: 10
batch_size: 256
learning_rate: 0.0001
learning_type: bacp_finetune
optimizer_type: adamw
prune: False
pruning_type: magnitude_pruning
target_sparsity: 0.97
sparsity_scheduler: linear
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vit_tiny/emnist/vit_tiny_emnist_magnitude_pruning_0.97_bacp_finetune.pt
finetuned_weights: /dbfs/research/vit_tiny/emnist/vit_tiny_emnist_magnitude_pruning_0.97_bacp_pruning.pt

Epoch [1/50]: Avg Loss: 1.1235 | Avg Accuracy: 87.01 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [2/50]: Avg Loss: 0.3722 | Avg Accuracy: 88.26 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [3/50]: Avg Loss: 0.3107 | Avg Accuracy: 88.89 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [4/50]: Avg Loss: 0.2882 | Avg Accuracy: 89.30 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [5/50]: Avg Loss: 0.2762 | Avg Accuracy: 89.36 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [6/50]: Avg Loss: 0.2700 | Avg Accuracy: 89.44 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [7/50]: Avg Loss: 0.2643 | Avg Accuracy: 89.30 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [8/50]: Avg Loss: 0.2607 | Avg Accuracy: 89.41 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [9/50]: Avg Loss: 0.2571 | Avg Accuracy: 89.20 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [10/50]: Avg Loss: 0.2552 | Avg Accuracy: 89.48 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [11/50]: Avg Loss: 0.2519 | Avg Accuracy: 89.45 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [12/50]: Avg Loss: 0.2491 | Avg Accuracy: 89.55 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [13/50]: Avg Loss: 0.2470 | Avg Accuracy: 89.25 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [14/50]: Avg Loss: 0.2452 | Avg Accuracy: 89.65 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [15/50]: Avg Loss: 0.2434 | Avg Accuracy: 89.49 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [16/50]: Avg Loss: 0.2422 | Avg Accuracy: 89.54 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [17/50]: Avg Loss: 0.2398 | Avg Accuracy: 89.83 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [18/50]: Avg Loss: 0.2370 | Avg Accuracy: 89.81 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [19/50]: Avg Loss: 0.2360 | Avg Accuracy: 89.70 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [20/50]: Avg Loss: 0.2346 | Avg Accuracy: 89.55 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [21/50]: Avg Loss: 0.2337 | Avg Accuracy: 89.71 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [22/50]: Avg Loss: 0.2319 | Avg Accuracy: 89.48 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [23/50]: Avg Loss: 0.2313 | Avg Accuracy: 89.84 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [24/50]: Avg Loss: 0.2289 | Avg Accuracy: 89.61 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [25/50]: Avg Loss: 0.2288 | Avg Accuracy: 89.46 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [26/50]: Avg Loss: 0.2276 | Avg Accuracy: 89.40 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [27/50]: Avg Loss: 0.2268 | Avg Accuracy: 89.64 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [28/50]: Avg Loss: 0.2256 | Avg Accuracy: 89.50 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [29/50]: Avg Loss: 0.2247 | Avg Accuracy: 89.18 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [30/50]: Avg Loss: 0.2237 | Avg Accuracy: 89.73 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [31/50]: Avg Loss: 0.2230 | Avg Accuracy: 89.81 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [32/50]: Avg Loss: 0.2214 | Avg Accuracy: 89.79 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [33/50]: Avg Loss: 0.2214 | Avg Accuracy: 89.99 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [34/50]: Avg Loss: 0.2185 | Avg Accuracy: 90.00 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [35/50]: Avg Loss: 0.2182 | Avg Accuracy: 89.83 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [36/50]: Avg Loss: 0.2175 | Avg Accuracy: 89.86 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [37/50]: Avg Loss: 0.2153 | Avg Accuracy: 89.74 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [38/50]: Avg Loss: 0.2168 | Avg Accuracy: 89.94 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [39/50]: Avg Loss: 0.2143 | Avg Accuracy: 89.78 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [40/50]: Avg Loss: 0.2146 | Avg Accuracy: 89.60 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [41/50]: Avg Loss: 0.2139 | Avg Accuracy: 89.87 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [42/50]: Avg Loss: 0.2116 | Avg Accuracy: 89.47 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [43/50]: Avg Loss: 0.2116 | Avg Accuracy: 89.68 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [44/50]: Avg Loss: 0.2116 | Avg Accuracy: 89.59 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [45/50]: Avg Loss: 0.2100 | Avg Accuracy: 90.09 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [46/50]: Avg Loss: 0.2099 | Avg Accuracy: 89.68 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [47/50]: Avg Loss: 0.2092 | Avg Accuracy: 89.96 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [48/50]: Avg Loss: 0.2081 | Avg Accuracy: 89.70 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [49/50]: Avg Loss: 0.2081 | Avg Accuracy: 89.63 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [50/50]: Avg Loss: 0.2060 | Avg Accuracy: 89.73 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
