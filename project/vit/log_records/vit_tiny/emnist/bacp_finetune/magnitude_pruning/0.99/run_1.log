Model : vit_tiny - Learning Type: emnist/bacp_finetune/magnitude_pruning/0.99
Configuration:
model_type: cv
model_name: vit_tiny
model_task: emnist
num_classes: 47
criterion: CrossEntropyLoss()
embedding_dim: 192
epochs: 50
pruning_epochs: 50
recovery_epochs: 10
batch_size: 256
learning_rate: 0.0001
learning_type: bacp_finetune
optimizer_type: adamw
prune: False
pruning_type: magnitude_pruning
target_sparsity: 0.99
sparsity_scheduler: linear
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vit_tiny/emnist/vit_tiny_emnist_magnitude_pruning_0.99_bacp_finetune.pt
finetuned_weights: /dbfs/research/vit_tiny/emnist/vit_tiny_emnist_magnitude_pruning_0.99_bacp_pruning.pt

Epoch [1/50]: Avg Loss: 1.4804 | Avg Accuracy: 85.07 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [2/50]: Avg Loss: 0.4503 | Avg Accuracy: 87.04 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [3/50]: Avg Loss: 0.3543 | Avg Accuracy: 88.13 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [4/50]: Avg Loss: 0.3248 | Avg Accuracy: 88.48 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [5/50]: Avg Loss: 0.3112 | Avg Accuracy: 88.65 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [6/50]: Avg Loss: 0.3013 | Avg Accuracy: 88.65 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [7/50]: Avg Loss: 0.2976 | Avg Accuracy: 89.08 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [8/50]: Avg Loss: 0.2909 | Avg Accuracy: 88.74 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [9/50]: Avg Loss: 0.2871 | Avg Accuracy: 88.66 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [10/50]: Avg Loss: 0.2842 | Avg Accuracy: 88.87 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [11/50]: Avg Loss: 0.2795 | Avg Accuracy: 89.01 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [12/50]: Avg Loss: 0.2776 | Avg Accuracy: 88.98 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [13/50]: Avg Loss: 0.2751 | Avg Accuracy: 88.89 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [14/50]: Avg Loss: 0.2736 | Avg Accuracy: 88.90 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [15/50]: Avg Loss: 0.2715 | Avg Accuracy: 89.07 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [16/50]: Avg Loss: 0.2688 | Avg Accuracy: 88.87 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [17/50]: Avg Loss: 0.2677 | Avg Accuracy: 88.81 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [18/50]: Avg Loss: 0.2664 | Avg Accuracy: 89.16 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [19/50]: Avg Loss: 0.2640 | Avg Accuracy: 89.21 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [20/50]: Avg Loss: 0.2640 | Avg Accuracy: 88.93 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [21/50]: Avg Loss: 0.2632 | Avg Accuracy: 88.93 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [22/50]: Avg Loss: 0.2598 | Avg Accuracy: 89.02 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [23/50]: Avg Loss: 0.2590 | Avg Accuracy: 89.11 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [24/50]: Avg Loss: 0.2584 | Avg Accuracy: 89.15 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [25/50]: Avg Loss: 0.2583 | Avg Accuracy: 89.12 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [26/50]: Avg Loss: 0.2565 | Avg Accuracy: 89.17 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [27/50]: Avg Loss: 0.2554 | Avg Accuracy: 89.00 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [28/50]: Avg Loss: 0.2561 | Avg Accuracy: 89.06 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [29/50]: Avg Loss: 0.2533 | Avg Accuracy: 88.93 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [30/50]: Avg Loss: 0.2530 | Avg Accuracy: 89.02 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [31/50]: Avg Loss: 0.2514 | Avg Accuracy: 88.85 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [32/50]: Avg Loss: 0.2512 | Avg Accuracy: 89.25 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [33/50]: Avg Loss: 0.2485 | Avg Accuracy: 89.20 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [34/50]: Avg Loss: 0.2493 | Avg Accuracy: 89.27 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [35/50]: Avg Loss: 0.2491 | Avg Accuracy: 89.05 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [36/50]: Avg Loss: 0.2467 | Avg Accuracy: 88.98 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [37/50]: Avg Loss: 0.2464 | Avg Accuracy: 89.07 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [38/50]: Avg Loss: 0.2463 | Avg Accuracy: 89.17 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [39/50]: Avg Loss: 0.2463 | Avg Accuracy: 89.19 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [40/50]: Avg Loss: 0.2440 | Avg Accuracy: 89.23 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [41/50]: Avg Loss: 0.2436 | Avg Accuracy: 89.18 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [42/50]: Avg Loss: 0.2418 | Avg Accuracy: 89.25 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [43/50]: Avg Loss: 0.2420 | Avg Accuracy: 89.12 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [44/50]: Avg Loss: 0.2419 | Avg Accuracy: 88.97 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [45/50]: Avg Loss: 0.2422 | Avg Accuracy: 89.09 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [46/50]: Avg Loss: 0.2393 | Avg Accuracy: 89.08 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [47/50]: Avg Loss: 0.2397 | Avg Accuracy: 88.99 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [48/50]: Avg Loss: 0.2396 | Avg Accuracy: 89.13 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [49/50]: Avg Loss: 0.2381 | Avg Accuracy: 89.18 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
Epoch [50/50]: Avg Loss: 0.2367 | Avg Accuracy: 88.75 | Avg Perplexity: 0.000 |Model Sparsity: 0.99
