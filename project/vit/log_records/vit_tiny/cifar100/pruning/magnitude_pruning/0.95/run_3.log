Model : vit_tiny - Learning Type: cifar100/pruning/magnitude_pruning/0.95
Configuration:
model_type: cv
model_name: vit_tiny
model_task: cifar100
num_classes: 100
criterion: CrossEntropyLoss()
embedding_dim: 192
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 256
learning_rate: 0.01
learning_type: pruning
optimizer_type: sgd
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vit_tiny/cifar100/vit_tiny_cifar100_magnitude_pruning_0.95_pruning.pt
finetuned_weights: /dbfs/research/vit_tiny/cifar100/vit_tiny_cifar100_baseline.pt

Epoch [1/5]: Avg Loss: 0.5399 | Avg Accuracy: 76.68 | Avg Perplexity: 0.000 |Model Sparsity: 0.4636
Recovery epoch [1/10]: Avg Loss: 0.3489 | Avg Accuracy: 78.03 | Model Sparsity: 0.4636
Recovery epoch [2/10]: Avg Loss: 0.2567 | Avg Accuracy: 78.23 | Model Sparsity: 0.4636
Recovery epoch [3/10]: Avg Loss: 0.2073 | Avg Accuracy: 78.99 | Model Sparsity: 0.4636
Recovery epoch [4/10]: Avg Loss: 0.1568 | Avg Accuracy: 79.14 | Model Sparsity: 0.4636
Recovery epoch [5/10]: Avg Loss: 0.1215 | Avg Accuracy: 79.49 | Model Sparsity: 0.4636
Recovery epoch [6/10]: Avg Loss: 0.0988 | Avg Accuracy: 79.88 | Model Sparsity: 0.4636
Recovery epoch [7/10]: Avg Loss: 0.0760 | Avg Accuracy: 80.93 | Model Sparsity: 0.4636
Recovery epoch [8/10]: Avg Loss: 0.0588 | Avg Accuracy: 80.85 | Model Sparsity: 0.4636
Recovery epoch [9/10]: Avg Loss: 0.0528 | Avg Accuracy: 79.89 | Model Sparsity: 0.4636
Recovery epoch [10/10]: Avg Loss: 0.0433 | Avg Accuracy: 81.25 | Model Sparsity: 0.4636
Epoch [2/5]: Avg Loss: 2.5464 | Avg Accuracy: 55.86 | Avg Perplexity: 0.000 |Model Sparsity: 0.7448
Recovery epoch [1/10]: Avg Loss: 1.1622 | Avg Accuracy: 65.19 | Model Sparsity: 0.7448
Recovery epoch [2/10]: Avg Loss: 0.8876 | Avg Accuracy: 66.95 | Model Sparsity: 0.7448
Recovery epoch [3/10]: Avg Loss: 0.7289 | Avg Accuracy: 69.11 | Model Sparsity: 0.7448
Recovery epoch [4/10]: Avg Loss: 0.6252 | Avg Accuracy: 70.45 | Model Sparsity: 0.7448
Recovery epoch [5/10]: Avg Loss: 0.5383 | Avg Accuracy: 71.65 | Model Sparsity: 0.7448
Recovery epoch [6/10]: Avg Loss: 0.4685 | Avg Accuracy: 71.19 | Model Sparsity: 0.7448
Recovery epoch [7/10]: Avg Loss: 0.4145 | Avg Accuracy: 71.09 | Model Sparsity: 0.7448
Recovery epoch [8/10]: Avg Loss: 0.3550 | Avg Accuracy: 71.57 | Model Sparsity: 0.7448
Recovery epoch [9/10]: Avg Loss: 0.3174 | Avg Accuracy: 72.16 | Model Sparsity: 0.7448
Recovery epoch [10/10]: Avg Loss: 0.2739 | Avg Accuracy: 73.30 | Model Sparsity: 0.7448
Epoch [3/5]: Avg Loss: 2.2871 | Avg Accuracy: 52.01 | Avg Perplexity: 0.000 |Model Sparsity: 0.8892
Recovery epoch [1/10]: Avg Loss: 1.3845 | Avg Accuracy: 57.18 | Model Sparsity: 0.8892
Recovery epoch [2/10]: Avg Loss: 1.1513 | Avg Accuracy: 60.63 | Model Sparsity: 0.8892
Recovery epoch [3/10]: Avg Loss: 1.0203 | Avg Accuracy: 62.50 | Model Sparsity: 0.8892
Recovery epoch [4/10]: Avg Loss: 0.9411 | Avg Accuracy: 63.01 | Model Sparsity: 0.8892
Recovery epoch [5/10]: Avg Loss: 0.8749 | Avg Accuracy: 64.36 | Model Sparsity: 0.8892
Recovery epoch [6/10]: Avg Loss: 0.8074 | Avg Accuracy: 64.61 | Model Sparsity: 0.8892
Recovery epoch [7/10]: Avg Loss: 0.7673 | Avg Accuracy: 64.96 | Model Sparsity: 0.8892
Recovery epoch [8/10]: Avg Loss: 0.7096 | Avg Accuracy: 66.11 | Model Sparsity: 0.8892
Recovery epoch [9/10]: Avg Loss: 0.6676 | Avg Accuracy: 66.10 | Model Sparsity: 0.8892
Recovery epoch [10/10]: Avg Loss: 0.6532 | Avg Accuracy: 65.21 | Model Sparsity: 0.8892
Epoch [4/5]: Avg Loss: 1.6849 | Avg Accuracy: 57.25 | Avg Perplexity: 0.000 |Model Sparsity: 0.9424
Recovery epoch [1/10]: Avg Loss: 1.1195 | Avg Accuracy: 59.12 | Model Sparsity: 0.9424
Recovery epoch [2/10]: Avg Loss: 1.0195 | Avg Accuracy: 60.37 | Model Sparsity: 0.9424
Recovery epoch [3/10]: Avg Loss: 0.9514 | Avg Accuracy: 62.66 | Model Sparsity: 0.9424
Recovery epoch [4/10]: Avg Loss: 0.8885 | Avg Accuracy: 64.02 | Model Sparsity: 0.9424
Recovery epoch [5/10]: Avg Loss: 0.8600 | Avg Accuracy: 63.42 | Model Sparsity: 0.9424
Recovery epoch [6/10]: Avg Loss: 0.8090 | Avg Accuracy: 64.78 | Model Sparsity: 0.9424
Recovery epoch [7/10]: Avg Loss: 0.7912 | Avg Accuracy: 63.32 | Model Sparsity: 0.9424
Recovery epoch [8/10]: Avg Loss: 0.7745 | Avg Accuracy: 64.79 | Model Sparsity: 0.9424
Recovery epoch [9/10]: Avg Loss: 0.7506 | Avg Accuracy: 63.00 | Model Sparsity: 0.9424
Recovery epoch [10/10]: Avg Loss: 0.7151 | Avg Accuracy: 64.45 | Model Sparsity: 0.9424
Epoch [5/5]: Avg Loss: 0.8779 | Avg Accuracy: 63.63 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Recovery epoch [1/10]: Avg Loss: 0.7598 | Avg Accuracy: 65.03 | Model Sparsity: 0.95
Recovery epoch [2/10]: Avg Loss: 0.7076 | Avg Accuracy: 63.00 | Model Sparsity: 0.95
Recovery epoch [3/10]: Avg Loss: 0.7064 | Avg Accuracy: 62.46 | Model Sparsity: 0.95
Recovery epoch [4/10]: Avg Loss: 0.6752 | Avg Accuracy: 63.13 | Model Sparsity: 0.95
Recovery epoch [5/10]: Avg Loss: 0.6521 | Avg Accuracy: 64.21 | Model Sparsity: 0.95
Recovery epoch [6/10]: Avg Loss: 0.6415 | Avg Accuracy: 63.38 | Model Sparsity: 0.95
Recovery epoch [7/10]: Avg Loss: 0.6338 | Avg Accuracy: 65.02 | Model Sparsity: 0.95
Recovery epoch [8/10]: Avg Loss: 0.6211 | Avg Accuracy: 63.78 | Model Sparsity: 0.95
Recovery epoch [9/10]: Avg Loss: 0.6072 | Avg Accuracy: 64.10 | Model Sparsity: 0.95
Recovery epoch [10/10]: Avg Loss: 0.6074 | Avg Accuracy: 63.38 | Model Sparsity: 0.95
