Model : vit_tiny - Learning Type: cifar100/pruning/magnitude_pruning/0.97
Configuration:
model_type: cv
model_name: vit_tiny
model_task: cifar100
num_classes: 100
criterion: CrossEntropyLoss()
embedding_dim: 192
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 256
learning_rate: 0.01
learning_type: pruning
optimizer_type: sgd
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.97
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vit_tiny/cifar100/vit_tiny_cifar100_magnitude_pruning_0.97_pruning.pt
finetuned_weights: /dbfs/research/vit_tiny/cifar100/vit_tiny_cifar100_baseline.pt

Epoch [1/5]: Avg Loss: 0.5788 | Avg Accuracy: 76.35 | Model Sparsity: 0.4734
Recovery epoch [1/10]: Avg Loss: 0.3490 | Avg Accuracy: 78.46 | Model Sparsity: 0.4734
Recovery epoch [2/10]: Avg Loss: 0.2740 | Avg Accuracy: 79.16 | Model Sparsity: 0.4734
Recovery epoch [3/10]: Avg Loss: 0.2058 | Avg Accuracy: 79.04 | Model Sparsity: 0.4734
Recovery epoch [4/10]: Avg Loss: 0.1678 | Avg Accuracy: 77.44 | Model Sparsity: 0.4734
Recovery epoch [5/10]: Avg Loss: 0.1408 | Avg Accuracy: 79.36 | Model Sparsity: 0.4734
Recovery epoch [6/10]: Avg Loss: 0.1144 | Avg Accuracy: 79.73 | Model Sparsity: 0.4734
Recovery epoch [7/10]: Avg Loss: 0.0793 | Avg Accuracy: 80.56 | Model Sparsity: 0.4734
Recovery epoch [8/10]: Avg Loss: 0.0583 | Avg Accuracy: 80.48 | Model Sparsity: 0.4734
Recovery epoch [9/10]: Avg Loss: 0.0414 | Avg Accuracy: 81.94 | Model Sparsity: 0.4734
Recovery epoch [10/10]: Avg Loss: 0.0298 | Avg Accuracy: 81.80 | Model Sparsity: 0.4734
Epoch [2/5]: Avg Loss: 4.6974 | Avg Accuracy: 5.50 | Model Sparsity: 0.7605
Recovery epoch [1/10]: Avg Loss: 4.0990 | Avg Accuracy: 9.09 | Model Sparsity: 0.7605
Recovery epoch [2/10]: Avg Loss: 3.7950 | Avg Accuracy: 14.67 | Model Sparsity: 0.7605
Recovery epoch [3/10]: Avg Loss: 3.4539 | Avg Accuracy: 21.16 | Model Sparsity: 0.7605
Recovery epoch [4/10]: Avg Loss: 2.9796 | Avg Accuracy: 31.07 | Model Sparsity: 0.7605
Recovery epoch [5/10]: Avg Loss: 2.4482 | Avg Accuracy: 39.95 | Model Sparsity: 0.7605
Recovery epoch [6/10]: Avg Loss: 1.9336 | Avg Accuracy: 50.90 | Model Sparsity: 0.7605
Recovery epoch [7/10]: Avg Loss: 1.5380 | Avg Accuracy: 57.27 | Model Sparsity: 0.7605
Recovery epoch [8/10]: Avg Loss: 1.2876 | Avg Accuracy: 60.72 | Model Sparsity: 0.7605
Recovery epoch [9/10]: Avg Loss: 1.1131 | Avg Accuracy: 63.00 | Model Sparsity: 0.7605
Recovery epoch [10/10]: Avg Loss: 0.9920 | Avg Accuracy: 63.91 | Model Sparsity: 0.7605
Epoch [3/5]: Avg Loss: 2.4354 | Avg Accuracy: 48.61 | Model Sparsity: 0.9079
Recovery epoch [1/10]: Avg Loss: 1.7031 | Avg Accuracy: 52.10 | Model Sparsity: 0.9079
Recovery epoch [2/10]: Avg Loss: 1.5288 | Avg Accuracy: 55.12 | Model Sparsity: 0.9079
Recovery epoch [3/10]: Avg Loss: 1.4221 | Avg Accuracy: 55.32 | Model Sparsity: 0.9079
Recovery epoch [4/10]: Avg Loss: 1.3544 | Avg Accuracy: 55.68 | Model Sparsity: 0.9079
Recovery epoch [5/10]: Avg Loss: 1.2886 | Avg Accuracy: 57.72 | Model Sparsity: 0.9079
Recovery epoch [6/10]: Avg Loss: 1.2306 | Avg Accuracy: 57.56 | Model Sparsity: 0.9079
Recovery epoch [7/10]: Avg Loss: 1.1882 | Avg Accuracy: 59.27 | Model Sparsity: 0.9079
Recovery epoch [8/10]: Avg Loss: 1.1693 | Avg Accuracy: 59.27 | Model Sparsity: 0.9079
Recovery epoch [9/10]: Avg Loss: 1.1240 | Avg Accuracy: 59.56 | Model Sparsity: 0.9079
Recovery epoch [10/10]: Avg Loss: 1.0957 | Avg Accuracy: 61.13 | Model Sparsity: 0.9079
Epoch [4/5]: Avg Loss: 1.9427 | Avg Accuracy: 52.34 | Model Sparsity: 0.9622
Recovery epoch [1/10]: Avg Loss: 1.4568 | Avg Accuracy: 54.35 | Model Sparsity: 0.9622
Recovery epoch [2/10]: Avg Loss: 1.3725 | Avg Accuracy: 56.06 | Model Sparsity: 0.9622
Recovery epoch [3/10]: Avg Loss: 1.2976 | Avg Accuracy: 57.22 | Model Sparsity: 0.9622
Recovery epoch [4/10]: Avg Loss: 1.2604 | Avg Accuracy: 58.03 | Model Sparsity: 0.9622
Recovery epoch [5/10]: Avg Loss: 1.2235 | Avg Accuracy: 58.38 | Model Sparsity: 0.9622
Recovery epoch [6/10]: Avg Loss: 1.2022 | Avg Accuracy: 58.65 | Model Sparsity: 0.9622
Recovery epoch [7/10]: Avg Loss: 1.1654 | Avg Accuracy: 58.14 | Model Sparsity: 0.9622
Recovery epoch [8/10]: Avg Loss: 1.1437 | Avg Accuracy: 58.82 | Model Sparsity: 0.9622
Recovery epoch [9/10]: Avg Loss: 1.1196 | Avg Accuracy: 59.62 | Model Sparsity: 0.9622
Recovery epoch [10/10]: Avg Loss: 1.1172 | Avg Accuracy: 56.78 | Model Sparsity: 0.9622
Epoch [5/5]: Avg Loss: 1.2562 | Avg Accuracy: 56.78 | Model Sparsity: 0.97
Recovery epoch [1/10]: Avg Loss: 1.1457 | Avg Accuracy: 60.14 | Model Sparsity: 0.97
Recovery epoch [2/10]: Avg Loss: 1.1033 | Avg Accuracy: 60.32 | Model Sparsity: 0.97
Recovery epoch [3/10]: Avg Loss: 1.0858 | Avg Accuracy: 59.40 | Model Sparsity: 0.97
Recovery epoch [4/10]: Avg Loss: 1.0619 | Avg Accuracy: 59.28 | Model Sparsity: 0.97
Recovery epoch [5/10]: Avg Loss: 1.0613 | Avg Accuracy: 59.48 | Model Sparsity: 0.97
Recovery epoch [6/10]: Avg Loss: 1.0631 | Avg Accuracy: 60.04 | Model Sparsity: 0.97
Recovery epoch [7/10]: Avg Loss: 1.0302 | Avg Accuracy: 59.98 | Model Sparsity: 0.97
Recovery epoch [8/10]: Avg Loss: 1.0110 | Avg Accuracy: 59.83 | Model Sparsity: 0.97
Recovery epoch [9/10]: Avg Loss: 1.0074 | Avg Accuracy: 60.33 | Model Sparsity: 0.97
Recovery epoch [10/10]: Avg Loss: 0.9918 | Avg Accuracy: 58.15 | Model Sparsity: 0.97
