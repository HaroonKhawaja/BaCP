Model : vit_tiny - Learning Type: cifar10/pruning/magnitude_pruning/0.95
Configuration:
model_type: cv
model_name: vit_tiny
model_task: cifar10
num_classes: 10
criterion: CrossEntropyLoss()
embedding_dim: 192
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 256
learning_rate: 0.001
learning_type: pruning
optimizer_type: sgd
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vit_tiny/cifar10/vit_tiny_cifar10_magnitude_pruning_0.95_pruning.pt
finetuned_weights: /dbfs/research/vit_tiny/cifar10/vit_tiny_cifar10_baseline.pt

Epoch [1/5]: Avg Loss: 0.4226 | Avg Accuracy: 91.14 | Model Sparsity: 0.4636
Recovery epoch [1/10]: Avg Loss: 0.2116 | Avg Accuracy: 92.59 | Model Sparsity: 0.4636
Recovery epoch [2/10]: Avg Loss: 0.1640 | Avg Accuracy: 93.60 | Model Sparsity: 0.4636
Recovery epoch [3/10]: Avg Loss: 0.1363 | Avg Accuracy: 94.22 | Model Sparsity: 0.4636
Recovery epoch [4/10]: Avg Loss: 0.1148 | Avg Accuracy: 94.69 | Model Sparsity: 0.4636
Recovery epoch [5/10]: Avg Loss: 0.1022 | Avg Accuracy: 94.68 | Model Sparsity: 0.4636
Recovery epoch [6/10]: Avg Loss: 0.0879 | Avg Accuracy: 95.18 | Model Sparsity: 0.4636
Recovery epoch [7/10]: Avg Loss: 0.0785 | Avg Accuracy: 94.91 | Model Sparsity: 0.4636
Recovery epoch [8/10]: Avg Loss: 0.0678 | Avg Accuracy: 95.16 | Model Sparsity: 0.4636
Recovery epoch [9/10]: Avg Loss: 0.0609 | Avg Accuracy: 95.15 | Model Sparsity: 0.4636
Recovery epoch [10/10]: Avg Loss: 0.0537 | Avg Accuracy: 95.54 | Model Sparsity: 0.4636
Epoch [2/5]: Avg Loss: 1.4767 | Avg Accuracy: 61.26 | Model Sparsity: 0.7448
Recovery epoch [1/10]: Avg Loss: 0.9906 | Avg Accuracy: 68.04 | Model Sparsity: 0.7448
Recovery epoch [2/10]: Avg Loss: 0.8172 | Avg Accuracy: 72.66 | Model Sparsity: 0.7448
Recovery epoch [3/10]: Avg Loss: 0.7233 | Avg Accuracy: 75.18 | Model Sparsity: 0.7448
Recovery epoch [4/10]: Avg Loss: 0.6398 | Avg Accuracy: 76.63 | Model Sparsity: 0.7448
Recovery epoch [5/10]: Avg Loss: 0.5920 | Avg Accuracy: 79.15 | Model Sparsity: 0.7448
Recovery epoch [6/10]: Avg Loss: 0.5349 | Avg Accuracy: 80.15 | Model Sparsity: 0.7448
Recovery epoch [7/10]: Avg Loss: 0.5080 | Avg Accuracy: 81.10 | Model Sparsity: 0.7448
Recovery epoch [8/10]: Avg Loss: 0.4745 | Avg Accuracy: 82.62 | Model Sparsity: 0.7448
Recovery epoch [9/10]: Avg Loss: 0.4458 | Avg Accuracy: 82.10 | Model Sparsity: 0.7448
Recovery epoch [10/10]: Avg Loss: 0.4172 | Avg Accuracy: 83.20 | Model Sparsity: 0.7448
Epoch [3/5]: Avg Loss: 1.6736 | Avg Accuracy: 49.39 | Model Sparsity: 0.8892
Recovery epoch [1/10]: Avg Loss: 1.3108 | Avg Accuracy: 56.83 | Model Sparsity: 0.8892
Recovery epoch [2/10]: Avg Loss: 1.1730 | Avg Accuracy: 59.25 | Model Sparsity: 0.8892
Recovery epoch [3/10]: Avg Loss: 1.0773 | Avg Accuracy: 63.20 | Model Sparsity: 0.8892
Recovery epoch [4/10]: Avg Loss: 1.0139 | Avg Accuracy: 62.97 | Model Sparsity: 0.8892
Recovery epoch [5/10]: Avg Loss: 0.9723 | Avg Accuracy: 65.72 | Model Sparsity: 0.8892
Recovery epoch [6/10]: Avg Loss: 0.9434 | Avg Accuracy: 67.16 | Model Sparsity: 0.8892
Recovery epoch [7/10]: Avg Loss: 0.9063 | Avg Accuracy: 68.28 | Model Sparsity: 0.8892
Recovery epoch [8/10]: Avg Loss: 0.8720 | Avg Accuracy: 68.48 | Model Sparsity: 0.8892
Recovery epoch [9/10]: Avg Loss: 0.8418 | Avg Accuracy: 67.35 | Model Sparsity: 0.8892
Recovery epoch [10/10]: Avg Loss: 0.8276 | Avg Accuracy: 70.27 | Model Sparsity: 0.8892
Epoch [4/5]: Avg Loss: 1.2850 | Avg Accuracy: 59.17 | Model Sparsity: 0.9424
Recovery epoch [1/10]: Avg Loss: 1.0864 | Avg Accuracy: 60.82 | Model Sparsity: 0.9424
Recovery epoch [2/10]: Avg Loss: 1.0283 | Avg Accuracy: 64.01 | Model Sparsity: 0.9424
Recovery epoch [3/10]: Avg Loss: 0.9984 | Avg Accuracy: 64.86 | Model Sparsity: 0.9424
Recovery epoch [4/10]: Avg Loss: 0.9697 | Avg Accuracy: 66.26 | Model Sparsity: 0.9424
Recovery epoch [5/10]: Avg Loss: 0.9537 | Avg Accuracy: 67.25 | Model Sparsity: 0.9424
Recovery epoch [6/10]: Avg Loss: 0.9303 | Avg Accuracy: 65.76 | Model Sparsity: 0.9424
Recovery epoch [7/10]: Avg Loss: 0.9167 | Avg Accuracy: 67.46 | Model Sparsity: 0.9424
Recovery epoch [8/10]: Avg Loss: 0.9078 | Avg Accuracy: 67.46 | Model Sparsity: 0.9424
Recovery epoch [9/10]: Avg Loss: 0.8872 | Avg Accuracy: 65.40 | Model Sparsity: 0.9424
Recovery epoch [10/10]: Avg Loss: 0.8825 | Avg Accuracy: 67.78 | Model Sparsity: 0.9424
Epoch [5/5]: Avg Loss: 0.9528 | Avg Accuracy: 67.89 | Model Sparsity: 0.95
Recovery epoch [1/10]: Avg Loss: 0.8514 | Avg Accuracy: 68.40 | Model Sparsity: 0.95
Recovery epoch [2/10]: Avg Loss: 0.8441 | Avg Accuracy: 66.35 | Model Sparsity: 0.95
Recovery epoch [3/10]: Avg Loss: 0.8402 | Avg Accuracy: 68.05 | Model Sparsity: 0.95
Recovery epoch [4/10]: Avg Loss: 0.8214 | Avg Accuracy: 69.53 | Model Sparsity: 0.95
Recovery epoch [5/10]: Avg Loss: 0.8098 | Avg Accuracy: 70.65 | Model Sparsity: 0.95
Recovery epoch [6/10]: Avg Loss: 0.8051 | Avg Accuracy: 70.55 | Model Sparsity: 0.95
Recovery epoch [7/10]: Avg Loss: 0.8059 | Avg Accuracy: 69.71 | Model Sparsity: 0.95
Recovery epoch [8/10]: Avg Loss: 0.7887 | Avg Accuracy: 70.97 | Model Sparsity: 0.95
Recovery epoch [9/10]: Avg Loss: 0.7863 | Avg Accuracy: 71.59 | Model Sparsity: 0.95
Recovery epoch [10/10]: Avg Loss: 0.7827 | Avg Accuracy: 71.65 | Model Sparsity: 0.95
