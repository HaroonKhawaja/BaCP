Model : vit_tiny - Learning Type: cifar10/pruning/magnitude_pruning/0.97
Configuration:
model_type: cv
model_name: vit_tiny
model_task: cifar10
num_classes: 10
criterion: CrossEntropyLoss()
embedding_dim: 192
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 256
learning_rate: 0.01
learning_type: pruning
optimizer_type: sgd
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.97
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vit_tiny/cifar10/vit_tiny_cifar10_magnitude_pruning_0.97_pruning.pt
finetuned_weights: /dbfs/research/vit_tiny/cifar10/vit_tiny_cifar10_baseline.pt

Epoch [1/5]: Avg Loss: 2.1812 | Avg Accuracy: 29.53 | Model Sparsity: 0.4734
Recovery epoch [1/10]: Avg Loss: 1.8217 | Avg Accuracy: 38.32 | Model Sparsity: 0.4734
Recovery epoch [2/10]: Avg Loss: 1.4647 | Avg Accuracy: 54.85 | Model Sparsity: 0.4734
Recovery epoch [3/10]: Avg Loss: 1.0594 | Avg Accuracy: 67.01 | Model Sparsity: 0.4734
Recovery epoch [4/10]: Avg Loss: 0.6909 | Avg Accuracy: 81.71 | Model Sparsity: 0.4734
Recovery epoch [5/10]: Avg Loss: 0.3881 | Avg Accuracy: 88.89 | Model Sparsity: 0.4734
Recovery epoch [6/10]: Avg Loss: 0.2668 | Avg Accuracy: 91.58 | Model Sparsity: 0.4734
Recovery epoch [7/10]: Avg Loss: 0.1947 | Avg Accuracy: 91.88 | Model Sparsity: 0.4734
Recovery epoch [8/10]: Avg Loss: 0.1589 | Avg Accuracy: 92.62 | Model Sparsity: 0.4734
Recovery epoch [9/10]: Avg Loss: 0.1296 | Avg Accuracy: 93.39 | Model Sparsity: 0.4734
Recovery epoch [10/10]: Avg Loss: 0.1146 | Avg Accuracy: 93.18 | Model Sparsity: 0.4734
Epoch [2/5]: Avg Loss: 1.8931 | Avg Accuracy: 38.52 | Model Sparsity: 0.7605
Recovery epoch [1/10]: Avg Loss: 1.3258 | Avg Accuracy: 64.00 | Model Sparsity: 0.7605
Recovery epoch [2/10]: Avg Loss: 0.7744 | Avg Accuracy: 79.01 | Model Sparsity: 0.7605
Recovery epoch [3/10]: Avg Loss: 0.5210 | Avg Accuracy: 83.00 | Model Sparsity: 0.7605
Recovery epoch [4/10]: Avg Loss: 0.4259 | Avg Accuracy: 85.68 | Model Sparsity: 0.7605
Recovery epoch [5/10]: Avg Loss: 0.3646 | Avg Accuracy: 85.70 | Model Sparsity: 0.7605
Recovery epoch [6/10]: Avg Loss: 0.3185 | Avg Accuracy: 87.96 | Model Sparsity: 0.7605
Recovery epoch [7/10]: Avg Loss: 0.2857 | Avg Accuracy: 88.19 | Model Sparsity: 0.7605
Recovery epoch [8/10]: Avg Loss: 0.2614 | Avg Accuracy: 88.66 | Model Sparsity: 0.7605
Recovery epoch [9/10]: Avg Loss: 0.2535 | Avg Accuracy: 88.31 | Model Sparsity: 0.7605
Recovery epoch [10/10]: Avg Loss: 0.2306 | Avg Accuracy: 87.55 | Model Sparsity: 0.7605
Epoch [3/5]: Avg Loss: 1.1153 | Avg Accuracy: 71.85 | Model Sparsity: 0.9079
Recovery epoch [1/10]: Avg Loss: 0.6866 | Avg Accuracy: 75.79 | Model Sparsity: 0.9079
Recovery epoch [2/10]: Avg Loss: 0.5932 | Avg Accuracy: 79.24 | Model Sparsity: 0.9079
Recovery epoch [3/10]: Avg Loss: 0.5396 | Avg Accuracy: 79.07 | Model Sparsity: 0.9079
Recovery epoch [4/10]: Avg Loss: 0.4932 | Avg Accuracy: 83.53 | Model Sparsity: 0.9079
Recovery epoch [5/10]: Avg Loss: 0.4626 | Avg Accuracy: 80.81 | Model Sparsity: 0.9079
Recovery epoch [6/10]: Avg Loss: 0.4605 | Avg Accuracy: 84.23 | Model Sparsity: 0.9079
Recovery epoch [7/10]: Avg Loss: 0.4249 | Avg Accuracy: 83.28 | Model Sparsity: 0.9079
Recovery epoch [8/10]: Avg Loss: 0.4182 | Avg Accuracy: 83.45 | Model Sparsity: 0.9079
Recovery epoch [9/10]: Avg Loss: 0.4070 | Avg Accuracy: 85.16 | Model Sparsity: 0.9079
Recovery epoch [10/10]: Avg Loss: 0.3830 | Avg Accuracy: 84.70 | Model Sparsity: 0.9079
Epoch [4/5]: Avg Loss: 0.8424 | Avg Accuracy: 77.51 | Model Sparsity: 0.9622
Recovery epoch [1/10]: Avg Loss: 0.5716 | Avg Accuracy: 79.28 | Model Sparsity: 0.9622
Recovery epoch [2/10]: Avg Loss: 0.5376 | Avg Accuracy: 81.20 | Model Sparsity: 0.9622
Recovery epoch [3/10]: Avg Loss: 0.5217 | Avg Accuracy: 80.77 | Model Sparsity: 0.9622
Recovery epoch [4/10]: Avg Loss: 0.4976 | Avg Accuracy: 81.57 | Model Sparsity: 0.9622
Recovery epoch [5/10]: Avg Loss: 0.4805 | Avg Accuracy: 82.06 | Model Sparsity: 0.9622
Recovery epoch [6/10]: Avg Loss: 0.4655 | Avg Accuracy: 81.80 | Model Sparsity: 0.9622
Recovery epoch [7/10]: Avg Loss: 0.4568 | Avg Accuracy: 81.37 | Model Sparsity: 0.9622
Recovery epoch [8/10]: Avg Loss: 0.4594 | Avg Accuracy: 82.87 | Model Sparsity: 0.9622
Recovery epoch [9/10]: Avg Loss: 0.4430 | Avg Accuracy: 83.36 | Model Sparsity: 0.9622
Recovery epoch [10/10]: Avg Loss: 0.4488 | Avg Accuracy: 83.14 | Model Sparsity: 0.9622
Epoch [5/5]: Avg Loss: 0.4815 | Avg Accuracy: 82.76 | Model Sparsity: 0.97
Recovery epoch [1/10]: Avg Loss: 0.4462 | Avg Accuracy: 81.98 | Model Sparsity: 0.97
Recovery epoch [2/10]: Avg Loss: 0.4331 | Avg Accuracy: 83.82 | Model Sparsity: 0.97
Recovery epoch [3/10]: Avg Loss: 0.4327 | Avg Accuracy: 83.71 | Model Sparsity: 0.97
Recovery epoch [4/10]: Avg Loss: 0.4235 | Avg Accuracy: 84.20 | Model Sparsity: 0.97
Recovery epoch [5/10]: Avg Loss: 0.4172 | Avg Accuracy: 83.30 | Model Sparsity: 0.97
Recovery epoch [6/10]: Avg Loss: 0.4112 | Avg Accuracy: 83.05 | Model Sparsity: 0.97
Recovery epoch [7/10]: Avg Loss: 0.4169 | Avg Accuracy: 83.62 | Model Sparsity: 0.97
Recovery epoch [8/10]: Avg Loss: 0.4101 | Avg Accuracy: 83.47 | Model Sparsity: 0.97
Recovery epoch [9/10]: Avg Loss: 0.3990 | Avg Accuracy: 81.45 | Model Sparsity: 0.97
Recovery epoch [10/10]: Avg Loss: 0.4063 | Avg Accuracy: 82.93 | Model Sparsity: 0.97
