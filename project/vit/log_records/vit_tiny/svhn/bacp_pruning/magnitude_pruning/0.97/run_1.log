Model : vit_tiny - Learning Type: svhn/bacp_pruning/magnitude_pruning/0.97
Configuration:
model_name: vit_tiny
model_task: svhn
model_type: cv
num_classes: 10
batch_size: 256
learning_rate: 0.01
optimizer_type: sgd
epochs: 5
recovery_epochs: 10
patience: 20
pruning_type: magnitude_pruning
target_sparsity: 0.97
sparsity_scheduler: cubic
pruning_epochs: 5
n_views: 2
temperature: 0.15
base_temperature: 0.15
device: cuda
enable_mixed_precision: True
num_workers: 24
train_batches: 243
val_batches: 42
current_model_path: /dbfs/research/vit_tiny/svhn/vit_tiny_svhn_magnitude_pruning_0.97_bacp_pruning.pt

Epoch [1/5]: Avg Total Loss: 5.8525 | Avg PrC Loss: 3.1781 | Avg SnC Loss: 0.0000 | Avg FiC Loss: 2.4975 | Avg CE Loss: 0.1768 | Model Sparsity: 0.4734
Retraining Epoch [1/10]: Avg Total Loss: 7.3188 | Avg PrC Loss: 3.1692 | Avg SnC Loss: 1.9240 | Avg FiC Loss: 2.1670 | Avg CE Loss: 0.0586 | Model Sparsity: 0.4734
Retraining Epoch [2/10]: Avg Total Loss: 7.2434 | Avg PrC Loss: 3.1579 | Avg SnC Loss: 1.9135 | Avg FiC Loss: 2.1255 | Avg CE Loss: 0.0464 | Model Sparsity: 0.4734
Retraining Epoch [3/10]: Avg Total Loss: 7.2208 | Avg PrC Loss: 3.1545 | Avg SnC Loss: 1.9152 | Avg FiC Loss: 2.1093 | Avg CE Loss: 0.0417 | Model Sparsity: 0.4734
Retraining Epoch [4/10]: Avg Total Loss: 7.1959 | Avg PrC Loss: 3.1490 | Avg SnC Loss: 1.9133 | Avg FiC Loss: 2.0961 | Avg CE Loss: 0.0374 | Model Sparsity: 0.4734
Retraining Epoch [5/10]: Avg Total Loss: 7.1831 | Avg PrC Loss: 3.1471 | Avg SnC Loss: 1.9142 | Avg FiC Loss: 2.0871 | Avg CE Loss: 0.0347 | Model Sparsity: 0.4734
Retraining Epoch [6/10]: Avg Total Loss: 7.1732 | Avg PrC Loss: 3.1439 | Avg SnC Loss: 1.9150 | Avg FiC Loss: 2.0818 | Avg CE Loss: 0.0325 | Model Sparsity: 0.4734
Retraining Epoch [7/10]: Avg Total Loss: 7.1650 | Avg PrC Loss: 3.1417 | Avg SnC Loss: 1.9154 | Avg FiC Loss: 2.0768 | Avg CE Loss: 0.0311 | Model Sparsity: 0.4734
Retraining Epoch [8/10]: Avg Total Loss: 7.1563 | Avg PrC Loss: 3.1401 | Avg SnC Loss: 1.9151 | Avg FiC Loss: 2.0716 | Avg CE Loss: 0.0296 | Model Sparsity: 0.4734
Retraining Epoch [9/10]: Avg Total Loss: 7.1514 | Avg PrC Loss: 3.1399 | Avg SnC Loss: 1.9157 | Avg FiC Loss: 2.0678 | Avg CE Loss: 0.0280 | Model Sparsity: 0.4734
Retraining Epoch [10/10]: Avg Total Loss: 7.1489 | Avg PrC Loss: 3.1387 | Avg SnC Loss: 1.9173 | Avg FiC Loss: 2.0659 | Avg CE Loss: 0.0269 | Model Sparsity: 0.4734
Epoch [2/5]: Avg Total Loss: 8.0896 | Avg PrC Loss: 3.2139 | Avg SnC Loss: 2.2467 | Avg FiC Loss: 2.4781 | Avg CE Loss: 0.1510 | Model Sparsity: 0.7605
Retraining Epoch [1/10]: Avg Total Loss: 9.3122 | Avg PrC Loss: 3.1889 | Avg SnC Loss: 3.8920 | Avg FiC Loss: 2.1773 | Avg CE Loss: 0.0540 | Model Sparsity: 0.7605
Retraining Epoch [2/10]: Avg Total Loss: 9.2363 | Avg PrC Loss: 3.1799 | Avg SnC Loss: 3.8623 | Avg FiC Loss: 2.1480 | Avg CE Loss: 0.0460 | Model Sparsity: 0.7605
Retraining Epoch [3/10]: Avg Total Loss: 9.2042 | Avg PrC Loss: 3.1775 | Avg SnC Loss: 3.8507 | Avg FiC Loss: 2.1338 | Avg CE Loss: 0.0421 | Model Sparsity: 0.7605
Retraining Epoch [4/10]: Avg Total Loss: 9.1928 | Avg PrC Loss: 3.1756 | Avg SnC Loss: 3.8486 | Avg FiC Loss: 2.1277 | Avg CE Loss: 0.0409 | Model Sparsity: 0.7605
Retraining Epoch [5/10]: Avg Total Loss: 9.1692 | Avg PrC Loss: 3.1728 | Avg SnC Loss: 3.8399 | Avg FiC Loss: 2.1186 | Avg CE Loss: 0.0379 | Model Sparsity: 0.7605
Retraining Epoch [6/10]: Avg Total Loss: 9.1607 | Avg PrC Loss: 3.1721 | Avg SnC Loss: 3.8376 | Avg FiC Loss: 2.1143 | Avg CE Loss: 0.0368 | Model Sparsity: 0.7605
Retraining Epoch [7/10]: Avg Total Loss: 9.1571 | Avg PrC Loss: 3.1708 | Avg SnC Loss: 3.8384 | Avg FiC Loss: 2.1121 | Avg CE Loss: 0.0359 | Model Sparsity: 0.7605
Retraining Epoch [8/10]: Avg Total Loss: 9.1464 | Avg PrC Loss: 3.1694 | Avg SnC Loss: 3.8346 | Avg FiC Loss: 2.1080 | Avg CE Loss: 0.0345 | Model Sparsity: 0.7605
Retraining Epoch [9/10]: Avg Total Loss: 9.1432 | Avg PrC Loss: 3.1690 | Avg SnC Loss: 3.8340 | Avg FiC Loss: 2.1062 | Avg CE Loss: 0.0340 | Model Sparsity: 0.7605
Retraining Epoch [10/10]: Avg Total Loss: 9.1378 | Avg PrC Loss: 3.1678 | Avg SnC Loss: 3.8324 | Avg FiC Loss: 2.1039 | Avg CE Loss: 0.0337 | Model Sparsity: 0.7605
Epoch [3/5]: Avg Total Loss: 10.8366 | Avg PrC Loss: 3.2320 | Avg SnC Loss: 4.7282 | Avg FiC Loss: 2.6596 | Avg CE Loss: 0.2168 | Model Sparsity: 0.9079
Retraining Epoch [1/10]: Avg Total Loss: 11.5114 | Avg PrC Loss: 3.2201 | Avg SnC Loss: 5.9743 | Avg FiC Loss: 2.2438 | Avg CE Loss: 0.0732 | Model Sparsity: 0.9079
Retraining Epoch [2/10]: Avg Total Loss: 11.3682 | Avg PrC Loss: 3.2093 | Avg SnC Loss: 5.8932 | Avg FiC Loss: 2.2053 | Avg CE Loss: 0.0604 | Model Sparsity: 0.9079
Retraining Epoch [3/10]: Avg Total Loss: 11.3190 | Avg PrC Loss: 3.2049 | Avg SnC Loss: 5.8678 | Avg FiC Loss: 2.1904 | Avg CE Loss: 0.0559 | Model Sparsity: 0.9079
Retraining Epoch [4/10]: Avg Total Loss: 11.2922 | Avg PrC Loss: 3.2035 | Avg SnC Loss: 5.8559 | Avg FiC Loss: 2.1799 | Avg CE Loss: 0.0528 | Model Sparsity: 0.9079
Retraining Epoch [5/10]: Avg Total Loss: 11.2699 | Avg PrC Loss: 3.2002 | Avg SnC Loss: 5.8451 | Avg FiC Loss: 2.1736 | Avg CE Loss: 0.0510 | Model Sparsity: 0.9079
Retraining Epoch [6/10]: Avg Total Loss: 11.2500 | Avg PrC Loss: 3.1989 | Avg SnC Loss: 5.8352 | Avg FiC Loss: 2.1667 | Avg CE Loss: 0.0492 | Model Sparsity: 0.9079
Retraining Epoch [7/10]: Avg Total Loss: 11.2359 | Avg PrC Loss: 3.1973 | Avg SnC Loss: 5.8286 | Avg FiC Loss: 2.1620 | Avg CE Loss: 0.0480 | Model Sparsity: 0.9079
