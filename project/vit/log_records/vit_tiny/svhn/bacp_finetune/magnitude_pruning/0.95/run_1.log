Model : vit_tiny - Learning Type: svhn/bacp_finetune/magnitude_pruning/0.95
Configuration:
model_type: cv
model_name: vit_tiny
model_task: svhn
num_classes: 10
criterion: CrossEntropyLoss()
embedding_dim: 192
epochs: 50
pruning_epochs: 50
recovery_epochs: 10
batch_size: 256
learning_rate: 0.0001
learning_type: bacp_finetune
optimizer_type: adamw
prune: False
pruning_type: magnitude_pruning
target_sparsity: 0.95
sparsity_scheduler: linear
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vit_tiny/svhn/vit_tiny_svhn_magnitude_pruning_0.95_bacp_finetune.pt
finetuned_weights: /dbfs/research/vit_tiny/svhn/vit_tiny_svhn_magnitude_pruning_0.95_bacp_pruning.pt

Epoch [1/50]: Avg Loss: 0.5170 | Avg Accuracy: 95.10 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [2/50]: Avg Loss: 0.1540 | Avg Accuracy: 95.74 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [3/50]: Avg Loss: 0.1402 | Avg Accuracy: 95.73 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [4/50]: Avg Loss: 0.1345 | Avg Accuracy: 95.95 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [5/50]: Avg Loss: 0.1287 | Avg Accuracy: 95.62 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [6/50]: Avg Loss: 0.1245 | Avg Accuracy: 95.84 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [7/50]: Avg Loss: 0.1236 | Avg Accuracy: 95.88 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [8/50]: Avg Loss: 0.1192 | Avg Accuracy: 95.94 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [9/50]: Avg Loss: 0.1170 | Avg Accuracy: 95.90 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [10/50]: Avg Loss: 0.1140 | Avg Accuracy: 96.05 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [11/50]: Avg Loss: 0.1115 | Avg Accuracy: 95.98 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [12/50]: Avg Loss: 0.1090 | Avg Accuracy: 95.57 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [13/50]: Avg Loss: 0.1073 | Avg Accuracy: 95.85 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [14/50]: Avg Loss: 0.1048 | Avg Accuracy: 95.81 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [15/50]: Avg Loss: 0.1035 | Avg Accuracy: 95.97 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [16/50]: Avg Loss: 0.1027 | Avg Accuracy: 95.84 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [17/50]: Avg Loss: 0.0994 | Avg Accuracy: 95.94 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [18/50]: Avg Loss: 0.0975 | Avg Accuracy: 95.85 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [19/50]: Avg Loss: 0.0943 | Avg Accuracy: 95.75 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [20/50]: Avg Loss: 0.0945 | Avg Accuracy: 95.68 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [21/50]: Avg Loss: 0.0918 | Avg Accuracy: 95.81 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [22/50]: Avg Loss: 0.0907 | Avg Accuracy: 95.92 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [23/50]: Avg Loss: 0.0898 | Avg Accuracy: 95.66 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [24/50]: Avg Loss: 0.0880 | Avg Accuracy: 95.87 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [25/50]: Avg Loss: 0.0849 | Avg Accuracy: 95.85 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [26/50]: Avg Loss: 0.0844 | Avg Accuracy: 95.53 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [27/50]: Avg Loss: 0.0848 | Avg Accuracy: 95.80 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [28/50]: Avg Loss: 0.0825 | Avg Accuracy: 95.74 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [29/50]: Avg Loss: 0.0817 | Avg Accuracy: 95.60 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
Epoch [30/50]: Avg Loss: 0.0791 | Avg Accuracy: 95.63 | Avg Perplexity: 0.000 |Model Sparsity: 0.95
