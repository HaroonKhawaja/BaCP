Model : vit_tiny - Learning Type: svhn/bacp_finetune/magnitude_pruning/0.97
Configuration:
model_type: cv
model_name: vit_tiny
model_task: svhn
num_classes: 10
criterion: CrossEntropyLoss()
embedding_dim: 192
epochs: 50
pruning_epochs: 50
recovery_epochs: 10
batch_size: 256
learning_rate: 0.0001
learning_type: bacp_finetune
optimizer_type: adamw
prune: False
pruning_type: magnitude_pruning
target_sparsity: 0.97
sparsity_scheduler: linear
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vit_tiny/svhn/vit_tiny_svhn_magnitude_pruning_0.97_bacp_finetune.pt
finetuned_weights: /dbfs/research/vit_tiny/svhn/vit_tiny_svhn_magnitude_pruning_0.97_bacp_pruning.pt

Epoch [1/50]: Avg Loss: 0.5865 | Avg Accuracy: 94.97 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [2/50]: Avg Loss: 0.1718 | Avg Accuracy: 95.09 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [3/50]: Avg Loss: 0.1545 | Avg Accuracy: 95.34 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [4/50]: Avg Loss: 0.1478 | Avg Accuracy: 95.43 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [5/50]: Avg Loss: 0.1428 | Avg Accuracy: 95.33 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [6/50]: Avg Loss: 0.1403 | Avg Accuracy: 95.40 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [7/50]: Avg Loss: 0.1357 | Avg Accuracy: 95.37 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [8/50]: Avg Loss: 0.1348 | Avg Accuracy: 95.34 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [9/50]: Avg Loss: 0.1303 | Avg Accuracy: 95.41 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [10/50]: Avg Loss: 0.1276 | Avg Accuracy: 95.30 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [11/50]: Avg Loss: 0.1266 | Avg Accuracy: 95.42 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [12/50]: Avg Loss: 0.1238 | Avg Accuracy: 95.47 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [13/50]: Avg Loss: 0.1231 | Avg Accuracy: 95.57 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [14/50]: Avg Loss: 0.1208 | Avg Accuracy: 95.76 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [15/50]: Avg Loss: 0.1175 | Avg Accuracy: 95.50 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [16/50]: Avg Loss: 0.1174 | Avg Accuracy: 95.18 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [17/50]: Avg Loss: 0.1171 | Avg Accuracy: 95.37 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [18/50]: Avg Loss: 0.1144 | Avg Accuracy: 95.41 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [19/50]: Avg Loss: 0.1127 | Avg Accuracy: 95.33 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [20/50]: Avg Loss: 0.1105 | Avg Accuracy: 95.36 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [21/50]: Avg Loss: 0.1088 | Avg Accuracy: 95.25 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [22/50]: Avg Loss: 0.1091 | Avg Accuracy: 95.29 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [23/50]: Avg Loss: 0.1066 | Avg Accuracy: 95.42 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [24/50]: Avg Loss: 0.1044 | Avg Accuracy: 95.49 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [25/50]: Avg Loss: 0.1053 | Avg Accuracy: 95.45 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [26/50]: Avg Loss: 0.1025 | Avg Accuracy: 95.28 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [27/50]: Avg Loss: 0.1019 | Avg Accuracy: 95.41 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [28/50]: Avg Loss: 0.1009 | Avg Accuracy: 95.48 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [29/50]: Avg Loss: 0.1000 | Avg Accuracy: 95.37 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [30/50]: Avg Loss: 0.0990 | Avg Accuracy: 95.45 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [31/50]: Avg Loss: 0.0974 | Avg Accuracy: 95.49 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [32/50]: Avg Loss: 0.0982 | Avg Accuracy: 95.60 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [33/50]: Avg Loss: 0.0947 | Avg Accuracy: 95.46 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
Epoch [34/50]: Avg Loss: 0.0952 | Avg Accuracy: 95.55 | Avg Perplexity: 0.000 |Model Sparsity: 0.97
