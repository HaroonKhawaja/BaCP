Model : vitl16 - Learning Type: cifar10/pruning/magnitude_pruning/0.97
Configuration:
model_type: cv
model_name: vitl16
model_task: cifar10
num_classes: 10
criterion: CrossEntropyLoss()
embedding_dim: 1024
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 128
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.97
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vitl16/cifar10/vitl16_cifar10_magnitude_pruning_0.97_pruning.pt
finetuned_weights: /dbfs/research/vitl16/cifar10/vitl16_cifar10_baseline.pt

Epoch [1/5]: Avg Loss: 0.0298 | Avg Accuracy: 99.21 | Model Sparsity: 0.4734
Recovery epoch [1/10]: Avg Loss: 0.0164 | Avg Accuracy: 99.29 | Model Sparsity: 0.4734
Recovery epoch [2/10]: Avg Loss: 0.0146 | Avg Accuracy: 99.37 | Model Sparsity: 0.4734
Recovery epoch [3/10]: Avg Loss: 0.0111 | Avg Accuracy: 99.15 | Model Sparsity: 0.4734
Recovery epoch [4/10]: Avg Loss: 0.0098 | Avg Accuracy: 98.91 | Model Sparsity: 0.4734
Recovery epoch [5/10]: Avg Loss: 0.0133 | Avg Accuracy: 99.16 | Model Sparsity: 0.4734
Recovery epoch [6/10]: Avg Loss: 0.0078 | Avg Accuracy: 98.92 | Model Sparsity: 0.4734
Recovery epoch [7/10]: Avg Loss: 0.0114 | Avg Accuracy: 98.91 | Model Sparsity: 0.4734
Recovery epoch [8/10]: Avg Loss: 0.0100 | Avg Accuracy: 99.07 | Model Sparsity: 0.4734
Recovery epoch [9/10]: Avg Loss: 0.0112 | Avg Accuracy: 98.95 | Model Sparsity: 0.4734
Recovery epoch [10/10]: Avg Loss: 0.0100 | Avg Accuracy: 98.48 | Model Sparsity: 0.4734
Epoch [2/5]: Avg Loss: 0.0218 | Avg Accuracy: 98.60 | Model Sparsity: 0.7605
Recovery epoch [1/10]: Avg Loss: 0.0042 | Avg Accuracy: 98.45 | Model Sparsity: 0.7605
Recovery epoch [2/10]: Avg Loss: 0.0051 | Avg Accuracy: 98.68 | Model Sparsity: 0.7605
Recovery epoch [3/10]: Avg Loss: 0.0035 | Avg Accuracy: 98.68 | Model Sparsity: 0.7605
Recovery epoch [4/10]: Avg Loss: 0.0043 | Avg Accuracy: 98.72 | Model Sparsity: 0.7605
Recovery epoch [5/10]: Avg Loss: 0.0034 | Avg Accuracy: 98.64 | Model Sparsity: 0.7605
Recovery epoch [6/10]: Avg Loss: 0.0033 | Avg Accuracy: 98.41 | Model Sparsity: 0.7605
Recovery epoch [7/10]: Avg Loss: 0.0043 | Avg Accuracy: 98.52 | Model Sparsity: 0.7605
Recovery epoch [8/10]: Avg Loss: 0.0021 | Avg Accuracy: 98.83 | Model Sparsity: 0.7605
Recovery epoch [9/10]: Avg Loss: 0.0048 | Avg Accuracy: 98.41 | Model Sparsity: 0.7605
Recovery epoch [10/10]: Avg Loss: 0.0059 | Avg Accuracy: 98.53 | Model Sparsity: 0.7605
Epoch [3/5]: Avg Loss: 0.0864 | Avg Accuracy: 97.36 | Model Sparsity: 0.9079
Recovery epoch [1/10]: Avg Loss: 0.0076 | Avg Accuracy: 97.45 | Model Sparsity: 0.9079
Recovery epoch [2/10]: Avg Loss: 0.0055 | Avg Accuracy: 97.70 | Model Sparsity: 0.9079
Recovery epoch [3/10]: Avg Loss: 0.0037 | Avg Accuracy: 97.74 | Model Sparsity: 0.9079
Recovery epoch [4/10]: Avg Loss: 0.0037 | Avg Accuracy: 97.78 | Model Sparsity: 0.9079
Recovery epoch [5/10]: Avg Loss: 0.0039 | Avg Accuracy: 97.66 | Model Sparsity: 0.9079
Recovery epoch [6/10]: Avg Loss: 0.0030 | Avg Accuracy: 97.75 | Model Sparsity: 0.9079
Recovery epoch [7/10]: Avg Loss: 0.0053 | Avg Accuracy: 97.70 | Model Sparsity: 0.9079
Recovery epoch [8/10]: Avg Loss: 0.0031 | Avg Accuracy: 97.80 | Model Sparsity: 0.9079
Recovery epoch [9/10]: Avg Loss: 0.0025 | Avg Accuracy: 97.99 | Model Sparsity: 0.9079
Recovery epoch [10/10]: Avg Loss: 0.0038 | Avg Accuracy: 97.37 | Model Sparsity: 0.9079
Epoch [4/5]: Avg Loss: 0.1745 | Avg Accuracy: 94.96 | Model Sparsity: 0.9622
Recovery epoch [1/10]: Avg Loss: 0.0290 | Avg Accuracy: 95.99 | Model Sparsity: 0.9622
Recovery epoch [2/10]: Avg Loss: 0.0141 | Avg Accuracy: 95.95 | Model Sparsity: 0.9622
Recovery epoch [3/10]: Avg Loss: 0.0081 | Avg Accuracy: 96.32 | Model Sparsity: 0.9622
Recovery epoch [4/10]: Avg Loss: 0.0055 | Avg Accuracy: 96.03 | Model Sparsity: 0.9622
Recovery epoch [5/10]: Avg Loss: 0.0049 | Avg Accuracy: 96.38 | Model Sparsity: 0.9622
Recovery epoch [6/10]: Avg Loss: 0.0068 | Avg Accuracy: 95.82 | Model Sparsity: 0.9622
Recovery epoch [7/10]: Avg Loss: 0.0061 | Avg Accuracy: 96.30 | Model Sparsity: 0.9622
Recovery epoch [8/10]: Avg Loss: 0.0055 | Avg Accuracy: 96.74 | Model Sparsity: 0.9622
Recovery epoch [9/10]: Avg Loss: 0.0048 | Avg Accuracy: 96.20 | Model Sparsity: 0.9622
Recovery epoch [10/10]: Avg Loss: 0.0064 | Avg Accuracy: 96.54 | Model Sparsity: 0.9622
Epoch [5/5]: Avg Loss: 0.0553 | Avg Accuracy: 95.35 | Model Sparsity: 0.97
Recovery epoch [1/10]: Avg Loss: 0.0086 | Avg Accuracy: 96.35 | Model Sparsity: 0.97
Recovery epoch [2/10]: Avg Loss: 0.0058 | Avg Accuracy: 95.78 | Model Sparsity: 0.97
Recovery epoch [3/10]: Avg Loss: 0.0050 | Avg Accuracy: 96.27 | Model Sparsity: 0.97
Recovery epoch [4/10]: Avg Loss: 0.0034 | Avg Accuracy: 96.75 | Model Sparsity: 0.97
Recovery epoch [5/10]: Avg Loss: 0.0061 | Avg Accuracy: 96.27 | Model Sparsity: 0.97
Recovery epoch [6/10]: Avg Loss: 0.0027 | Avg Accuracy: 96.34 | Model Sparsity: 0.97
Recovery epoch [7/10]: Avg Loss: 0.0030 | Avg Accuracy: 96.23 | Model Sparsity: 0.97
Recovery epoch [8/10]: Avg Loss: 0.0027 | Avg Accuracy: 96.35 | Model Sparsity: 0.97
Recovery epoch [9/10]: Avg Loss: 0.0032 | Avg Accuracy: 96.24 | Model Sparsity: 0.97
Recovery epoch [10/10]: Avg Loss: 0.0033 | Avg Accuracy: 96.48 | Model Sparsity: 0.97
