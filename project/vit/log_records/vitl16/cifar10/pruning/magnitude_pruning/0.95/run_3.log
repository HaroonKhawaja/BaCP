Model : vitl16 - Learning Type: cifar10/pruning/magnitude_pruning/0.95
Configuration:
model_type: cv
model_name: vitl16
model_task: cifar10
num_classes: 10
criterion: CrossEntropyLoss()
embedding_dim: 1024
epochs: 5
pruning_epochs: 5
recovery_epochs: 10
batch_size: 128
learning_rate: 5e-05
learning_type: pruning
optimizer_type: adamw
prune: True
pruning_type: magnitude_pruning
target_sparsity: 0.95
sparsity_scheduler: cubic
enable_mixed_precision: True
device: cuda
save_path: /dbfs/research/vitl16/cifar10/vitl16_cifar10_magnitude_pruning_0.95_pruning.pt
finetuned_weights: /dbfs/research/vitl16/cifar10/vitl16_cifar10_baseline.pt

Epoch [1/5]: Avg Loss: 0.0286 | Avg Accuracy: 99.33 | Model Sparsity: 0.4636
Recovery epoch [1/10]: Avg Loss: 0.0175 | Avg Accuracy: 99.25 | Model Sparsity: 0.4636
Recovery epoch [2/10]: Avg Loss: 0.0162 | Avg Accuracy: 99.22 | Model Sparsity: 0.4636
Recovery epoch [3/10]: Avg Loss: 0.0102 | Avg Accuracy: 98.94 | Model Sparsity: 0.4636
Recovery epoch [4/10]: Avg Loss: 0.0116 | Avg Accuracy: 98.99 | Model Sparsity: 0.4636
Recovery epoch [5/10]: Avg Loss: 0.0110 | Avg Accuracy: 99.10 | Model Sparsity: 0.4636
Recovery epoch [6/10]: Avg Loss: 0.0098 | Avg Accuracy: 98.95 | Model Sparsity: 0.4636
Recovery epoch [7/10]: Avg Loss: 0.0120 | Avg Accuracy: 98.64 | Model Sparsity: 0.4636
Recovery epoch [8/10]: Avg Loss: 0.0122 | Avg Accuracy: 98.68 | Model Sparsity: 0.4636
Recovery epoch [9/10]: Avg Loss: 0.0072 | Avg Accuracy: 99.10 | Model Sparsity: 0.4636
Recovery epoch [10/10]: Avg Loss: 0.0098 | Avg Accuracy: 98.92 | Model Sparsity: 0.4636
Epoch [2/5]: Avg Loss: 0.0165 | Avg Accuracy: 98.50 | Model Sparsity: 0.7448
Recovery epoch [1/10]: Avg Loss: 0.0062 | Avg Accuracy: 98.64 | Model Sparsity: 0.7448
Recovery epoch [2/10]: Avg Loss: 0.0037 | Avg Accuracy: 98.25 | Model Sparsity: 0.7448
Recovery epoch [3/10]: Avg Loss: 0.0044 | Avg Accuracy: 98.05 | Model Sparsity: 0.7448
Recovery epoch [4/10]: Avg Loss: 0.0053 | Avg Accuracy: 98.50 | Model Sparsity: 0.7448
Recovery epoch [5/10]: Avg Loss: 0.0036 | Avg Accuracy: 98.68 | Model Sparsity: 0.7448
Recovery epoch [6/10]: Avg Loss: 0.0027 | Avg Accuracy: 98.52 | Model Sparsity: 0.7448
Recovery epoch [7/10]: Avg Loss: 0.0037 | Avg Accuracy: 98.41 | Model Sparsity: 0.7448
Recovery epoch [8/10]: Avg Loss: 0.0070 | Avg Accuracy: 98.64 | Model Sparsity: 0.7448
Recovery epoch [9/10]: Avg Loss: 0.0042 | Avg Accuracy: 98.24 | Model Sparsity: 0.7448
Recovery epoch [10/10]: Avg Loss: 0.0029 | Avg Accuracy: 98.75 | Model Sparsity: 0.7448
Epoch [3/5]: Avg Loss: 0.0549 | Avg Accuracy: 97.25 | Model Sparsity: 0.8892
Recovery epoch [1/10]: Avg Loss: 0.0085 | Avg Accuracy: 97.94 | Model Sparsity: 0.8892
Recovery epoch [2/10]: Avg Loss: 0.0038 | Avg Accuracy: 97.93 | Model Sparsity: 0.8892
Recovery epoch [3/10]: Avg Loss: 0.0035 | Avg Accuracy: 98.01 | Model Sparsity: 0.8892
Recovery epoch [4/10]: Avg Loss: 0.0039 | Avg Accuracy: 97.90 | Model Sparsity: 0.8892
Recovery epoch [5/10]: Avg Loss: 0.0027 | Avg Accuracy: 98.03 | Model Sparsity: 0.8892
Recovery epoch [6/10]: Avg Loss: 0.0044 | Avg Accuracy: 98.17 | Model Sparsity: 0.8892
Recovery epoch [7/10]: Avg Loss: 0.0033 | Avg Accuracy: 97.94 | Model Sparsity: 0.8892
Recovery epoch [8/10]: Avg Loss: 0.0021 | Avg Accuracy: 97.67 | Model Sparsity: 0.8892
Recovery epoch [9/10]: Avg Loss: 0.0030 | Avg Accuracy: 97.98 | Model Sparsity: 0.8892
Recovery epoch [10/10]: Avg Loss: 0.0025 | Avg Accuracy: 97.99 | Model Sparsity: 0.8892
Epoch [4/5]: Avg Loss: 0.0969 | Avg Accuracy: 96.63 | Model Sparsity: 0.9424
Recovery epoch [1/10]: Avg Loss: 0.0119 | Avg Accuracy: 96.67 | Model Sparsity: 0.9424
Recovery epoch [2/10]: Avg Loss: 0.0060 | Avg Accuracy: 97.08 | Model Sparsity: 0.9424
Recovery epoch [3/10]: Avg Loss: 0.0047 | Avg Accuracy: 96.57 | Model Sparsity: 0.9424
Recovery epoch [4/10]: Avg Loss: 0.0032 | Avg Accuracy: 96.79 | Model Sparsity: 0.9424
Recovery epoch [5/10]: Avg Loss: 0.0038 | Avg Accuracy: 97.25 | Model Sparsity: 0.9424
Recovery epoch [6/10]: Avg Loss: 0.0039 | Avg Accuracy: 96.85 | Model Sparsity: 0.9424
Recovery epoch [7/10]: Avg Loss: 0.0042 | Avg Accuracy: 97.29 | Model Sparsity: 0.9424
Recovery epoch [8/10]: Avg Loss: 0.0013 | Avg Accuracy: 97.72 | Model Sparsity: 0.9424
Recovery epoch [9/10]: Avg Loss: 0.0013 | Avg Accuracy: 97.17 | Model Sparsity: 0.9424
Recovery epoch [10/10]: Avg Loss: 0.0044 | Avg Accuracy: 96.89 | Model Sparsity: 0.9424
Epoch [5/5]: Avg Loss: 0.0248 | Avg Accuracy: 97.02 | Model Sparsity: 0.95
Recovery epoch [1/10]: Avg Loss: 0.0045 | Avg Accuracy: 97.01 | Model Sparsity: 0.95
Recovery epoch [2/10]: Avg Loss: 0.0017 | Avg Accuracy: 96.98 | Model Sparsity: 0.95
Recovery epoch [3/10]: Avg Loss: 0.0032 | Avg Accuracy: 97.01 | Model Sparsity: 0.95
Recovery epoch [4/10]: Avg Loss: 0.0024 | Avg Accuracy: 97.05 | Model Sparsity: 0.95
Recovery epoch [5/10]: Avg Loss: 0.0023 | Avg Accuracy: 97.21 | Model Sparsity: 0.95
Recovery epoch [6/10]: Avg Loss: 0.0021 | Avg Accuracy: 97.32 | Model Sparsity: 0.95
Recovery epoch [7/10]: Avg Loss: 0.0013 | Avg Accuracy: 97.36 | Model Sparsity: 0.95
Recovery epoch [8/10]: Avg Loss: 0.0019 | Avg Accuracy: 96.69 | Model Sparsity: 0.95
Recovery epoch [9/10]: Avg Loss: 0.0041 | Avg Accuracy: 97.31 | Model Sparsity: 0.95
Recovery epoch [10/10]: Avg Loss: 0.0012 | Avg Accuracy: 96.78 | Model Sparsity: 0.95
