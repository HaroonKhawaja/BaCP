{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b6c9a6e-1b60-4ee4-8763-115be61961c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d371d65-5585-4197-910a-fe63d9770305",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ac9bfdc-d83e-4035-b2f3-96535477ab8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from contrastive_learning import ContrastiveLearner\n",
    "from models import EncoderProjectionNetwork, ClassificationNetwork\n",
    "from datasets_class import CreateDatasets\n",
    "from supervised_learning import train, test\n",
    "from unstructured_pruning import MagnitudePrune, MovementPrune, LocalMagnitudePrune, LocalMovementPrune\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from logger import Logger\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d24cf944-fd6f-4c6f-a895-920d954f2f10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 24\n",
    "SIZE = 224\n",
    "\n",
    "TRAINING_EPOCHS = 3\n",
    "BIG_TRAINING_EPOCHS = 6\n",
    "FINETUNING_EPOCHS = 5\n",
    "CIFAR10_CLASSES = 10\n",
    "PRUNING_EPOCHS = 5\n",
    "\n",
    "TARGET_SPARSITY = 0.95\n",
    "\n",
    "TEMPERATURE = 0.07\n",
    "BASE_TEMPERATURE = 0.07\n",
    "\n",
    "LR_VITB16 = 0.00001\n",
    "LR_VITL16 = 0.000005\n",
    "\n",
    "WEIGHT_DECAY = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe9fe2eb-fb21-44ab-b395-e09b4b4e551b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datasets = CreateDatasets('./data')\n",
    "\n",
    "# Data for supervised learning\n",
    "trainset_c10_cls_fn, testset_c10_cls_fn = datasets.get_dataset_fn('supervised', 'cifar10', SIZE)\n",
    "trainset_c10_cls, testset_c10_cls = trainset_c10_cls_fn(), testset_c10_cls_fn()\n",
    "\n",
    "trainloader_c10_cls = DataLoader(trainset_c10_cls, BATCH_SIZE, shuffle=True)\n",
    "testloader_c10_cls = DataLoader(testset_c10_cls, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 2-view augmented data for supervised contrastive learning+\n",
    "trainset_c10_cl_fn, testset_c10_cl_fn = datasets.get_dataset_fn('supcon', 'cifar10', SIZE)\n",
    "trainset_c10_cl, testset_c10_cl = trainset_c10_cl_fn(), testset_c10_cl_fn()\n",
    "\n",
    "trainloader_c10_cl = DataLoader(trainset_c10_cl, BATCH_SIZE, shuffle=True)\n",
    "testloader_c10_cl = DataLoader(testset_c10_cl, BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7a72052-1178-426e-b2b5-a0547b148d04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Baseline Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df5837fb-fc09-4a1a-b9ca-0a629169cdc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ViT-Base-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "313f6508-8008-4e4f-9703-e86210a82054",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating a classification net for downstream task\n",
    "model_name = 'vitb16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY,\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt'\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           TRAINING_EPOCHS,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    \"lambda_reg\":       0,\n",
    "    'recover_epochs':   0,\n",
    "    'pruning_type':     \"\",\n",
    "}\n",
    "\n",
    "# Set True if trained\n",
    "is_trained = True\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config)\n",
    "    graph_losses_n_accs(losses, train_accuracies, test_accuracies)\n",
    "    \n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6312afa7-4c62-4adc-aa47-310d76f852e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ViT-Large-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a2833c1-d39b-446a-ab65-36078972c527",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating a classification net for downstream task\n",
    "model_name = 'vitl16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITL16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY,\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt'\n",
    "load_weights(cls_model, save_path)\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           TRAINING_EPOCHS,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    \"lambda_reg\":       0,\n",
    "    'recover_epochs':   0,\n",
    "}\n",
    "\n",
    "# Set True if trained\n",
    "is_trained = True\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config)\n",
    "    graph_losses_n_accs(losses, train_accuracies, test_accuracies)\n",
    "    \n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b268a59-36cf-4cf1-8599-c8971fccd831",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Pruning Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9efd17d-5431-4179-9e93-a80b84c4a2c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ViT-Base-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef0ec44a-084c-4f3b-b2f4-dbe81b492c5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Magnitude Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15e328b8-3d1a-4c81-acc7-14deacc68c5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating classification model\n",
    "model_name = 'vitb16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_sup_magp_c10.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "# pruner = MagnitudePrune(PRUNING_EPOCHS, TARGET_SPARSITY_LOW)\n",
    "# pruner = LocalMagnitudePrune(1, 0.965)\n",
    "pruner = LocalMovementPrune(1, 0.965, target_layer='self_attention')\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'lambda_reg':       0,\n",
    "    'recover_epochs':   5,\n",
    "    'pruning_type':    'local_magnitude_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9740fbb3-28e1-4cf3-b433-e39bdf5a70b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for name, param in cls_model.named_parameters():\n",
    "    # if param.dim() > 1:\n",
    "    print(name, (1-(torch.count_nonzero(param).item() / param.numel())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a03bfb02-1d9b-46e3-bec1-963252ba1c15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Movement Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06f30ea7-a11d-4dc9-8577-4bb86e6e519f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating classification model\n",
    "model_name = 'vitb16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_sup_mvmp_c10.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "# pruner = MovementPrune(PRUNING_EPOCHS, TARGET_SPARSITY_LOW)\n",
    "pruner = LocalMovementPrune(PRUNING_EPOCHS, 0.965)\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           PRUNING_EPOCHS,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'lambda_reg':       0,\n",
    "    'recover_epochs':   1,\n",
    "    'pruning_type':    'local_movement_prune',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d89d1e3-89ba-46c7-a3a3-2a1321929a00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ViT-Large-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb6fddac-007d-4668-a665-2208bf081720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Magnitude Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "167b148d-df75-49a2-a221-9e413505fa68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating classification model\n",
    "model_name = 'vitl16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITL16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_sup_magp_c10.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "# pruner = MagnitudePrune(PRUNING_EPOCHS, TARGET_SPARSITY_LOW)\n",
    "pruner = LocalMagnitudePrune(PRUNING_EPOCHS, 0.965)\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           PRUNING_EPOCHS,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'lambda_reg':       0,\n",
    "    'recover_epochs':   1,\n",
    "    'pruning_type':    'local_magnitude_prune',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2d40b26-0c01-4f22-8efe-8be65e07b16a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### MovementPrune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14f0cb86-889f-4952-85af-3c1d9187a5fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating classification model\n",
    "model_name = 'vitl16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITL16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_sup_mvmp_c10.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "# pruner = MovementPrune(PRUNING_EPOCHS, TARGET_SPARSITY_LOW)\n",
    "pruner = LocalMovementPrune(PRUNING_EPOCHS, 0.965)\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           PRUNING_EPOCHS,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'lambda_reg':       0,\n",
    "    'recover_epochs':   1,\n",
    "    'pruning_type':    'local_movement_prune',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88d4dbfe-4b72-4b17-81ea-64f6299f9531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# SupCon Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcaeb8d5-4e9e-4231-8876-9f1714681eb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing projection model for supervised-contrastive learning\n",
    "model_name = 'vitb16'    \n",
    "projection_model = EncoderProjectionNetwork(model_name, 128)\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "# optimizer_type = 'adam'\n",
    "# optimizer_cfg = {\n",
    "#     'model':        projection_model,\n",
    "#     'lr':           LR_VITB16,\n",
    "#     'momentum':     MOMENTUM,\n",
    "#     'weight_decay': WEIGHT_DECAY,\n",
    "# }\n",
    "\n",
    "optimizer_type = 'sgd'\n",
    "optimizer_cfg = {\n",
    "    'model':        projection_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_supcon_c10.pt'\n",
    "logger = Logger(model_name, learning_type='supcon')\n",
    "\n",
    "config = {\n",
    "    'n_views':          2,\n",
    "    'optimizer':        optimizer,\n",
    "    'epochs':           TRAINING_EPOCHS,\n",
    "    'scheduler':        scheduler,\n",
    "    'batch_size':       BATCH_SIZE,\n",
    "    'temperature':      TEMP,\n",
    "    'base_temperature': BASE_TEMP,\n",
    "    'loss_type':        'supcon',\n",
    "}\n",
    "\n",
    "supcon_learner = ContrastiveLearner(projection_model, config)\n",
    "\n",
    "# Set if trained\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    supcon_learner.train(trainloader_c10_cl, save_path, logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53ab81f9-86ff-461b-970e-9cad6af58508",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating a classification net for downstream task\n",
    "model_name = 'vitb16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "cls_model.to(get_device())\n",
    "\n",
    "# Loading the projection models backbone weights into the new classification net\n",
    "load_projection_model_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_supcon_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt'\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           LINEAR_EPOCHS,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    \"lambda_reg\":       5e-4,\n",
    "    'recover_epochs':   0,\n",
    "    'pruning_type':     \"\",\n",
    "    'stop_epochs':     25,\n",
    "}\n",
    "\n",
    "# Set True if trained\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config)\n",
    "    graph_losses_n_accs(losses, train_accuracies, test_accuracies)\n",
    "    \n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe4faaaa-512f-4045-b477-d3732b013302",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# BaCP Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88b57771-09ab-4b14-b781-60e1c7efb58a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ViT-Base-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18d34aab-2fb3-4fd4-9a43-cfa4b78c3437",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Magnitude Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24e97869-3f38-494e-a961-61bd9f6a19a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from bacp import create_models_for_cap\n",
    "from bacp import BaCPLearner\n",
    "# Creating projection models for BaCP framework\n",
    "model_name = 'vitb16'\n",
    "                                  \n",
    "# Projection networks\n",
    "finetuned_weights = f'/dbfs/{model_name}_weights/{model_name}_supcon_c10.pt'\n",
    "pre_trained_model, current_model, finetuned_model = create_models_for_cap(model_name, finetuned_weights)\n",
    "\n",
    "# Fine-tuned classification network\n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "print(f\"Current model sparsity: {get_model_sparsity(current_model)}\")\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'sgd'\n",
    "optimizer_cfg = {\n",
    "    'model':        current_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_magp_c10'\n",
    "logger = Logger(model_name, learning_type='bacp')\n",
    "\n",
    "# Initializing pruner\n",
    "# pruner = MagnitudePrune(5, TARGET_SPARSITY_LOW)\n",
    "pruner = LocalMagnitudePrune(5, 0.965)\n",
    "\n",
    "config = {\n",
    "    'model_name':       model_name,\n",
    "    'n_views':          2,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,               \n",
    "    'criterion':        criterion,\n",
    "    'temperature':      TEMP,\n",
    "    'base_temperature': BASE_TEMP,\n",
    "    'target_sparsity':  TARGET_SPARSITY_MID,   \n",
    "    'logger':           logger,\n",
    "    'epochs':           BACP_EPOCHS,         \n",
    "    'batch_size':       BATCH_SIZE,     \n",
    "    'num_classes':      CIFAR10_CLASSES,    # Change this based on dataloader\n",
    "    'lambdas':          LAMBDAS,            # None lambas => lambdas become learnable parameters\n",
    "    'save_path':        save_path,\n",
    "    'pruner':           pruner,\n",
    "}\n",
    "\n",
    "cap_learner = BaCPLearner(current_model, pre_trained_model, finetuned_model, cls_model, config)\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    cap_learner.cap_train(trainloader_c10_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10b36144-ce3c-4e9a-9997-fee5881091c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating classification model with unfrozen parameters\n",
    "model_name = 'vitb16'\n",
    "cls_model = cap_learner.create_classification_net(False)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(cls_model)}\")\n",
    "\n",
    "# Generate masks from model\n",
    "cap_learner.generate_mask_from_model()\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_magp_cls_c10.pt'\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = cap_learner.get_pruner()\n",
    "pruning_type = 'magnitude_pruning'\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           LINEAR_EPOCHS,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'lambda_reg':       0,\n",
    "    'recover_epochs':   0,\n",
    "    'pruning_type':     pruning_type,\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner,\n",
    "                                                      True)\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44413729-5da7-46cc-bf9b-a69d75cb411d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Movement Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74225026-8856-457c-a276-b7d5751e8314",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from bacp import create_models_for_cap\n",
    "from bacp import BaCPLearner\n",
    "# Creating projection models for BaCP framework\n",
    "model_name = 'vitb16'\n",
    "                                  \n",
    "# Projection networks\n",
    "finetuned_weights = f'/dbfs/{model_name}_weights/{model_name}_supcon_c10.pt'\n",
    "pre_trained_model, current_model, finetuned_model = create_models_for_cap(model_name, finetuned_weights)\n",
    "\n",
    "# Fine-tuned classification network\n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "print(f\"Current model sparsity: {get_model_sparsity(current_model)}\")\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'sgd'\n",
    "optimizer_cfg = {\n",
    "    'model':        current_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_mvmp_c10'\n",
    "logger = Logger(model_name, learning_type='bacp')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = MovementPrune(5, TARGET_SPARSITY_LOW)\n",
    "\n",
    "config = {\n",
    "    'model_name':       model_name,\n",
    "    'n_views':          2,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,               \n",
    "    'criterion':        criterion,\n",
    "    'temperature':      TEMP,\n",
    "    'base_temperature': BASE_TEMP,\n",
    "    'target_sparsity':  TARGET_SPARSITY_MID,   \n",
    "    'logger':           logger,\n",
    "    'epochs':           BACP_EPOCHS,         \n",
    "    'batch_size':       BATCH_SIZE,     \n",
    "    'num_classes':      CIFAR10_CLASSES,    # Change this based on dataloader\n",
    "    'lambdas':          LAMBDAS,            # None lambas => lambdas become learnable parameters\n",
    "    'save_path':        save_path,\n",
    "    'pruner':           pruner,\n",
    "}\n",
    "\n",
    "cap_learner = BaCPLearner(current_model, pre_trained_model, finetuned_model, cls_model, config)\n",
    "\n",
    "# Set False to train\n",
    "is_trained = True\n",
    "if not is_trained:\n",
    "    cap_learner.cap_train(trainloader_c10_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "588367e9-2b4a-4b0b-a341-6d7e40e634c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating classification model with unfrozen parameters\n",
    "model_name = 'vitb16'\n",
    "cls_model = cap_learner.create_classification_net(False)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(cls_model)}\")\n",
    "\n",
    "# Generate masks from model\n",
    "cap_learner.generate_mask_from_model()\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_mvmp_cls_c10_v2.pt'\n",
    "# load_weights(cls_model, save_path)\n",
    "\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = cap_learner.get_pruner()\n",
    "pruning_type = 'movement_pruning'\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           LINEAR_EPOCHS,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'lambda_reg':       0,\n",
    "    'recover_epochs':   0,\n",
    "    'pruning_type':     pruning_type,\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner,\n",
    "                                                      True)\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "vit_notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
