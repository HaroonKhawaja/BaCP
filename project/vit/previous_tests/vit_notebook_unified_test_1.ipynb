{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b6c9a6e-1b60-4ee4-8763-115be61961c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d371d65-5585-4197-910a-fe63d9770305",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ac9bfdc-d83e-4035-b2f3-96535477ab8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# importing modules from main directory\n",
    "from contrastive_learning import ContrastiveLearner\n",
    "from models import EncoderProjectionNetwork, ClassificationNetwork\n",
    "from datasets_class import CreateDatasets\n",
    "from supervised_learning import train, test\n",
    "from unstructured_pruning import MagnitudePrune, MovementPrune, LocalMagnitudePrune, LocalMovementPrune\n",
    "from torch.utils.data import DataLoader\n",
    "from bacp import BaCPLearner, create_models_for_bacp\n",
    "from logger import Logger\n",
    "from utils import *\n",
    "from constants import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d24cf944-fd6f-4c6f-a895-920d954f2f10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 512  # For baseline pruning\n",
    "BATCH_SIZE = 256    # For BaCP \n",
    "NUM_WORKERS = 24\n",
    "SIZE = 224\n",
    "BATCH_SIZE_VITL16 = 128\n",
    "BATCH_SIZE_VIBL16 = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe9fe2eb-fb21-44ab-b395-e09b4b4e551b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datasets = CreateDatasets('./data')\n",
    "\n",
    "# Data for supervised learning\n",
    "trainset_c10_cls_fn, testset_c10_cls_fn = datasets.get_dataset_fn('supervised', 'cifar10', SIZE)\n",
    "trainset_c10_cls, testset_c10_cls = trainset_c10_cls_fn(), testset_c10_cls_fn()\n",
    "\n",
    "trainloader_c10_cls = DataLoader(trainset_c10_cls, BATCH_SIZE_VITL16, shuffle=True)\n",
    "testloader_c10_cls = DataLoader(testset_c10_cls, BATCH_SIZE_VITL16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7a72052-1178-426e-b2b5-a0547b148d04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Baseline Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df5837fb-fc09-4a1a-b9ca-0a629169cdc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ViT-Base-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "313f6508-8008-4e4f-9703-e86210a82054",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating a classification net for downstream task\n",
    "model_name = 'vitb16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY,\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt'\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           EPOCHS_VITB16,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "}\n",
    "\n",
    "# Set True if trained\n",
    "is_trained = True\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config)\n",
    "    graph_losses_n_accs(losses, train_accuracies, test_accuracies)\n",
    "    \n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6312afa7-4c62-4adc-aa47-310d76f852e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ViT-Large-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a2833c1-d39b-446a-ab65-36078972c527",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating a classification net for downstream task\n",
    "model_name = 'vitl16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITL16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY,\n",
    "}\n",
    "optimizer = set_optimizer('adam', optimizer_cfg)\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt'\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        None,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           EPOCHS_VITL16,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           Logger(model_name, learning_type='cls'),\n",
    "    \"lambda_reg\":       0,\n",
    "    'recover_epochs':   0,\n",
    "    'pruning_type':     \"\",\n",
    "}\n",
    "\n",
    "# Set True if trained\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model, config)\n",
    "    graph_losses_n_accs(losses, train_accuracies, test_accuracies)\n",
    "\n",
    "\n",
    "# Evaluating model\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b268a59-36cf-4cf1-8599-c8971fccd831",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Pruning Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d2a5144-c809-4602-b830-f4340d2f09ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sparsity: 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9efd17d-5431-4179-9e93-a80b84c4a2c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ViT-Base-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef0ec44a-084c-4f3b-b2f4-dbe81b492c5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Magnitude Pruning - Movement Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15e328b8-3d1a-4c81-acc7-14deacc68c5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "########## MAGNITUDE PRUNING ##########\n",
    "#######################################\n",
    "\n",
    "# Creating classification model\n",
    "model_name = 'vitb16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_magp_095.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "pruner = LocalMagnitudePrune(1, TARGET_SPARSITY_LOW)\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   50,\n",
    "    'pruning_type':    'magnitude_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06f30ea7-a11d-4dc9-8577-4bb86e6e519f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "########## MOVEMENT PRUNING ##########\n",
    "######################################\n",
    "\n",
    "# Creating classification model\n",
    "model_name = 'vitb16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_mvmp_095.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "# pruner = MovementPrune(1, TARGET_SPARSITY_LOW)\n",
    "pruner = LocalMovementPrune(1, TARGET_SPARSITY_LOW)\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   50,\n",
    "    'pruning_type':    'movement_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d89d1e3-89ba-46c7-a3a3-2a1321929a00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ViT-Large-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb6fddac-007d-4668-a665-2208bf081720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Magnitude Prunining - Movement Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "167b148d-df75-49a2-a221-9e413505fa68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "########## MAGNITUDE PRUNING ##########\n",
    "#######################################\n",
    "\n",
    "# Creating classification model\n",
    "model_name = 'vitl16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITL16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer('adam', optimizer_cfg)\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_magp_095.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "pruner = LocalMagnitudePrune(1, TARGET_SPARSITY_LOW)\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        None,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE_VITL16,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   50,\n",
    "    'pruning_type':    'local_magnitude_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14f0cb86-889f-4952-85af-3c1d9187a5fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "########## MOVEMENT PRUNING ##########\n",
    "######################################\n",
    "\n",
    "# Creating classification model\n",
    "model_name = 'vitl16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITL16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_mvmp_095.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "pruner = LocalMovementPrune(1, TARGET_SPARSITY_LOW)\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE_VITL16,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   50,\n",
    "    'pruning_type':    'local_movement_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10d9222a-c7a1-496f-a5b3-c1d436a17946",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sparsity: 0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c68dfa7-0e66-455f-b1b2-d33335091ef2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ViT-B-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed47726f-d2a1-4132-8583-7c3fe9e61489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Magnitude Pruning - Movement Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c1b09a3-7221-45cf-8eab-db8ddc5ff0e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "########## MAGNITUDE PRUNING ##########\n",
    "#######################################\n",
    "\n",
    "# Creating classification model\n",
    "model_name = 'vitb16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_magp_097.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "pruner = LocalMagnitudePrune(1, TARGET_SPARSITY_MID)\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   50,\n",
    "    'pruning_type':    'local_magnitude_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b171dba-a64c-4ae8-8e7c-15e39ca97fe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "########## MOVEMENT PRUNING ##########\n",
    "######################################\n",
    "\n",
    "# Creating classification model\n",
    "model_name = 'vitb16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_mvmp_097.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "pruner = LocalMovementPrune(1, TARGET_SPARSITY_MID)\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   50,\n",
    "    'pruning_type':    'local_movement_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a6315bf-ba73-4a97-8bf2-6797b081c9d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ViT-L-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb8c532e-bcce-45f3-b1c9-e2f450f82810",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Magnitude Pruning - Movement Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dbe1bdf-1dd9-4423-98fa-b172f3e2f5a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "########## MAGNITUDE PRUNING ##########\n",
    "#######################################\n",
    "\n",
    "# Creating classification model\n",
    "model_name = 'vitl16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITL16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_magp_097.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "pruner = LocalMagnitudePrune(1, TARGET_SPARSITY_MID)\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE_VITL16,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   23,\n",
    "    'pruning_type':    'local_magnitude_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ec91331-3dc3-41dc-98cf-1c7a3b75332b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "########## MOVEMENT PRUNING ##########\n",
    "######################################\n",
    "\n",
    "# Creating classification model\n",
    "model_name = 'vitl16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITL16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_mvmp_097.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "pruner = LocalMovementPrune(1, TARGET_SPARSITY_MID)\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE_VITL16,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   50,\n",
    "    'pruning_type':    'local_movement_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ef1bfcf-fc9c-4932-9c62-1572112e1b2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sparsity: 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb46b8b3-5375-44ad-af62-083b65a47f7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ViT-B-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a56d216-9988-43ff-aa3f-ced4baa5c87a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Magnitude Pruning - Movement Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c55b19a-e064-4a5a-887a-7be551fda72f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "########## MAGNITUDE PRUNING ##########\n",
    "#######################################\n",
    "\n",
    "# Creating classification model\n",
    "model_name = 'vitb16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_magp_099.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "pruner = LocalMagnitudePrune(1, TARGET_SPARSITY_HIGH)\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   50,\n",
    "    'pruning_type':    'local_magnitude_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "600c86ca-141c-4630-8d69-043d54780231",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "########## MOVEMENT PRUNING ##########\n",
    "######################################\n",
    "\n",
    "# Creating classification model\n",
    "model_name = 'vitb16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITB16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_mvmp_099.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "pruner = LocalMovementPrune(1, TARGET_SPARSITY_HIGH)\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   50,\n",
    "    'pruning_type':    'local_movement_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "105ce029-f4d1-4b58-bfd1-98986cad9b10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ViT-L-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42b1fa47-1519-4acd-acd2-d99b0f6b6b73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Magnitude Pruning - Movement Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65287583-ab7a-44d2-8329-f81d9ecd65b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "########## MAGNITUDE PRUNING ##########\n",
    "#######################################\n",
    "\n",
    "# Creating classification model\n",
    "model_name = 'vitl16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITL16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_magp_099.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "pruner = LocalMagnitudePrune(1, TARGET_SPARSITY_HIGH)\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE_VITL16,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   50,\n",
    "    'pruning_type':    'local_magnitude_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f6e69f2-044b-45e8-aa90-9c6d736d23bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "########## MOVEMENT PRUNING ##########\n",
    "######################################\n",
    "\n",
    "# Creating classification model\n",
    "model_name = 'vitl16'    \n",
    "cls_model = ClassificationNetwork(model_name, CIFAR10_CLASSES, False).to(get_device())\n",
    "load_weights(cls_model, f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt')\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           LR_VITL16,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_mvmp_099.pt'\n",
    "\n",
    "# Initialing pruning method\n",
    "pruner = LocalMovementPrune(1, TARGET_SPARSITY_HIGH)\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           1,\n",
    "    \"batch_size\":       BATCH_SIZE_VITL16,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   50,\n",
    "    'pruning_type':    'local_movement_pruning',\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner)\n",
    "    torch.save(cls_model.state_dict(), save_path)\n",
    "    \n",
    "    # Displaying loss-acc graph\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Sparsity of pruned model: {get_model_sparsity(cls_model):.3f}\")\n",
    "pruned_acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"Accuracy of pruned model is: {pruned_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe4faaaa-512f-4045-b477-d3732b013302",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# BaCP Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b18733fb-dcc0-46b2-b97e-90dcce621e6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sparsity: 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88b57771-09ab-4b14-b781-60e1c7efb58a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ViT-Base-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24e97869-3f38-494e-a961-61bd9f6a19a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "########## MAGNITUDE PRUNING ##########\n",
    "#######################################\n",
    "\n",
    "# Creating projection models for BaCP framework\n",
    "model_name = 'vitb16'\n",
    "                                  \n",
    "# Projection networks\n",
    "finetuned_weights = f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt'\n",
    "pre_trained_model, current_model, finetuned_model = create_models_for_cap(model_name, finetuned_weights)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(current_model)}\")\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        current_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_magp_095'\n",
    "logger = Logger(model_name, learning_type='bacp')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = LocalMagnitudePrune(1, TARGET_SPARSITY_LOW)\n",
    "\n",
    "config = {\n",
    "    'model_name':       model_name,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,               \n",
    "    'criterion':        criterion,\n",
    "    'target_sparsity':  TARGET_SPARSITY_LOW,   \n",
    "    'logger':           logger,\n",
    "    'batch_size':       BATCH_SIZE,     \n",
    "    'num_classes':      CIFAR10_CLASSES,\n",
    "    'lambdas':          [0.25, 0.25, 0.25, 0.25], \n",
    "    'save_path':        save_path,\n",
    "    'pruner':           pruner,\n",
    "    'recovery_epochs':  0,\n",
    "    'epochs':           20,\n",
    "    'pruning_epochs':   1,\n",
    "}\n",
    "\n",
    "cap_learner = BaCPLearner(current_model, pre_trained_model, finetuned_model, config)\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    cap_learner.train(trainloader_c10_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10b36144-ce3c-4e9a-9997-fee5881091c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating classification model with unfrozen parameters\n",
    "model_name = 'vitb16'\n",
    "cls_model = cap_learner.create_classification_net(False)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(cls_model)}\")\n",
    "\n",
    "# Generate masks from model\n",
    "cap_learner.generate_mask_from_model()\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_magp_095_ds.pt'\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = cap_learner.get_pruner()\n",
    "pruning_type = 'magnitude_pruning'\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           30,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   0,\n",
    "    'pruning_type':     pruning_type,\n",
    "    'stop_epochs':      5,\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner,\n",
    "                                                      True)\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(cls_model)}\")\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74225026-8856-457c-a276-b7d5751e8314",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "########## MOVEMENT PRUNING ##########\n",
    "######################################\n",
    "\n",
    "# Creating projection models for BaCP framework\n",
    "model_name = 'vitb16'\n",
    "                                  \n",
    "# Projection networks\n",
    "finetuned_weights = f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt'\n",
    "pre_trained_model, current_model, finetuned_model = create_models_for_cap(model_name, finetuned_weights)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(current_model)}\")\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        current_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_mvmp_095'\n",
    "logger = Logger(model_name, learning_type='bacp')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = LocalMovementPrune(1, TARGET_SPARSITY_LOW)\n",
    "\n",
    "config = {\n",
    "    'model_name':       model_name,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,               \n",
    "    'criterion':        criterion,\n",
    "    'target_sparsity':  TARGET_SPARSITY_LOW,   \n",
    "    'logger':           logger,\n",
    "    'batch_size':       BATCH_SIZE,     \n",
    "    'num_classes':      CIFAR10_CLASSES,\n",
    "    'lambdas':          [0.25, 0.25, 0.25, 0.25], \n",
    "    'save_path':        save_path,\n",
    "    'pruner':           pruner,\n",
    "    'recovery_epochs':  0,\n",
    "    'epochs':           20,\n",
    "    'pruning_epochs':   1,\n",
    "}\n",
    "\n",
    "cap_learner = BaCPLearner(current_model, pre_trained_model, finetuned_model, config)\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    cap_learner.train(trainloader_c10_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "588367e9-2b4a-4b0b-a341-6d7e40e634c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating classification model with unfrozen parameters\n",
    "model_name = 'vitb16'\n",
    "cls_model = cap_learner.create_classification_net(False)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(cls_model)}\")\n",
    "\n",
    "# Generate masks from model\n",
    "cap_learner.generate_mask_from_model()\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_mvmp_095_ds.pt'\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = cap_learner.get_pruner()\n",
    "pruning_type = 'movement_pruning'\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           30,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   0,\n",
    "    'pruning_type':     pruning_type,\n",
    "    'stop_epochs':      5,\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner,\n",
    "                                                      True)\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fef01280-179b-415f-b8b3-ac9253ec6484",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sparsity: 0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a8b7c43-62f9-4802-a567-b3174d66aa9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ViT-B-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "733dcf4f-299e-4fcf-97c2-606045a0d1b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "########## MAGNITUDE PRUNING ##########\n",
    "#######################################\n",
    "\n",
    "# Creating projection models for BaCP framework\n",
    "model_name = 'vitb16'\n",
    "                                  \n",
    "# Projection networks\n",
    "finetuned_weights = f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt'\n",
    "pre_trained_model, current_model, finetuned_model = create_models_for_cap(model_name, finetuned_weights)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(current_model)}\")\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        current_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_magp_097'\n",
    "logger = Logger(model_name, learning_type='bacp')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = LocalMagnitudePrune(1, TARGET_SPARSITY_MID)\n",
    "\n",
    "config = {\n",
    "    'model_name':       model_name,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,               \n",
    "    'criterion':        criterion,\n",
    "    'target_sparsity':  TARGET_SPARSITY_MID,   \n",
    "    'logger':           logger,\n",
    "    'batch_size':       BATCH_SIZE,     \n",
    "    'num_classes':      CIFAR10_CLASSES,\n",
    "    'lambdas':          [0.25, 0.25, 0.25, 0.25], \n",
    "    'save_path':        save_path,\n",
    "    'pruner':           pruner,\n",
    "    'recovery_epochs':  0,\n",
    "    'epochs':           20,\n",
    "    'pruning_epochs':   1,\n",
    "}\n",
    "\n",
    "cap_learner = BaCPLearner(current_model, pre_trained_model, finetuned_model, config)\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    cap_learner.train(trainloader_c10_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "402943ba-16ff-4b40-9c21-8b29be968b8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating classification model with unfrozen parameters\n",
    "model_name = 'vitb16'\n",
    "cls_model = cap_learner.create_classification_net(False)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(cls_model)}\")\n",
    "\n",
    "# Generate masks from model\n",
    "cap_learner.generate_mask_from_model()\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_magp_097_ds.pt'\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = cap_learner.get_pruner()\n",
    "pruning_type = 'magnitude_pruning'\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           30,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   0,\n",
    "    'pruning_type':     pruning_type,\n",
    "    'stop_epochs':      5,\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner,\n",
    "                                                      True)\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dace8483-55a0-4a9c-8c9a-b34c83bb30b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "########## MOVEMENT PRUNING ##########\n",
    "######################################\n",
    "\n",
    "# Creating projection models for BaCP framework\n",
    "model_name = 'vitb16'\n",
    "                                  \n",
    "# Projection networks\n",
    "finetuned_weights = f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt'\n",
    "pre_trained_model, current_model, finetuned_model = create_models_for_cap(model_name, finetuned_weights)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(current_model)}\")\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        current_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_mvmp_097'\n",
    "logger = Logger(model_name, learning_type='bacp')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = LocalMovementPrune(1, TARGET_SPARSITY_MID)\n",
    "\n",
    "config = {\n",
    "    'model_name':       model_name,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,               \n",
    "    'criterion':        criterion,\n",
    "    'target_sparsity':  TARGET_SPARSITY_MID,   \n",
    "    'logger':           logger,\n",
    "    'batch_size':       BATCH_SIZE,     \n",
    "    'num_classes':      CIFAR10_CLASSES,\n",
    "    'lambdas':          [0.25, 0.25, 0.25, 0.25], \n",
    "    'save_path':        save_path,\n",
    "    'pruner':           pruner,\n",
    "    'recovery_epochs':  0,\n",
    "    'epochs':           20,\n",
    "    'pruning_epochs':   1,\n",
    "}\n",
    "\n",
    "cap_learner = BaCPLearner(current_model, pre_trained_model, finetuned_model, config)\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    cap_learner.train(trainloader_c10_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b3e78ca-3354-4ae0-8947-cb499d4c11f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating classification model with unfrozen parameters\n",
    "model_name = 'vitb16'\n",
    "cls_model = cap_learner.create_classification_net(False)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(cls_model)}\")\n",
    "\n",
    "# Generate masks from model\n",
    "cap_learner.generate_mask_from_model()\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_mvmp_097_ds.pt'\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = cap_learner.get_pruner()\n",
    "pruning_type = 'movement_pruning'\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           30,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   0,\n",
    "    'pruning_type':     pruning_type,\n",
    "    'stop_epochs':      5,\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner,\n",
    "                                                      True)\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f53bbdb-b218-4776-b54e-3df263836095",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sparsity: 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "927cd277-5090-4360-8aa3-8cf7ccc92923",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ViT-B-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77c7494f-7060-40ea-8831-e9424246aa91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "########## MAGNITUDE PRUNING ##########\n",
    "#######################################\n",
    "\n",
    "# Creating projection models for BaCP framework\n",
    "model_name = 'vitb16'\n",
    "                                  \n",
    "# Projection networks\n",
    "finetuned_weights = f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt'\n",
    "pre_trained_model, current_model, finetuned_model = create_models_for_cap(model_name, finetuned_weights)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(current_model)}\")\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        current_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_magp_099'\n",
    "logger = Logger(model_name, learning_type='bacp')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = LocalMagnitudePrune(1, TARGET_SPARSITY_HIGH)\n",
    "\n",
    "config = {\n",
    "    'model_name':       model_name,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,               \n",
    "    'criterion':        criterion,\n",
    "    'target_sparsity':  TARGET_SPARSITY_HIGH,   \n",
    "    'logger':           logger,\n",
    "    'batch_size':       BATCH_SIZE,     \n",
    "    'num_classes':      CIFAR10_CLASSES,\n",
    "    'lambdas':          [0.25, 0.25, 0.25, 0.25], \n",
    "    'save_path':        save_path,\n",
    "    'pruner':           pruner,\n",
    "    'recovery_epochs':  0,\n",
    "    'epochs':           20,\n",
    "    'pruning_epochs':   1,\n",
    "}\n",
    "\n",
    "cap_learner = BaCPLearner(current_model, pre_trained_model, finetuned_model, config)\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    cap_learner.train(trainloader_c10_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be23343c-8981-4476-8b0b-53a5569e28ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating classification model with unfrozen parameters\n",
    "model_name = 'vitb16'\n",
    "cls_model = cap_learner.create_classification_net(False)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(cls_model)}\")\n",
    "\n",
    "# Generate masks from model\n",
    "cap_learner.generate_mask_from_model()\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_magp_099_ds.pt'\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = cap_learner.get_pruner()\n",
    "pruning_type = 'magnitude_pruning'\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           30,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   0,\n",
    "    'pruning_type':     pruning_type,\n",
    "    'stop_epochs':      5,\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner,\n",
    "                                                      True)\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e44f0e3c-ebc1-4c74-8173-eec970252eb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "########## MOVEMENT PRUNING ##########\n",
    "######################################\n",
    "\n",
    "# Creating projection models for BaCP framework\n",
    "model_name = 'vitb16'\n",
    "                                  \n",
    "# Projection networks\n",
    "finetuned_weights = f'/dbfs/{model_name}_weights/{model_name}_sup_c10.pt'\n",
    "pre_trained_model, current_model, finetuned_model = create_models_for_cap(model_name, finetuned_weights)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(current_model)}\")\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        current_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_mvmp_099'\n",
    "logger = Logger(model_name, learning_type='bacp')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = LocalMovementPrune(1, TARGET_SPARSITY_HIGH)\n",
    "\n",
    "config = {\n",
    "    'model_name':       model_name,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,               \n",
    "    'criterion':        criterion,\n",
    "    'target_sparsity':  TARGET_SPARSITY_HIGH,   \n",
    "    'logger':           logger,\n",
    "    'batch_size':       BATCH_SIZE,     \n",
    "    'num_classes':      CIFAR10_CLASSES,\n",
    "    'lambdas':          [0.25, 0.25, 0.25, 0.25], \n",
    "    'save_path':        save_path,\n",
    "    'pruner':           pruner,\n",
    "    'recovery_epochs':  0,\n",
    "    'epochs':           20,\n",
    "    'pruning_epochs':   1,\n",
    "}\n",
    "\n",
    "cap_learner = BaCPLearner(current_model, pre_trained_model, finetuned_model, config)\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    cap_learner.train(trainloader_c10_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5d71ab2-a511-48e4-81fb-4531fa442a3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating classification model with unfrozen parameters\n",
    "model_name = 'vitb16'\n",
    "cls_model = cap_learner.create_classification_net(False)\n",
    "print(f\"Current model sparsity: {get_model_sparsity(cls_model)}\")\n",
    "\n",
    "# Generate masks from model\n",
    "cap_learner.generate_mask_from_model()\n",
    "\n",
    "# Initializing Hyperparameters\n",
    "optimizer_type = 'adam'\n",
    "optimizer_cfg = {\n",
    "    'model':        cls_model,\n",
    "    'lr':           0.0001,\n",
    "    'momentum':     MOMENTUM,\n",
    "    'weight_decay': WEIGHT_DECAY\n",
    "}\n",
    "optimizer = set_optimizer(optimizer_type, optimizer_cfg)\n",
    "scheduler = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_path = f'/dbfs/{model_name}_weights/{model_name}_bacp_mvmp_099_ds.pt'\n",
    "logger = Logger(model_name, learning_type='cls')\n",
    "\n",
    "# Initializing pruner\n",
    "pruner = cap_learner.get_pruner()\n",
    "pruning_type = 'movement_pruning'\n",
    "\n",
    "config = {\n",
    "    'trainloader':      trainloader_c10_cls,\n",
    "    'testloader':       testloader_c10_cls,\n",
    "    'optimizer':        optimizer,\n",
    "    'scheduler':        scheduler,\n",
    "    'criterion':        nn.CrossEntropyLoss(),\n",
    "    'epochs':           30,\n",
    "    \"batch_size\":       BATCH_SIZE,\n",
    "    \"save_path\":        save_path,\n",
    "    \"logger\":           logger,\n",
    "    'recover_epochs':   0,\n",
    "    'pruning_type':     pruning_type,\n",
    "    'stop_epochs':      5,\n",
    "}\n",
    "\n",
    "# Set False to train\n",
    "is_trained = False\n",
    "if not is_trained:\n",
    "    losses, train_accuracies, test_accuracies = train(cls_model,\n",
    "                                                      config,\n",
    "                                                      pruner,\n",
    "                                                      True)\n",
    "    graph_losses_n_accs(losses, \n",
    "                        train_accuracies, \n",
    "                        test_accuracies)\n",
    "\n",
    "# Evaluating model\n",
    "load_weights(cls_model, save_path)\n",
    "acc = test(cls_model, testloader_c10_cls)\n",
    "print(f\"\\nAccuracy of model is: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "vit_notebook_unified_test_1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
