{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74c9a2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ef6146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\haroo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\haroo\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "UsageError: Line magic function `%restart_python` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchinfo\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2c549e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = 'cpu'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from bacp import BaCPLearner, BaCPTrainer, BaCPTrainingArgumentsLLM\n",
    "from models import EncoderProjectionNetwork, ClassificationNetwork\n",
    "from unstructured_pruning import MagnitudePrune, MovementPrune, LocalMagnitudePrune, LocalMovementPrune, WandaPrune, PRUNER_DICT, check_model_sparsity\n",
    "from LLM_trainer import LLMTrainer, LLMTrainingArguments\n",
    "from CV_trainer import *\n",
    "from dataset_utils import get_glue_data\n",
    "from logger import Logger\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "disable_progress_bar()\n",
    "import os\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/dbfs/hf_datasets\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" \n",
    "\n",
    "from utils import *\n",
    "from constants import *\n",
    "\n",
    "device = get_device()\n",
    "print(f\"{device = }\")\n",
    "BATCH_SIZE_DISTILBERT = 64\n",
    "NUM_WORKERS = 24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c601a04e",
   "metadata": {},
   "source": [
    "## Baseline Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8c11a874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAINER] Initializing model\n",
      "[TRAINER] Pruning disabled\n",
      "[TRAINER] Current model sparsity: 0.0\n",
      "[TRAINER] Initializing data loaders for cifar10\n",
      "[CV DATALOADERS] Loaded cifar10 with splits: ['train', 'validation', 'test']\n",
      "[TRAINER] Saving model checkpoints to ./research/vitb16/cifar10/vitb16_baseline.pt\n",
      "[LOGGER] Log file created at location: ./log_records\\vitb16\\baseline\\run_7.log\n",
      "[TRAINER] Training with mixed precision enabled\n",
      "[TRAINER] Initial model sparsity: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/3]:   0%|          | 0/42500 [00:11<?, ?it/s, Loss=2.2102, Sparsity=0.00]\n",
      "Validation Epoch [1/3]:   0%|          | 0/7500 [00:09<?, ?it/s, Accuracy=0.00, Sparsity=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3]: Avg Loss: 0.0001 | Avg Accuracy: 0.00 | Model Sparsity: 0.00\n",
      "\n",
      "[TRAINER] weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [2/3]:   0%|          | 0/42500 [00:04<?, ?it/s, Loss=2.5949, Sparsity=0.00]\n",
      "Validation Epoch [2/3]:   0%|          | 0/7500 [00:00<?, ?it/s, Accuracy=0.00, Sparsity=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3]: Avg Loss: 0.0001 | Avg Accuracy: 0.00 | Model Sparsity: 0.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [3/3]:   0%|          | 0/42500 [00:02<?, ?it/s, Loss=2.7915, Sparsity=0.00]\n",
      "Validation Epoch [3/3]:   0%|          | 0/7500 [00:00<?, ?it/s, Accuracy=0.00, Sparsity=0.00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3]: Avg Loss: 0.0001 | Avg Accuracy: 0.00 | Model Sparsity: 0.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Model initialization\n",
    "model_name = \"vitb16\"\n",
    "model_task = \"cifar10\"\n",
    "\n",
    "training_args = CVTrainingArguments(\n",
    "    model_name=model_name,\n",
    "    model_task=model_task,\n",
    "    batch_size=1,\n",
    "    image_size=224,\n",
    "    epochs=3,\n",
    "    learning_type=\"baseline\",\n",
    "    db=False,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(training_args=training_args)\n",
    "\n",
    "if True:\n",
    "    trainer.train()\n",
    "\n",
    "# acc = trainer.evaluate()\n",
    "# print(f\"Accuracy = {acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b276cf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'cv',\n",
       " 'model_name': 'vitb16',\n",
       " 'model_task': 'cifar10',\n",
       " 'num_classes': 2,\n",
       " 'embedding_dim': 768,\n",
       " 'epochs': 3,\n",
       " 'pruning_epochs': 0,\n",
       " 'recovery_epochs': 0,\n",
       " 'batch_size': 64,\n",
       " 'learning_rate': 2e-05,\n",
       " 'learning_type': 'baseline',\n",
       " 'prune': False,\n",
       " 'target_sparsity': 0,\n",
       " 'sparsity_scheduler': 'linear',\n",
       " 'delta_t': 500,\n",
       " 'enable_mixed_precision': True,\n",
       " 'device': 'cpu',\n",
       " 'save_path': './research/vitb16/cifar10/vitb16_baseline.pt',\n",
       " 'current_sparsity': 0.0}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logger_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e25df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
