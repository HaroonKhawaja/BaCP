[34m[1mwandb[0m: Detected [huggingface_hub.inference] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
[TRAINER] Saving model to /dbfs/research/bacp/resnet34/cifar10/resnet34_cifar10_rigl_pruning_0.99_bacp_finetune.pt
[TRAINER] Optimizer type w/ learning rate: (sgd, 0.005)
Fine-tuning Epoch [1/100] - Finetuning Accuracy: 40.7452 - Finetuning Loss: 1.8251 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [2/100] - Finetuning Accuracy: 43.2792 - Finetuning Loss: 1.5678 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [3/100] - Finetuning Accuracy: 44.8518 - Finetuning Loss: 1.4888 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [4/100] - Finetuning Accuracy: 47.2055 - Finetuning Loss: 1.4409 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [5/100] - Finetuning Accuracy: 44.9319 - Finetuning Loss: 1.3980 - sparsity: 0.9997
Fine-tuning Epoch [6/100] - Finetuning Accuracy: 51.7428 - Finetuning Loss: 1.3676 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [7/100] - Finetuning Accuracy: 52.6843 - Finetuning Loss: 1.3439 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [8/100] - Finetuning Accuracy: 47.8065 - Finetuning Loss: 1.3330 - sparsity: 0.9997
Fine-tuning Epoch [9/100] - Finetuning Accuracy: 53.2452 - Finetuning Loss: 1.3161 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [10/100] - Finetuning Accuracy: 49.3089 - Finetuning Loss: 1.3055 - sparsity: 0.9997
Fine-tuning Epoch [11/100] - Finetuning Accuracy: 53.4856 - Finetuning Loss: 1.2969 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [12/100] - Finetuning Accuracy: 53.9864 - Finetuning Loss: 1.2848 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [13/100] - Finetuning Accuracy: 54.2268 - Finetuning Loss: 1.2714 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [14/100] - Finetuning Accuracy: 51.8530 - Finetuning Loss: 1.2693 - sparsity: 0.9997
Fine-tuning Epoch [15/100] - Finetuning Accuracy: 53.3754 - Finetuning Loss: 1.2687 - sparsity: 0.9997
Fine-tuning Epoch [16/100] - Finetuning Accuracy: 55.7192 - Finetuning Loss: 1.2630 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [17/100] - Finetuning Accuracy: 48.8482 - Finetuning Loss: 1.2602 - sparsity: 0.9997
Fine-tuning Epoch [18/100] - Finetuning Accuracy: 53.0749 - Finetuning Loss: 1.2482 - sparsity: 0.9997
Fine-tuning Epoch [19/100] - Finetuning Accuracy: 56.2500 - Finetuning Loss: 1.2534 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [20/100] - Finetuning Accuracy: 56.9010 - Finetuning Loss: 1.2350 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [21/100] - Finetuning Accuracy: 53.5958 - Finetuning Loss: 1.2415 - sparsity: 0.9997
Fine-tuning Epoch [22/100] - Finetuning Accuracy: 53.7961 - Finetuning Loss: 1.2394 - sparsity: 0.9997
Fine-tuning Epoch [23/100] - Finetuning Accuracy: 49.2989 - Finetuning Loss: 1.2397 - sparsity: 0.9997
Fine-tuning Epoch [24/100] - Finetuning Accuracy: 49.0284 - Finetuning Loss: 1.2348 - sparsity: 0.9997
Fine-tuning Epoch [25/100] - Finetuning Accuracy: 50.1002 - Finetuning Loss: 1.2267 - sparsity: 0.9997
Fine-tuning Epoch [26/100] - Finetuning Accuracy: 53.4355 - Finetuning Loss: 1.2208 - sparsity: 0.9997
Fine-tuning Epoch [27/100] - Finetuning Accuracy: 54.6274 - Finetuning Loss: 1.2213 - sparsity: 0.9997
Fine-tuning Epoch [28/100] - Finetuning Accuracy: 54.5573 - Finetuning Loss: 1.2164 - sparsity: 0.9997
Fine-tuning Epoch [29/100] - Finetuning Accuracy: 52.8846 - Finetuning Loss: 1.2269 - sparsity: 0.9997
Fine-tuning Epoch [30/100] - Finetuning Accuracy: 49.4591 - Finetuning Loss: 1.2221 - sparsity: 0.9997
Fine-tuning Epoch [31/100] - Finetuning Accuracy: 54.6274 - Finetuning Loss: 1.2254 - sparsity: 0.9997
Fine-tuning Epoch [32/100] - Finetuning Accuracy: 54.3870 - Finetuning Loss: 1.2170 - sparsity: 0.9997
Fine-tuning Epoch [33/100] - Finetuning Accuracy: 55.3986 - Finetuning Loss: 1.2152 - sparsity: 0.9997
Fine-tuning Epoch [34/100] - Finetuning Accuracy: 52.2736 - Finetuning Loss: 1.2167 - sparsity: 0.9997
Fine-tuning Epoch [35/100] - Finetuning Accuracy: 53.6058 - Finetuning Loss: 1.2159 - sparsity: 0.9997
Fine-tuning Epoch [36/100] - Finetuning Accuracy: 50.1302 - Finetuning Loss: 1.2062 - sparsity: 0.9997
Fine-tuning Epoch [37/100] - Finetuning Accuracy: 50.8814 - Finetuning Loss: 1.2118 - sparsity: 0.9997
Fine-tuning Epoch [38/100] - Finetuning Accuracy: 56.6006 - Finetuning Loss: 1.2106 - sparsity: 0.9997
Fine-tuning Epoch [39/100] - Finetuning Accuracy: 52.5240 - Finetuning Loss: 1.2037 - sparsity: 0.9997
Fine-tuning Epoch [40/100] - Finetuning Accuracy: 55.7893 - Finetuning Loss: 1.2117 - sparsity: 0.9997
Fine-tuning Epoch [41/100] - Finetuning Accuracy: 53.1050 - Finetuning Loss: 1.2133 - sparsity: 0.9997
Exception in thread Thread-3 (_pin_memory_loop):
Traceback (most recent call last):
  File "/usr/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.12/threading.py", line 1010, in run
    self._target(*self._args, **self._kwargs)
  File "/databricks/python/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py", line 61, in _pin_memory_loop
    do_one_step()
  File "/databricks/python/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py", line 37, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/multiprocessing/reductions.py", line 541, in rebuild_storage_fd
    fd = df.detach()
         ^^^^^^^^^^^
  File "/usr/lib/python3.12/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/multiprocessing/connection.py", line 526, in Client
    deliver_challenge(c, authkey)
  File "/usr/lib/python3.12/multiprocessing/connection.py", line 939, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/multiprocessing/connection.py", line 430, in _recv_bytes
    buf = self._recv(4)
          ^^^^^^^^^^^^^
  File "/usr/lib/python3.12/multiprocessing/connection.py", line 395, in _recv
    chunk = read(handle, remaining)
            ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer
Traceback (most recent call last):
  File "/Workspace/Users/haroon.khawaja@outlook.com/BaCP/project/test_notebooks/../scripts/bacp_script.py", line 42, in run_training
    bacp_trainer.finetune(run)
  File "/Workspace/Users/haroon.khawaja@outlook.com/BaCP/project/bacp.py", line 353, in finetune
    ft_metrics = self._run_finetune_validation_epoch(desc)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Workspace/Users/haroon.khawaja@outlook.com/BaCP/project/bacp.py", line 444, in _run_finetune_validation_epoch
    outputs = self.model(data)
              ^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Workspace/Users/haroon.khawaja@outlook.com/BaCP/project/model_factory.py", line 179, in forward
    x = self.model(x)
        ^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Workspace/Users/haroon.khawaja@outlook.com/BaCP/project/models/resnet.py", line 255, in forward
    return self._forward_impl(x)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Workspace/Users/haroon.khawaja@outlook.com/BaCP/project/models/resnet.py", line 246, in _forward_impl
    x = self.layer4(x)
        ^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/modules/container.py", line 240, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Workspace/Users/haroon.khawaja@outlook.com/BaCP/project/models/resnet.py", line 50, in forward
    out = self.bn1(out)
          ^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/nn/functional.py", line 2822, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
KeyboardInterrupt
