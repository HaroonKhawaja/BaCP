[34m[1mwandb[0m: Detected [huggingface_hub.inference] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
[TRAINER] Saving model to /dbfs/research/bacp/resnet34/cifar10/resnet34_cifar10_rigl_pruning_0.99_bacp_finetune.pt
[TRAINER] Optimizer type w/ learning rate: (sgd, 0.005)
Fine-tuning Epoch [1/100] - Finetuning Accuracy: 39.2428 - Finetuning Loss: 1.8470 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [2/100] - Finetuning Accuracy: 46.9852 - Finetuning Loss: 1.5981 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [3/100] - Finetuning Accuracy: 45.3726 - Finetuning Loss: 1.4997 - sparsity: 0.9997
Fine-tuning Epoch [4/100] - Finetuning Accuracy: 48.8582 - Finetuning Loss: 1.4552 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [5/100] - Finetuning Accuracy: 43.1891 - Finetuning Loss: 1.4075 - sparsity: 0.9997
Fine-tuning Epoch [6/100] - Finetuning Accuracy: 48.9183 - Finetuning Loss: 1.3783 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [7/100] - Finetuning Accuracy: 46.8149 - Finetuning Loss: 1.3559 - sparsity: 0.9997
Fine-tuning Epoch [8/100] - Finetuning Accuracy: 47.2857 - Finetuning Loss: 1.3406 - sparsity: 0.9997
Fine-tuning Epoch [9/100] - Finetuning Accuracy: 46.5445 - Finetuning Loss: 1.3250 - sparsity: 0.9997
Fine-tuning Epoch [10/100] - Finetuning Accuracy: 52.4339 - Finetuning Loss: 1.3099 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [11/100] - Finetuning Accuracy: 53.5056 - Finetuning Loss: 1.2995 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [12/100] - Finetuning Accuracy: 51.0717 - Finetuning Loss: 1.2881 - sparsity: 0.9997
Fine-tuning Epoch [13/100] - Finetuning Accuracy: 52.0232 - Finetuning Loss: 1.2821 - sparsity: 0.9997
Fine-tuning Epoch [14/100] - Finetuning Accuracy: 56.0497 - Finetuning Loss: 1.2713 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [15/100] - Finetuning Accuracy: 42.2877 - Finetuning Loss: 1.2600 - sparsity: 0.9997
Fine-tuning Epoch [16/100] - Finetuning Accuracy: 48.6378 - Finetuning Loss: 1.2641 - sparsity: 0.9997
Fine-tuning Epoch [17/100] - Finetuning Accuracy: 54.3269 - Finetuning Loss: 1.2604 - sparsity: 0.9997
Fine-tuning Epoch [18/100] - Finetuning Accuracy: 48.2272 - Finetuning Loss: 1.2464 - sparsity: 0.9997
Fine-tuning Epoch [19/100] - Finetuning Accuracy: 53.2252 - Finetuning Loss: 1.2363 - sparsity: 0.9997
Fine-tuning Epoch [20/100] - Finetuning Accuracy: 51.3522 - Finetuning Loss: 1.2396 - sparsity: 0.9997
Fine-tuning Epoch [21/100] - Finetuning Accuracy: 47.7965 - Finetuning Loss: 1.2425 - sparsity: 0.9997
Fine-tuning Epoch [22/100] - Finetuning Accuracy: 46.0437 - Finetuning Loss: 1.2380 - sparsity: 0.9997
Fine-tuning Epoch [23/100] - Finetuning Accuracy: 57.9427 - Finetuning Loss: 1.2370 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [24/100] - Finetuning Accuracy: 57.8325 - Finetuning Loss: 1.2240 - sparsity: 0.9997
Fine-tuning Epoch [25/100] - Finetuning Accuracy: 59.3249 - Finetuning Loss: 1.2215 - sparsity: 0.9997
[TRAINER] weights saved!
Fine-tuning Epoch [26/100] - Finetuning Accuracy: 49.9299 - Finetuning Loss: 1.2221 - sparsity: 0.9997
Fine-tuning Epoch [27/100] - Finetuning Accuracy: 55.6490 - Finetuning Loss: 1.2167 - sparsity: 0.9997
Fine-tuning Epoch [28/100] - Finetuning Accuracy: 55.8494 - Finetuning Loss: 1.2093 - sparsity: 0.9997
Fine-tuning Epoch [29/100] - Finetuning Accuracy: 44.4411 - Finetuning Loss: 1.2073 - sparsity: 0.9997
Fine-tuning Epoch [30/100] - Finetuning Accuracy: 50.6310 - Finetuning Loss: 1.2143 - sparsity: 0.9997
Fine-tuning Epoch [31/100] - Finetuning Accuracy: 54.5873 - Finetuning Loss: 1.2190 - sparsity: 0.9997
Fine-tuning Epoch [32/100] - Finetuning Accuracy: 51.3321 - Finetuning Loss: 1.2008 - sparsity: 0.9997
Fine-tuning Epoch [33/100] - Finetuning Accuracy: 55.9295 - Finetuning Loss: 1.1992 - sparsity: 0.9997
Fine-tuning Epoch [34/100] - Finetuning Accuracy: 51.8029 - Finetuning Loss: 1.1983 - sparsity: 0.9997
Fine-tuning Epoch [35/100] - Finetuning Accuracy: 55.9696 - Finetuning Loss: 1.2103 - sparsity: 0.9997
Fine-tuning Epoch [36/100] - Finetuning Accuracy: 46.8149 - Finetuning Loss: 1.1892 - sparsity: 0.9997
Fine-tuning Epoch [37/100] - Finetuning Accuracy: 57.0112 - Finetuning Loss: 1.2088 - sparsity: 0.9997
Fine-tuning Epoch [38/100] - Finetuning Accuracy: 54.9980 - Finetuning Loss: 1.1987 - sparsity: 0.9997
Fine-tuning Epoch [39/100] - Finetuning Accuracy: 55.0681 - Finetuning Loss: 1.2009 - sparsity: 0.9997
Fine-tuning Epoch [40/100] - Finetuning Accuracy: 37.3197 - Finetuning Loss: 1.2038 - sparsity: 0.9997
Fine-tuning Epoch [41/100] - Finetuning Accuracy: 54.1967 - Finetuning Loss: 1.2010 - sparsity: 0.9997
Fine-tuning Epoch [42/100] - Finetuning Accuracy: 56.8910 - Finetuning Loss: 1.1993 - sparsity: 0.9997
Fine-tuning Epoch [43/100] - Finetuning Accuracy: 55.2885 - Finetuning Loss: 1.2043 - sparsity: 0.9997
Fine-tuning Epoch [44/100] - Finetuning Accuracy: 51.1318 - Finetuning Loss: 1.1974 - sparsity: 0.9997
Fine-tuning Epoch [45/100] - Finetuning Accuracy: 57.0312 - Finetuning Loss: 1.1936 - sparsity: 0.9997
Fine-tuning Epoch [46/100] - Finetuning Accuracy: 51.1418 - Finetuning Loss: 1.1963 - sparsity: 0.9997
Fine-tuning Epoch [47/100] - Finetuning Accuracy: 52.1434 - Finetuning Loss: 1.1960 - sparsity: 0.9997
Fine-tuning Epoch [48/100] - Finetuning Accuracy: 58.2732 - Finetuning Loss: 1.1890 - sparsity: 0.9997
Fine-tuning Epoch [49/100] - Finetuning Accuracy: 53.9764 - Finetuning Loss: 1.1854 - sparsity: 0.9997
Fine-tuning Epoch [50/100] - Finetuning Accuracy: 57.4820 - Finetuning Loss: 1.2017 - sparsity: 0.9997
Fine-tuning Epoch [51/100] - Finetuning Accuracy: 52.6843 - Finetuning Loss: 1.1939 - sparsity: 0.9997
Fine-tuning Epoch [52/100] - Finetuning Accuracy: 51.6126 - Finetuning Loss: 1.1837 - sparsity: 0.9997
Fine-tuning Epoch [53/100] - Finetuning Accuracy: 54.3369 - Finetuning Loss: 1.1937 - sparsity: 0.9997
Fine-tuning Epoch [54/100] - Finetuning Accuracy: 56.1498 - Finetuning Loss: 1.1873 - sparsity: 0.9997
Fine-tuning Epoch [55/100] - Finetuning Accuracy: 54.4271 - Finetuning Loss: 1.1810 - sparsity: 0.9997
Fine-tuning Epoch [56/100] - Finetuning Accuracy: 56.5104 - Finetuning Loss: 1.1929 - sparsity: 0.9997
Fine-tuning Epoch [57/100] - Finetuning Accuracy: 49.3490 - Finetuning Loss: 1.1851 - sparsity: 0.9997
Fine-tuning Epoch [58/100] - Finetuning Accuracy: 51.0417 - Finetuning Loss: 1.1914 - sparsity: 0.9997
Fine-tuning Epoch [59/100] - Finetuning Accuracy: 56.1699 - Finetuning Loss: 1.1919 - sparsity: 0.9997
Fine-tuning Epoch [60/100] - Finetuning Accuracy: 49.0385 - Finetuning Loss: 1.1868 - sparsity: 0.9997
Fine-tuning Epoch [61/100] - Finetuning Accuracy: 51.3622 - Finetuning Loss: 1.1838 - sparsity: 0.9997
Fine-tuning Epoch [62/100] - Finetuning Accuracy: 48.4776 - Finetuning Loss: 1.1854 - sparsity: 0.9997
Fine-tuning Epoch [63/100] - Finetuning Accuracy: 57.6422 - Finetuning Loss: 1.1803 - sparsity: 0.9997
Fine-tuning Epoch [64/100] - Finetuning Accuracy: 48.5677 - Finetuning Loss: 1.1859 - sparsity: 0.9997
Fine-tuning Epoch [65/100] - Finetuning Accuracy: 49.4692 - Finetuning Loss: 1.1803 - sparsity: 0.9997
Fine-tuning Epoch [66/100] - Finetuning Accuracy: 48.4375 - Finetuning Loss: 1.1826 - sparsity: 0.9997
Fine-tuning Epoch [67/100] - Finetuning Accuracy: 58.0228 - Finetuning Loss: 1.1797 - sparsity: 0.9997
Fine-tuning Epoch [68/100] - Finetuning Accuracy: 57.4319 - Finetuning Loss: 1.1803 - sparsity: 0.9997
Fine-tuning Epoch [69/100] - Finetuning Accuracy: 57.5921 - Finetuning Loss: 1.1864 - sparsity: 0.9997
Fine-tuning Epoch [70/100] - Finetuning Accuracy: 53.6458 - Finetuning Loss: 1.1799 - sparsity: 0.9997
Fine-tuning Epoch [71/100] - Finetuning Accuracy: 54.7977 - Finetuning Loss: 1.1816 - sparsity: 0.9997
Fine-tuning Epoch [72/100] - Finetuning Accuracy: 54.9379 - Finetuning Loss: 1.1760 - sparsity: 0.9997
Fine-tuning Epoch [73/100] - Finetuning Accuracy: 54.5974 - Finetuning Loss: 1.1726 - sparsity: 0.9997
Fine-tuning Epoch [74/100] - Finetuning Accuracy: 51.1018 - Finetuning Loss: 1.1818 - sparsity: 0.9997
Fine-tuning Epoch [75/100] - Finetuning Accuracy: 55.8594 - Finetuning Loss: 1.1776 - sparsity: 0.9997
Fine-tuning Epoch [76/100] - Finetuning Accuracy: 54.0865 - Finetuning Loss: 1.1723 - sparsity: 0.9997
Fine-tuning Epoch [77/100] - Finetuning Accuracy: 49.2188 - Finetuning Loss: 1.1780 - sparsity: 0.9997
Fine-tuning Epoch [78/100] - Finetuning Accuracy: 51.5725 - Finetuning Loss: 1.1765 - sparsity: 0.9997
Fine-tuning Epoch [79/100] - Finetuning Accuracy: 56.3502 - Finetuning Loss: 1.1700 - sparsity: 0.9997
Fine-tuning Epoch [80/100] - Finetuning Accuracy: 41.5365 - Finetuning Loss: 1.1777 - sparsity: 0.9997
Fine-tuning Epoch [81/100] - Finetuning Accuracy: 50.7212 - Finetuning Loss: 1.1813 - sparsity: 0.9997
Fine-tuning Epoch [82/100] - Finetuning Accuracy: 55.4888 - Finetuning Loss: 1.1738 - sparsity: 0.9997
Fine-tuning Epoch [83/100] - Finetuning Accuracy: 39.5633 - Finetuning Loss: 1.1725 - sparsity: 0.9997
Fine-tuning Epoch [84/100] - Finetuning Accuracy: 49.9099 - Finetuning Loss: 1.1722 - sparsity: 0.9997
Fine-tuning Epoch [85/100] - Finetuning Accuracy: 41.3462 - Finetuning Loss: 1.1815 - sparsity: 0.9997
Fine-tuning Epoch [86/100] - Finetuning Accuracy: 55.0982 - Finetuning Loss: 1.1741 - sparsity: 0.9997
Fine-tuning Epoch [87/100] - Finetuning Accuracy: 55.0280 - Finetuning Loss: 1.1794 - sparsity: 0.9997
Fine-tuning Epoch [88/100] - Finetuning Accuracy: 58.4635 - Finetuning Loss: 1.1710 - sparsity: 0.9997
Fine-tuning Epoch [89/100] - Finetuning Accuracy: 55.0881 - Finetuning Loss: 1.1737 - sparsity: 0.9997
Fine-tuning Epoch [90/100] - Finetuning Accuracy: 55.1482 - Finetuning Loss: 1.1628 - sparsity: 0.9997
Traceback (most recent call last):
  File "/Workspace/Users/haroon.khawaja@outlook.com/BaCP/project/test_notebooks/../scripts/bacp_script.py", line 42, in run_training
    bacp_trainer.finetune(run)
  File "/Workspace/Users/haroon.khawaja@outlook.com/BaCP/project/bacp.py", line 350, in finetune
    ft_loss = self._run_finetune_epoch(epoch, desc)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Workspace/Users/haroon.khawaja@outlook.com/BaCP/project/bacp.py", line 420, in _run_finetune_epoch
    _handle_optimizer_and_pruning(self, loss, epoch, step)
  File "/Workspace/Users/haroon.khawaja@outlook.com/BaCP/project/training_utils.py", line 214, in _handle_optimizer_and_pruning
    args.optimizer.zero_grad()
  File "/databricks/python/lib/python3.12/site-packages/torch/_compile.py", line 51, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 838, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/optim/optimizer.py", line 962, in zero_grad
    with torch.autograd.profiler.record_function(self._zero_grad_profile_name):
  File "/databricks/python/lib/python3.12/site-packages/torch/autograd/profiler.py", line 771, in __enter__
    self.record = torch.ops.profiler._record_function_enter_new(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/torch/_ops.py", line 1158, in __call__
    return self._op(*args, **(kwargs or {}))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
