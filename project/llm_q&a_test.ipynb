{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58a9ae51-88d5-4a44-9724-222fb310ae08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bde51b7-8be0-49a2-8664-fdb723e846b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install torchinfo\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d864be54-f8b5-4448-b908-2f110b1e7fa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from bacp import BaCPLearner, BaCPTrainer, BaCPTrainingArgumentsLLM\n",
    "from models import EncoderProjectionNetwork, ClassificationNetwork\n",
    "from unstructured_pruning import MagnitudePrune, MovementPrune, LocalMagnitudePrune, LocalMovementPrune, WandaPrune, PRUNER_DICT, check_model_sparsity\n",
    "from LLM_trainer import LLMTrainer, LLMTrainingArguments\n",
    "from dataset_utils import get_glue_data, get_squad_data\n",
    "from logger import Logger\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset \n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "disable_progress_bar()\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/dbfs/hf_datasets\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" \n",
    "\n",
    "from utils import *\n",
    "from constants import *\n",
    "\n",
    "device = get_device()\n",
    "print(f\"{device = }\")\n",
    "BATCH_SIZE_DISTILBERT = 64\n",
    "NUM_WORKERS = 24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03b79bb7-268a-4c59-b58c-a3fbccb495bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c82ff98c-09ac-42ae-841c-cfc34d4efb1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create Training Script Here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11542415-08f0-412f-9598-f62b3f5c65ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DistilBertForQuestionAnswering, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    train_loader,\n",
    "    validation_loader=None,\n",
    "    output_dir=\"./squad_model\",\n",
    "    num_epochs=3,\n",
    "    lr=5e-5,\n",
    "    device=None\n",
    "):\n",
    "    \n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    print(f\"Training on device: {device}\")\n",
    "\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=int(0.1 * total_steps),\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    # Epoch loop\n",
    "    avg_losses = []\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        batch_losses = []\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        batchloader = tqdm(train_loader, desc=f\"Epoch {epoch} Training\")\n",
    "        for step, batch in enumerate(batchloader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            batchloader.set_postfix(Running_Loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        avg_loss = torch.mean(torch.tensor(batch_losses))\n",
    "        avg_losses.append(avg_loss)\n",
    "        print(f\"Epoch {epoch} training loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        if validation_loader:\n",
    "            model.eval()\n",
    "            val_batch_losses = []\n",
    "            correct_start = 0\n",
    "            correct_end = 0\n",
    "            exact_matches = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                batchloader = tqdm(validation_loader, desc=\"Validation\")\n",
    "                for batch in batchloader:\n",
    "                    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                    outputs = model(**batch)\n",
    "                    \n",
    "                    # Same loss calculation as training\n",
    "                    loss = outputs.loss\n",
    "                    val_batch_losses.append(loss.item())\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    start_preds = outputs.start_logits.argmax(dim=1)\n",
    "                    end_preds = outputs.end_logits.argmax(dim=1)\n",
    "                    \n",
    "                    correct_start += (start_preds == batch['start_positions']).sum().item()\n",
    "                    correct_end += (end_preds == batch['end_positions']).sum().item()\n",
    "                    \n",
    "                    both_correct = ((start_preds == batch['start_positions']) & \n",
    "                                   (end_preds == batch['end_positions'])).sum().item()\n",
    "                    exact_matches += both_correct\n",
    "                    \n",
    "                    total += batch['input_ids'].size(0)\n",
    "            \n",
    "            # Calculate metrics - same as training\n",
    "            avg_val_loss = torch.mean(torch.tensor(val_batch_losses))\n",
    "            start_acc = (correct_start / total) * 100\n",
    "            end_acc = (correct_end / total) * 100\n",
    "            exact_match_acc = (exact_matches / total) * 100\n",
    "            \n",
    "            print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
    "            print(f\"Start accuracy: {start_acc:.2f}\")\n",
    "            print(f\"End accuracy: {end_acc:.2f}\")\n",
    "            print(f\"Exact match accuracy: {exact_match_acc:.2f}\")\n",
    "            print(f\"Total samples: {total}\")\n",
    "            \n",
    "    # Save model\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"Model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa565d44-1630-4e69-b044-4957f3ebe4e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DistilBertForQuestionAnswering\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(model_name)\n",
    "subset_ratio = 1.0\n",
    "\n",
    "data = get_squad_data(tokenizer, 512, subset_ratio=subset_ratio, num_workers=24)\n",
    "trainloader = data['trainloader']\n",
    "valloader = data['valloader']\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    trainloader,\n",
    "    validation_loader=valloader,\n",
    "    output_dir=\"./squad_model\",\n",
    "    num_epochs=3,\n",
    "    lr=5e-5,\n",
    "    device=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8922147083857509,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "llm_q&a_test",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
